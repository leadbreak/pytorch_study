{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ad9da7",
   "metadata": {},
   "source": [
    "# STEP 00. GPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf18db95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "PYTORCH 기준 학습을 진행하는 기기: cuda:0\n",
      "================================================================================\n",
      "TENSORFLOW 기준 학습을 진행하는 기기  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# gpu test\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('PYTORCH 기준 학습을 진행하는 기기:',device)\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"TENSORFLOW 기준 학습을 진행하는 기기 \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524ed9d",
   "metadata": {},
   "source": [
    "# STEP 01. Simple 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ffd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2edc3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_boston()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29dfabeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e32b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00,  ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 데이터와 타깃을 텐서 자료구조로 변경\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).unsqueeze(-1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f208a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24.0000],\n",
       "        [21.6000],\n",
       "        [34.7000],\n",
       "        [33.4000],\n",
       "        [36.2000],\n",
       "        [28.7000],\n",
       "        [22.9000],\n",
       "        [27.1000],\n",
       "        [16.5000],\n",
       "        [18.9000],\n",
       "        [15.0000],\n",
       "        [18.9000],\n",
       "        [21.7000],\n",
       "        [20.4000],\n",
       "        [18.2000],\n",
       "        [19.9000],\n",
       "        [23.1000],\n",
       "        [17.5000],\n",
       "        [20.2000],\n",
       "        [18.2000],\n",
       "        [13.6000],\n",
       "        [19.6000],\n",
       "        [15.2000],\n",
       "        [14.5000],\n",
       "        [15.6000],\n",
       "        [13.9000],\n",
       "        [16.6000],\n",
       "        [14.8000],\n",
       "        [18.4000],\n",
       "        [21.0000],\n",
       "        [12.7000],\n",
       "        [14.5000],\n",
       "        [13.2000],\n",
       "        [13.1000],\n",
       "        [13.5000],\n",
       "        [18.9000],\n",
       "        [20.0000],\n",
       "        [21.0000],\n",
       "        [24.7000],\n",
       "        [30.8000],\n",
       "        [34.9000],\n",
       "        [26.6000],\n",
       "        [25.3000],\n",
       "        [24.7000],\n",
       "        [21.2000],\n",
       "        [19.3000],\n",
       "        [20.0000],\n",
       "        [16.6000],\n",
       "        [14.4000],\n",
       "        [19.4000],\n",
       "        [19.7000],\n",
       "        [20.5000],\n",
       "        [25.0000],\n",
       "        [23.4000],\n",
       "        [18.9000],\n",
       "        [35.4000],\n",
       "        [24.7000],\n",
       "        [31.6000],\n",
       "        [23.3000],\n",
       "        [19.6000],\n",
       "        [18.7000],\n",
       "        [16.0000],\n",
       "        [22.2000],\n",
       "        [25.0000],\n",
       "        [33.0000],\n",
       "        [23.5000],\n",
       "        [19.4000],\n",
       "        [22.0000],\n",
       "        [17.4000],\n",
       "        [20.9000],\n",
       "        [24.2000],\n",
       "        [21.7000],\n",
       "        [22.8000],\n",
       "        [23.4000],\n",
       "        [24.1000],\n",
       "        [21.4000],\n",
       "        [20.0000],\n",
       "        [20.8000],\n",
       "        [21.2000],\n",
       "        [20.3000],\n",
       "        [28.0000],\n",
       "        [23.9000],\n",
       "        [24.8000],\n",
       "        [22.9000],\n",
       "        [23.9000],\n",
       "        [26.6000],\n",
       "        [22.5000],\n",
       "        [22.2000],\n",
       "        [23.6000],\n",
       "        [28.7000],\n",
       "        [22.6000],\n",
       "        [22.0000],\n",
       "        [22.9000],\n",
       "        [25.0000],\n",
       "        [20.6000],\n",
       "        [28.4000],\n",
       "        [21.4000],\n",
       "        [38.7000],\n",
       "        [43.8000],\n",
       "        [33.2000],\n",
       "        [27.5000],\n",
       "        [26.5000],\n",
       "        [18.6000],\n",
       "        [19.3000],\n",
       "        [20.1000],\n",
       "        [19.5000],\n",
       "        [19.5000],\n",
       "        [20.4000],\n",
       "        [19.8000],\n",
       "        [19.4000],\n",
       "        [21.7000],\n",
       "        [22.8000],\n",
       "        [18.8000],\n",
       "        [18.7000],\n",
       "        [18.5000],\n",
       "        [18.3000],\n",
       "        [21.2000],\n",
       "        [19.2000],\n",
       "        [20.4000],\n",
       "        [19.3000],\n",
       "        [22.0000],\n",
       "        [20.3000],\n",
       "        [20.5000],\n",
       "        [17.3000],\n",
       "        [18.8000],\n",
       "        [21.4000],\n",
       "        [15.7000],\n",
       "        [16.2000],\n",
       "        [18.0000],\n",
       "        [14.3000],\n",
       "        [19.2000],\n",
       "        [19.6000],\n",
       "        [23.0000],\n",
       "        [18.4000],\n",
       "        [15.6000],\n",
       "        [18.1000],\n",
       "        [17.4000],\n",
       "        [17.1000],\n",
       "        [13.3000],\n",
       "        [17.8000],\n",
       "        [14.0000],\n",
       "        [14.4000],\n",
       "        [13.4000],\n",
       "        [15.6000],\n",
       "        [11.8000],\n",
       "        [13.8000],\n",
       "        [15.6000],\n",
       "        [14.6000],\n",
       "        [17.8000],\n",
       "        [15.4000],\n",
       "        [21.5000],\n",
       "        [19.6000],\n",
       "        [15.3000],\n",
       "        [19.4000],\n",
       "        [17.0000],\n",
       "        [15.6000],\n",
       "        [13.1000],\n",
       "        [41.3000],\n",
       "        [24.3000],\n",
       "        [23.3000],\n",
       "        [27.0000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [22.7000],\n",
       "        [25.0000],\n",
       "        [50.0000],\n",
       "        [23.8000],\n",
       "        [23.8000],\n",
       "        [22.3000],\n",
       "        [17.4000],\n",
       "        [19.1000],\n",
       "        [23.1000],\n",
       "        [23.6000],\n",
       "        [22.6000],\n",
       "        [29.4000],\n",
       "        [23.2000],\n",
       "        [24.6000],\n",
       "        [29.9000],\n",
       "        [37.2000],\n",
       "        [39.8000],\n",
       "        [36.2000],\n",
       "        [37.9000],\n",
       "        [32.5000],\n",
       "        [26.4000],\n",
       "        [29.6000],\n",
       "        [50.0000],\n",
       "        [32.0000],\n",
       "        [29.8000],\n",
       "        [34.9000],\n",
       "        [37.0000],\n",
       "        [30.5000],\n",
       "        [36.4000],\n",
       "        [31.1000],\n",
       "        [29.1000],\n",
       "        [50.0000],\n",
       "        [33.3000],\n",
       "        [30.3000],\n",
       "        [34.6000],\n",
       "        [34.9000],\n",
       "        [32.9000],\n",
       "        [24.1000],\n",
       "        [42.3000],\n",
       "        [48.5000],\n",
       "        [50.0000],\n",
       "        [22.6000],\n",
       "        [24.4000],\n",
       "        [22.5000],\n",
       "        [24.4000],\n",
       "        [20.0000],\n",
       "        [21.7000],\n",
       "        [19.3000],\n",
       "        [22.4000],\n",
       "        [28.1000],\n",
       "        [23.7000],\n",
       "        [25.0000],\n",
       "        [23.3000],\n",
       "        [28.7000],\n",
       "        [21.5000],\n",
       "        [23.0000],\n",
       "        [26.7000],\n",
       "        [21.7000],\n",
       "        [27.5000],\n",
       "        [30.1000],\n",
       "        [44.8000],\n",
       "        [50.0000],\n",
       "        [37.6000],\n",
       "        [31.6000],\n",
       "        [46.7000],\n",
       "        [31.5000],\n",
       "        [24.3000],\n",
       "        [31.7000],\n",
       "        [41.7000],\n",
       "        [48.3000],\n",
       "        [29.0000],\n",
       "        [24.0000],\n",
       "        [25.1000],\n",
       "        [31.5000],\n",
       "        [23.7000],\n",
       "        [23.3000],\n",
       "        [22.0000],\n",
       "        [20.1000],\n",
       "        [22.2000],\n",
       "        [23.7000],\n",
       "        [17.6000],\n",
       "        [18.5000],\n",
       "        [24.3000],\n",
       "        [20.5000],\n",
       "        [24.5000],\n",
       "        [26.2000],\n",
       "        [24.4000],\n",
       "        [24.8000],\n",
       "        [29.6000],\n",
       "        [42.8000],\n",
       "        [21.9000],\n",
       "        [20.9000],\n",
       "        [44.0000],\n",
       "        [50.0000],\n",
       "        [36.0000],\n",
       "        [30.1000],\n",
       "        [33.8000],\n",
       "        [43.1000],\n",
       "        [48.8000],\n",
       "        [31.0000],\n",
       "        [36.5000],\n",
       "        [22.8000],\n",
       "        [30.7000],\n",
       "        [50.0000],\n",
       "        [43.5000],\n",
       "        [20.7000],\n",
       "        [21.1000],\n",
       "        [25.2000],\n",
       "        [24.4000],\n",
       "        [35.2000],\n",
       "        [32.4000],\n",
       "        [32.0000],\n",
       "        [33.2000],\n",
       "        [33.1000],\n",
       "        [29.1000],\n",
       "        [35.1000],\n",
       "        [45.4000],\n",
       "        [35.4000],\n",
       "        [46.0000],\n",
       "        [50.0000],\n",
       "        [32.2000],\n",
       "        [22.0000],\n",
       "        [20.1000],\n",
       "        [23.2000],\n",
       "        [22.3000],\n",
       "        [24.8000],\n",
       "        [28.5000],\n",
       "        [37.3000],\n",
       "        [27.9000],\n",
       "        [23.9000],\n",
       "        [21.7000],\n",
       "        [28.6000],\n",
       "        [27.1000],\n",
       "        [20.3000],\n",
       "        [22.5000],\n",
       "        [29.0000],\n",
       "        [24.8000],\n",
       "        [22.0000],\n",
       "        [26.4000],\n",
       "        [33.1000],\n",
       "        [36.1000],\n",
       "        [28.4000],\n",
       "        [33.4000],\n",
       "        [28.2000],\n",
       "        [22.8000],\n",
       "        [20.3000],\n",
       "        [16.1000],\n",
       "        [22.1000],\n",
       "        [19.4000],\n",
       "        [21.6000],\n",
       "        [23.8000],\n",
       "        [16.2000],\n",
       "        [17.8000],\n",
       "        [19.8000],\n",
       "        [23.1000],\n",
       "        [21.0000],\n",
       "        [23.8000],\n",
       "        [23.1000],\n",
       "        [20.4000],\n",
       "        [18.5000],\n",
       "        [25.0000],\n",
       "        [24.6000],\n",
       "        [23.0000],\n",
       "        [22.2000],\n",
       "        [19.3000],\n",
       "        [22.6000],\n",
       "        [19.8000],\n",
       "        [17.1000],\n",
       "        [19.4000],\n",
       "        [22.2000],\n",
       "        [20.7000],\n",
       "        [21.1000],\n",
       "        [19.5000],\n",
       "        [18.5000],\n",
       "        [20.6000],\n",
       "        [19.0000],\n",
       "        [18.7000],\n",
       "        [32.7000],\n",
       "        [16.5000],\n",
       "        [23.9000],\n",
       "        [31.2000],\n",
       "        [17.5000],\n",
       "        [17.2000],\n",
       "        [23.1000],\n",
       "        [24.5000],\n",
       "        [26.6000],\n",
       "        [22.9000],\n",
       "        [24.1000],\n",
       "        [18.6000],\n",
       "        [30.1000],\n",
       "        [18.2000],\n",
       "        [20.6000],\n",
       "        [17.8000],\n",
       "        [21.7000],\n",
       "        [22.7000],\n",
       "        [22.6000],\n",
       "        [25.0000],\n",
       "        [19.9000],\n",
       "        [20.8000],\n",
       "        [16.8000],\n",
       "        [21.9000],\n",
       "        [27.5000],\n",
       "        [21.9000],\n",
       "        [23.1000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [50.0000],\n",
       "        [13.8000],\n",
       "        [13.8000],\n",
       "        [15.0000],\n",
       "        [13.9000],\n",
       "        [13.3000],\n",
       "        [13.1000],\n",
       "        [10.2000],\n",
       "        [10.4000],\n",
       "        [10.9000],\n",
       "        [11.3000],\n",
       "        [12.3000],\n",
       "        [ 8.8000],\n",
       "        [ 7.2000],\n",
       "        [10.5000],\n",
       "        [ 7.4000],\n",
       "        [10.2000],\n",
       "        [11.5000],\n",
       "        [15.1000],\n",
       "        [23.2000],\n",
       "        [ 9.7000],\n",
       "        [13.8000],\n",
       "        [12.7000],\n",
       "        [13.1000],\n",
       "        [12.5000],\n",
       "        [ 8.5000],\n",
       "        [ 5.0000],\n",
       "        [ 6.3000],\n",
       "        [ 5.6000],\n",
       "        [ 7.2000],\n",
       "        [12.1000],\n",
       "        [ 8.3000],\n",
       "        [ 8.5000],\n",
       "        [ 5.0000],\n",
       "        [11.9000],\n",
       "        [27.9000],\n",
       "        [17.2000],\n",
       "        [27.5000],\n",
       "        [15.0000],\n",
       "        [17.2000],\n",
       "        [17.9000],\n",
       "        [16.3000],\n",
       "        [ 7.0000],\n",
       "        [ 7.2000],\n",
       "        [ 7.5000],\n",
       "        [10.4000],\n",
       "        [ 8.8000],\n",
       "        [ 8.4000],\n",
       "        [16.7000],\n",
       "        [14.2000],\n",
       "        [20.8000],\n",
       "        [13.4000],\n",
       "        [11.7000],\n",
       "        [ 8.3000],\n",
       "        [10.2000],\n",
       "        [10.9000],\n",
       "        [11.0000],\n",
       "        [ 9.5000],\n",
       "        [14.5000],\n",
       "        [14.1000],\n",
       "        [16.1000],\n",
       "        [14.3000],\n",
       "        [11.7000],\n",
       "        [13.4000],\n",
       "        [ 9.6000],\n",
       "        [ 8.7000],\n",
       "        [ 8.4000],\n",
       "        [12.8000],\n",
       "        [10.5000],\n",
       "        [17.1000],\n",
       "        [18.4000],\n",
       "        [15.4000],\n",
       "        [10.8000],\n",
       "        [11.8000],\n",
       "        [14.9000],\n",
       "        [12.6000],\n",
       "        [14.1000],\n",
       "        [13.0000],\n",
       "        [13.4000],\n",
       "        [15.2000],\n",
       "        [16.1000],\n",
       "        [17.8000],\n",
       "        [14.9000],\n",
       "        [14.1000],\n",
       "        [12.7000],\n",
       "        [13.5000],\n",
       "        [14.9000],\n",
       "        [20.0000],\n",
       "        [16.4000],\n",
       "        [17.7000],\n",
       "        [19.5000],\n",
       "        [20.2000],\n",
       "        [21.4000],\n",
       "        [19.9000],\n",
       "        [19.0000],\n",
       "        [19.1000],\n",
       "        [19.1000],\n",
       "        [20.1000],\n",
       "        [19.9000],\n",
       "        [19.6000],\n",
       "        [23.2000],\n",
       "        [29.8000],\n",
       "        [13.8000],\n",
       "        [13.3000],\n",
       "        [16.7000],\n",
       "        [12.0000],\n",
       "        [14.6000],\n",
       "        [21.4000],\n",
       "        [23.0000],\n",
       "        [23.7000],\n",
       "        [25.0000],\n",
       "        [21.8000],\n",
       "        [20.6000],\n",
       "        [21.2000],\n",
       "        [19.1000],\n",
       "        [20.6000],\n",
       "        [15.2000],\n",
       "        [ 7.0000],\n",
       "        [ 8.1000],\n",
       "        [13.6000],\n",
       "        [20.1000],\n",
       "        [21.8000],\n",
       "        [24.5000],\n",
       "        [23.1000],\n",
       "        [19.7000],\n",
       "        [18.3000],\n",
       "        [21.2000],\n",
       "        [17.5000],\n",
       "        [16.8000],\n",
       "        [22.4000],\n",
       "        [20.6000],\n",
       "        [23.9000],\n",
       "        [22.0000],\n",
       "        [11.9000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5629912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4827, -0.3587, -0.4668,  ..., -0.3773,  2.2514, -0.4484],\n",
       "        [-0.4825, -0.4827, -0.4340,  ..., -0.3601,  2.2514, -0.4198],\n",
       "        [-0.4825, -0.4827, -0.4340,  ..., -0.3601,  2.2233, -0.4550],\n",
       "        ...,\n",
       "        [-0.4823, -0.4827, -0.4005,  ..., -0.3381,  2.2514, -0.4439],\n",
       "        [-0.4820, -0.4827, -0.4005,  ..., -0.3381,  2.2276, -0.4381],\n",
       "        [-0.4824, -0.4827, -0.4005,  ..., -0.3381,  2.2514, -0.4284]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 범위 조정을 위해 표준화를 적용\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae952ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=13, out_features=1, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13개의 값을 입력받는 선형회귀 모델 객체를 생성\n",
    "\n",
    "model = nn.Linear(13,1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "148b36a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균제곱오차(Mean Squared Error) 손실 함수 객체를 생성\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 확률적 경사 하강법 옵티마이저 객체를 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ebd49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcd06db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.train(model, criterion, optimizer, X, y)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습함수를 정의\n",
    "def train(model, criterion, optimizer, X, y) :\n",
    "    # 기울기 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 모델을 사용해 타깃을 추론\n",
    "    hypothesis = model(X)\n",
    "    # 오차를 계산\n",
    "    loss = criterion(hypothesis, y)\n",
    "    # 기울기를 계산\n",
    "    loss.backward()\n",
    "    # 경사 하강법으로 가중치를 수정\n",
    "    optimizer.step()\n",
    "    # 현재 에포크의 오차를 반환\n",
    "    return loss.item()\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7168838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 71.17890167236328\n",
      "epoch : 20, loss : 70.68428802490234\n",
      "epoch : 30, loss : 70.25029754638672\n",
      "epoch : 40, loss : 69.8577651977539\n",
      "epoch : 50, loss : 69.4946517944336\n",
      "epoch : 60, loss : 69.15338897705078\n",
      "epoch : 70, loss : 68.82913208007812\n",
      "epoch : 80, loss : 68.51878356933594\n",
      "epoch : 90, loss : 68.22029113769531\n",
      "epoch : 100, loss : 67.93229675292969\n",
      "epoch : 110, loss : 67.6538314819336\n",
      "epoch : 120, loss : 67.38420867919922\n",
      "epoch : 130, loss : 67.12290954589844\n",
      "epoch : 140, loss : 66.86951446533203\n",
      "epoch : 150, loss : 66.62366485595703\n",
      "epoch : 160, loss : 66.3850326538086\n",
      "epoch : 170, loss : 66.15339660644531\n",
      "epoch : 180, loss : 65.92847442626953\n",
      "epoch : 190, loss : 65.71003723144531\n",
      "epoch : 200, loss : 65.49786376953125\n",
      "epoch : 210, loss : 65.29174041748047\n",
      "epoch : 220, loss : 65.09148406982422\n",
      "epoch : 230, loss : 64.8968734741211\n",
      "epoch : 240, loss : 64.70773315429688\n",
      "epoch : 250, loss : 64.52391052246094\n",
      "epoch : 260, loss : 64.34519958496094\n",
      "epoch : 270, loss : 64.17144012451172\n",
      "epoch : 280, loss : 64.00248718261719\n",
      "epoch : 290, loss : 63.83818054199219\n",
      "epoch : 300, loss : 63.678340911865234\n",
      "epoch : 310, loss : 63.52286148071289\n",
      "epoch : 320, loss : 63.37158966064453\n",
      "epoch : 330, loss : 63.224369049072266\n",
      "epoch : 340, loss : 63.08109664916992\n",
      "epoch : 350, loss : 62.94164276123047\n",
      "epoch : 360, loss : 62.805885314941406\n",
      "epoch : 370, loss : 62.67368698120117\n",
      "epoch : 380, loss : 62.54494094848633\n",
      "epoch : 390, loss : 62.4195556640625\n",
      "epoch : 400, loss : 62.29739761352539\n",
      "epoch : 410, loss : 62.178382873535156\n",
      "epoch : 420, loss : 62.06239318847656\n",
      "epoch : 430, loss : 61.94935989379883\n",
      "epoch : 440, loss : 61.83917236328125\n",
      "epoch : 450, loss : 61.73173904418945\n",
      "epoch : 460, loss : 61.626976013183594\n",
      "epoch : 470, loss : 61.52479934692383\n",
      "epoch : 480, loss : 61.42512130737305\n",
      "epoch : 490, loss : 61.327880859375\n",
      "epoch : 500, loss : 61.23298645019531\n",
      "epoch : 510, loss : 61.14036560058594\n",
      "epoch : 520, loss : 61.049964904785156\n",
      "epoch : 530, loss : 60.961692810058594\n",
      "epoch : 540, loss : 60.87549591064453\n",
      "epoch : 550, loss : 60.79129409790039\n",
      "epoch : 560, loss : 60.70903778076172\n",
      "epoch : 570, loss : 60.62867736816406\n",
      "epoch : 580, loss : 60.55013656616211\n",
      "epoch : 590, loss : 60.4733772277832\n",
      "epoch : 600, loss : 60.3983154296875\n",
      "epoch : 610, loss : 60.32492446899414\n",
      "epoch : 620, loss : 60.253150939941406\n",
      "epoch : 630, loss : 60.18292999267578\n",
      "epoch : 640, loss : 60.114234924316406\n",
      "epoch : 650, loss : 60.0469970703125\n",
      "epoch : 660, loss : 59.981197357177734\n",
      "epoch : 670, loss : 59.916778564453125\n",
      "epoch : 680, loss : 59.85370635986328\n",
      "epoch : 690, loss : 59.79191970825195\n",
      "epoch : 700, loss : 59.73140335083008\n",
      "epoch : 710, loss : 59.672115325927734\n",
      "epoch : 720, loss : 59.61399841308594\n",
      "epoch : 730, loss : 59.55705261230469\n",
      "epoch : 740, loss : 59.50121307373047\n",
      "epoch : 750, loss : 59.44647216796875\n",
      "epoch : 760, loss : 59.392765045166016\n",
      "epoch : 770, loss : 59.340091705322266\n",
      "epoch : 780, loss : 59.288414001464844\n",
      "epoch : 790, loss : 59.2376823425293\n",
      "epoch : 800, loss : 59.187896728515625\n",
      "epoch : 810, loss : 59.1390266418457\n",
      "epoch : 820, loss : 59.09103012084961\n",
      "epoch : 830, loss : 59.04389572143555\n",
      "epoch : 840, loss : 58.99759292602539\n",
      "epoch : 850, loss : 58.952091217041016\n",
      "epoch : 860, loss : 58.907379150390625\n",
      "epoch : 870, loss : 58.86343002319336\n",
      "epoch : 880, loss : 58.82021713256836\n",
      "epoch : 890, loss : 58.77772903442383\n",
      "epoch : 900, loss : 58.735939025878906\n",
      "epoch : 910, loss : 58.694828033447266\n",
      "epoch : 920, loss : 58.65436935424805\n",
      "epoch : 930, loss : 58.61457061767578\n",
      "epoch : 940, loss : 58.57538604736328\n",
      "epoch : 950, loss : 58.53682327270508\n",
      "epoch : 960, loss : 58.49882507324219\n",
      "epoch : 970, loss : 58.4614143371582\n",
      "epoch : 980, loss : 58.4245719909668\n",
      "epoch : 990, loss : 58.388267517089844\n",
      "epoch : 1000, loss : 58.35248947143555\n"
     ]
    }
   ],
   "source": [
    "# 1000회에 걸쳐 모델을 학습시킵니다\n",
    "n_epochs = 1000\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    # 모델을 학습시킵니다\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    # 10 epoch마다 오차를 출력합니다\n",
    "    if epoch % 10 == 0 :\n",
    "        print(f\"epoch : {epoch}, loss : {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72411323",
   "metadata": {},
   "source": [
    "# STEP 02. Simple 002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84cc19c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1923, -0.2256,  0.2668,  ..., -0.2699, -0.2691, -0.2706],\n",
       "        [-0.1810, -0.1933,  0.3110,  ..., -0.2703, -0.2699, -0.2707],\n",
       "        [-0.1848, -0.1780,  0.2983,  ..., -0.2700, -0.2695, -0.2707],\n",
       "        ...,\n",
       "        [-0.1984, -0.1481,  0.2033,  ..., -0.2705, -0.2701, -0.2707],\n",
       "        [-0.1809, -0.1426,  0.3426,  ..., -0.2699, -0.2693, -0.2705],\n",
       "        [-0.2371, -0.1636, -0.0612,  ..., -0.2711, -0.2698, -0.2708]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1,1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "868b6f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e24088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([569, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd71ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30개의 값을 입력받는 로지스틱 회귀 모델 객체를 생성합니다\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(30,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b203425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이진 크로스엔트로피(Binary Cross Entropy) 혼실 함수 객체를 생성합니다\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 확률적 경사 하강법 객체를 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6c85c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec3ea5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.train(model, criterion, optimizer, X, y)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 함수를 정의합니다\n",
    "def train(model, criterion, optimizer, X, y) :\n",
    "    # 기울기를 초기화합니다\n",
    "    optimizer.zero_grad()\n",
    "    # 모델을 사용해 결과를 추정합니다\n",
    "    hypothesis = model(X)\n",
    "    # 오차를 계산합니다\n",
    "    loss = criterion(hypothesis, y)\n",
    "    # 기울기를 계산합니다\n",
    "    loss.backward()\n",
    "    #경사하강법으로 가중치를 수정합니다\n",
    "    optimizer.step()\n",
    "    # 현재 에포크의 오차를 반환합니다\n",
    "    return loss.item()\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd06771d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 0.16283491253852844\n",
      "epoch : 20, loss : 0.16282859444618225\n",
      "epoch : 30, loss : 0.16282230615615845\n",
      "epoch : 40, loss : 0.16281597316265106\n",
      "epoch : 50, loss : 0.16280971467494965\n",
      "epoch : 60, loss : 0.16280345618724823\n",
      "epoch : 70, loss : 0.16279715299606323\n",
      "epoch : 80, loss : 0.1627909243106842\n",
      "epoch : 90, loss : 0.1627846360206604\n",
      "epoch : 100, loss : 0.16277840733528137\n",
      "epoch : 110, loss : 0.16277214884757996\n",
      "epoch : 120, loss : 0.16276593506336212\n",
      "epoch : 130, loss : 0.1627596616744995\n",
      "epoch : 140, loss : 0.16275346279144287\n",
      "epoch : 150, loss : 0.16274726390838623\n",
      "epoch : 160, loss : 0.16274107992649078\n",
      "epoch : 170, loss : 0.16273485124111176\n",
      "epoch : 180, loss : 0.1627286672592163\n",
      "epoch : 190, loss : 0.16272246837615967\n",
      "epoch : 200, loss : 0.1627163141965866\n",
      "epoch : 210, loss : 0.16271014511585236\n",
      "epoch : 220, loss : 0.1627039760351181\n",
      "epoch : 230, loss : 0.16269783675670624\n",
      "epoch : 240, loss : 0.16269166767597198\n",
      "epoch : 250, loss : 0.16268552839756012\n",
      "epoch : 260, loss : 0.16267938911914825\n",
      "epoch : 270, loss : 0.1626732349395752\n",
      "epoch : 280, loss : 0.1626671403646469\n",
      "epoch : 290, loss : 0.16266100108623505\n",
      "epoch : 300, loss : 0.16265489161014557\n",
      "epoch : 310, loss : 0.16264881193637848\n",
      "epoch : 320, loss : 0.1626427322626114\n",
      "epoch : 330, loss : 0.1626366227865219\n",
      "epoch : 340, loss : 0.16263052821159363\n",
      "epoch : 350, loss : 0.16262447834014893\n",
      "epoch : 360, loss : 0.16261839866638184\n",
      "epoch : 370, loss : 0.16261231899261475\n",
      "epoch : 380, loss : 0.16260626912117004\n",
      "epoch : 390, loss : 0.16260024905204773\n",
      "epoch : 400, loss : 0.16259422898292542\n",
      "epoch : 410, loss : 0.16258813440799713\n",
      "epoch : 420, loss : 0.1625821590423584\n",
      "epoch : 430, loss : 0.16257613897323608\n",
      "epoch : 440, loss : 0.16257013380527496\n",
      "epoch : 450, loss : 0.16256409883499146\n",
      "epoch : 460, loss : 0.16255810856819153\n",
      "epoch : 470, loss : 0.1625521034002304\n",
      "epoch : 480, loss : 0.1625460833311081\n",
      "epoch : 490, loss : 0.16254012286663055\n",
      "epoch : 500, loss : 0.16253414750099182\n",
      "epoch : 510, loss : 0.16252818703651428\n",
      "epoch : 520, loss : 0.16252221167087555\n",
      "epoch : 530, loss : 0.1625162661075592\n",
      "epoch : 540, loss : 0.16251032054424286\n",
      "epoch : 550, loss : 0.16250436007976532\n",
      "epoch : 560, loss : 0.16249847412109375\n",
      "epoch : 570, loss : 0.1624925136566162\n",
      "epoch : 580, loss : 0.16248659789562225\n",
      "epoch : 590, loss : 0.1624806821346283\n",
      "epoch : 600, loss : 0.16247476637363434\n",
      "epoch : 610, loss : 0.1624688357114792\n",
      "epoch : 620, loss : 0.16246297955513\n",
      "epoch : 630, loss : 0.16245704889297485\n",
      "epoch : 640, loss : 0.16245119273662567\n",
      "epoch : 650, loss : 0.1624452918767929\n",
      "epoch : 660, loss : 0.16243940591812134\n",
      "epoch : 670, loss : 0.16243351995944977\n",
      "epoch : 680, loss : 0.16242767870426178\n",
      "epoch : 690, loss : 0.1624218225479126\n",
      "epoch : 700, loss : 0.16241596639156342\n",
      "epoch : 710, loss : 0.16241012513637543\n",
      "epoch : 720, loss : 0.16240431368350983\n",
      "epoch : 730, loss : 0.16239842772483826\n",
      "epoch : 740, loss : 0.16239264607429504\n",
      "epoch : 750, loss : 0.16238683462142944\n",
      "epoch : 760, loss : 0.16238102316856384\n",
      "epoch : 770, loss : 0.16237522661685944\n",
      "epoch : 780, loss : 0.16236938536167145\n",
      "epoch : 790, loss : 0.16236360371112823\n",
      "epoch : 800, loss : 0.16235783696174622\n",
      "epoch : 810, loss : 0.1623520404100418\n",
      "epoch : 820, loss : 0.1623462736606598\n",
      "epoch : 830, loss : 0.16234047710895538\n",
      "epoch : 840, loss : 0.16233471035957336\n",
      "epoch : 850, loss : 0.16232895851135254\n",
      "epoch : 860, loss : 0.1623232066631317\n",
      "epoch : 870, loss : 0.1623174548149109\n",
      "epoch : 880, loss : 0.16231171786785126\n",
      "epoch : 890, loss : 0.162306010723114\n",
      "epoch : 900, loss : 0.1623002588748932\n",
      "epoch : 910, loss : 0.16229450702667236\n",
      "epoch : 920, loss : 0.16228879988193512\n",
      "epoch : 930, loss : 0.1622830629348755\n",
      "epoch : 940, loss : 0.16227735579013824\n",
      "epoch : 950, loss : 0.1622716635465622\n",
      "epoch : 960, loss : 0.16226598620414734\n",
      "epoch : 970, loss : 0.1622602790594101\n",
      "epoch : 980, loss : 0.16225458681583405\n",
      "epoch : 990, loss : 0.1622489094734192\n",
      "epoch : 1000, loss : 0.16224324703216553\n"
     ]
    }
   ],
   "source": [
    "# 1,000회에 걸쳐 모델을 학습시킵니다\n",
    "n_epochs = 1000\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    # 모델을 학습시킵니다\n",
    "    loss = train(model, criterion, optimizer, X, y)\n",
    "    # 10 epoch마다 오차를 출력합니다\n",
    "    if epoch % 10 == 0  :\n",
    "        print(f\"epoch : {epoch}, loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b778c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9332161545753479\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델을 사용해 결과를 추론합니다\n",
    "y_predicted = (model(X) >= 0.5)\n",
    "\n",
    "# 정확도를 계산하고 출력합니다\n",
    "score = (y_predicted == y).float().mean()\n",
    "print(f\"accuracy : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0e920",
   "metadata": {},
   "source": [
    "# STEP 03. Simple 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24dfd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10d0c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1,1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "628278e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x248a8df4460>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 데이터와 타깃을 묶어 텐서 데이터셋을 생성\n",
    "dset = TensorDataset(X, y)\n",
    "\n",
    "# 한 번에 256개의 데이터 샘플을 배치로 사용하는 데이터로더를 생성\n",
    "loader = DataLoader(dset, batch_size=256, shuffle=True)\n",
    "\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b663f5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x248a8df4310>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a013f4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.NeuralNetwork"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n개의 값을 입력받는 신경망 모델 클래스를 정의합니다\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    # 생성자에서 모델의 구조를 정의\n",
    "    def __init__(self, num_features) :\n",
    "        # 상속받아 생성한 객체이므로 부모(nn.Module)의 생성자를 호출\n",
    "        super().__init__()\n",
    "        # num_features개의 특성을 입력받는 은닉층 노드를 4개 생성\n",
    "        self.linear1 = nn.Linear(num_features, 4)\n",
    "        # 렐루 함수 객체를 생성\n",
    "        self.relu = nn.ReLU()\n",
    "        # 4개의 값을 입력받는 출력층 노드 1개를 생성\n",
    "        self.linear2 = nn.Linear(4, 1)\n",
    "        # 시그모이드 함수 객체를 생성\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    # 모델의 순전파를 정의\n",
    "    def forward(self, X) :\n",
    "        # 생성자에서 만든 은닉층과 출력층 노드로 타깃을 추론하고 반환합니다\n",
    "        out = self.linear1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea1a4a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear1): Linear(in_features=30, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30개의 특성값을 입력받는 신경망 모델 객체를 생성\n",
    "\n",
    "model = NeuralNetwork(30)\n",
    "\n",
    "# 이진 크로스엔트로피(BCE) 손실 함수 객체를 생성\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 확률적 경사 하강법 옵티마이저 객체를 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd9214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수를 정의\n",
    "def train(model, criterion, optimizer, loader) :\n",
    "    # 현재 에포크의 오차를 저장할 변수를 생성\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # 배치 학습을 실행\n",
    "    for X_batch, y_batch in loader :\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 타겟 추론\n",
    "        hypothesis = model(X_batch)\n",
    "        # 오차 계산\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        # 기울기 계산\n",
    "        loss.backward()\n",
    "        # 가중치 수정\n",
    "        optimizer.step()\n",
    "        # 현재 배치의 오차를 기록\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # 현재 에포크의 오차를 반환\n",
    "    return epoch_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74eeacf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 0.14315225929021835\n",
      "epoch : 20, loss : 0.12819945315519968\n",
      "epoch : 30, loss : 0.13140330463647842\n",
      "epoch : 40, loss : 0.15163597961266836\n",
      "epoch : 50, loss : 0.161420039832592\n",
      "epoch : 60, loss : 0.15141854186852774\n",
      "epoch : 70, loss : 0.1976399620374044\n",
      "epoch : 80, loss : 0.14155914137760797\n",
      "epoch : 90, loss : 0.1431352992852529\n",
      "epoch : 100, loss : 0.1491796871026357\n",
      "epoch : 110, loss : 0.12461210042238235\n",
      "epoch : 120, loss : 0.13904371857643127\n",
      "epoch : 130, loss : 0.15435154736042023\n",
      "epoch : 140, loss : 0.12693929423888525\n",
      "epoch : 150, loss : 0.1326469679673513\n",
      "epoch : 160, loss : 0.15073647598425546\n",
      "epoch : 170, loss : 0.13901318609714508\n",
      "epoch : 180, loss : 0.11752371986707051\n",
      "epoch : 190, loss : 0.13714458545049033\n",
      "epoch : 200, loss : 0.15521177152792612\n",
      "epoch : 210, loss : 0.1335706263780594\n",
      "epoch : 220, loss : 0.16512931883335114\n",
      "epoch : 230, loss : 0.15255325039227804\n",
      "epoch : 240, loss : 0.17163008451461792\n",
      "epoch : 250, loss : 0.12544378389914831\n",
      "epoch : 260, loss : 0.14478765924771628\n",
      "epoch : 270, loss : 0.14052851249774298\n",
      "epoch : 280, loss : 0.13745866467555365\n",
      "epoch : 290, loss : 0.18364475667476654\n",
      "epoch : 300, loss : 0.18582269052664438\n",
      "epoch : 310, loss : 0.14840390781561533\n",
      "epoch : 320, loss : 0.15032820155223212\n",
      "epoch : 330, loss : 0.14835420747598013\n",
      "epoch : 340, loss : 0.12943709393342337\n",
      "epoch : 350, loss : 0.1327697013815244\n",
      "Eearly Stopping Process...\n",
      "현재 epoch : 355, best loss : 0.11583940933148067, 현재 loss : 0.1665946990251541\n"
     ]
    }
   ],
   "source": [
    "# 1,000회에 걸쳐 모델을 학습합니다\n",
    "n_epochs = 1000\n",
    "patience = 50      # Eearly Stopping patient num\n",
    "before_loss = 100 # before loss 초기화\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    # 모델을 학습시킵니다.\n",
    "    loss = train(model, criterion, optimizer, loader)\n",
    "    # 10 에포크마다 오차를 출력합니다\n",
    "    if epoch % 10 == 0 :\n",
    "        print(f\"epoch : {epoch}, loss : {loss}\")\n",
    "    \n",
    "    if epoch > 0.3 * n_epochs :\n",
    "\n",
    "        if loss <= before_loss :\n",
    "            before_loss = loss\n",
    "        else :\n",
    "            patience -= 1\n",
    "\n",
    "        if patience == 0 :\n",
    "            print(\"Eearly Stopping Process...\")\n",
    "            print(f\"현재 epoch : {epoch}, best loss : {before_loss}, 현재 loss : {loss}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891dc68",
   "metadata": {},
   "source": [
    "# STEP 04. Simple 004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c42f73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y).view(-1,1)\n",
    "\n",
    "X = (X - torch.mean(X)) / torch.std(X)\n",
    "\n",
    "dset = TensorDataset(X, y)\n",
    "loader = DataLoader(dset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bb3c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n개의 값을 입력받는 신경맘 모델 클래스 정의\n",
    "class NeuralNetwork(nn.Module) :\n",
    "    def __init__(self, num_features) :\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_features, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        out = self.linear1(X)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba73d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(30)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aacfa589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader) :\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader :\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caec6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, loss : 0.5627442797025045\n",
      "epoch : 20, loss : 0.36279649535814923\n",
      "epoch : 30, loss : 0.2738478481769562\n",
      "epoch : 40, loss : 0.22603384653727213\n",
      "epoch : 50, loss : 0.21633872389793396\n",
      "epoch : 60, loss : 0.20620746413866678\n",
      "epoch : 70, loss : 0.22633328040440878\n",
      "epoch : 80, loss : 0.1817046453555425\n",
      "epoch : 90, loss : 0.20741680761178335\n",
      "epoch : 100, loss : 0.18252301216125488\n",
      "epoch : 110, loss : 0.19120151301225027\n",
      "epoch : 120, loss : 0.17650902271270752\n",
      "epoch : 130, loss : 0.18859981497128805\n",
      "epoch : 140, loss : 0.16810965041319528\n",
      "epoch : 150, loss : 0.20443023244539896\n",
      "epoch : 160, loss : 0.1726884295543035\n",
      "epoch : 170, loss : 0.17630979915459952\n",
      "epoch : 180, loss : 0.17115322748819986\n",
      "epoch : 190, loss : 0.1819175879160563\n",
      "epoch : 200, loss : 0.17606008549531302\n",
      "epoch : 210, loss : 0.16847515602906546\n",
      "epoch : 220, loss : 0.1642550230026245\n",
      "epoch : 230, loss : 0.16060688843329748\n",
      "epoch : 240, loss : 0.164187952876091\n",
      "epoch : 250, loss : 0.16276825467745462\n",
      "epoch : 260, loss : 0.1771649867296219\n",
      "epoch : 270, loss : 0.1793379783630371\n",
      "epoch : 280, loss : 0.16580955187479654\n",
      "epoch : 290, loss : 0.16357644399007162\n",
      "epoch : 300, loss : 0.16482923924922943\n",
      "epoch : 310, loss : 0.16729220747947693\n",
      "epoch : 320, loss : 0.1672640691200892\n",
      "epoch : 330, loss : 0.19049751261870065\n",
      "epoch : 340, loss : 0.1665955533583959\n",
      "epoch : 350, loss : 0.1542439783612887\n",
      "Eearly Stopping Process...\n",
      "현재 epoch : 354, best loss : 0.1469378024339676, 현재 loss : 0.1766022046407064\n"
     ]
    }
   ],
   "source": [
    "# 1,000회에 걸쳐 모델을 학습합니다\n",
    "n_epochs = 1000\n",
    "patience = 50      # Eearly Stopping patient num\n",
    "before_loss = 100 # before loss 초기화\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    # 모델을 학습시킵니다.\n",
    "    loss = train(model, criterion, optimizer, loader)\n",
    "    # 10 에포크마다 오차를 출력합니다\n",
    "    if epoch % 10 == 0 :\n",
    "        print(f\"epoch : {epoch}, loss : {loss}\")\n",
    "    \n",
    "    if epoch > 0.3 * n_epochs :\n",
    "\n",
    "        if loss <= before_loss :\n",
    "            before_loss = loss\n",
    "        else :\n",
    "            patience -= 1\n",
    "\n",
    "        if patience == 0 :\n",
    "            print(\"Eearly Stopping Process...\")\n",
    "            print(f\"현재 epoch : {epoch}, best loss : {before_loss}, 현재 loss : {loss}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58946b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9297012090682983\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델을 사용해 결과를 추론합니다\n",
    "y_predicted = (model(X) >= 0.5)\n",
    "\n",
    "# 정확도를 계산하고 출력합니다\n",
    "score = (y_predicted == y).float().mean()\n",
    "print(f\"accuracy : {score}\")\n",
    "\n",
    "# 현재 경로에 trained_model.pt라는 이름으로 학습된 모델을 저장\n",
    "torch.save(model.state_dict(), './trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f2fb60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9297012090682983\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델의 객체를 새로 생성합니다\n",
    "loaded_model = NeuralNetwork(30)\n",
    "\n",
    "# 저장한 파일에서 가중치를 불러와 복원합니다\n",
    "loaded_model.load_state_dict(torch.load('./trained_model.pt'))\n",
    "\n",
    "# 불러온 모델을 사용해 결과를 추론합니다\n",
    "# 학습된 모델을 사용해 결과를 추론합니다\n",
    "y_predicted2 = (loaded_model(X) >= 0.5)\n",
    "\n",
    "# 정확도를 계산하고 출력합니다\n",
    "score = (y_predicted2 == y).float().mean()\n",
    "print(f\"accuracy : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b29a7d",
   "metadata": {},
   "source": [
    "# STEP 05. Intermediate 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5450ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml'...\n",
      "tar: Error opening archive: Failed to open '/.ml/datasets/MNIST.tar.gz'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001b41dc6ac54e15ae8248a299637f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4402d9318bc24fde89261988d403bbb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10a5bd7fee94ed7b33ac51fda188e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609f9e958a0c47079b8bea8a4b40a9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# github에서 MNIST dataset 다운로드\n",
    "!git clone https://github.com/baek2sm/ml.git\n",
    "!tar -zxvf /.ml/datasets/MNIST.tar.gz\n",
    "\n",
    "# 현재 경로에 MNIST 학습 세트와 테스트 세트를 불러옵니다\n",
    "path = \"./\"\n",
    "train_dataset = datasets.MNIST(path, train=True, download=True)\n",
    "test_dataset = datasets.MNIST(path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff70706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 입력 데이터: torch.Size([60000, 28, 28])\n",
      "학습 세트 타깃: torch.Size([60000])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 28, 28])\n",
      "테스트 세트 타깃: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 학습 세트와 테스트 세트의 입력 데이터와 타깃을 준비\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets\n",
    "\n",
    "# 학습 세트와 테스트 세트의 데이터 형태를 확인\n",
    "print(\"학습 세트 입력 데이터:\", X_train.shape)\n",
    "print(\"학습 세트 타깃:\", y_train.shape)\n",
    "print(\"테스트 세트 입력 데이터:\", X_test.shape)\n",
    "print(\"테스트 세트 타깃:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94048b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 입력 데이터: torch.Size([60000, 784])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열을 1차원 배열로 변환합니다\n",
    "X_train, X_test = X_train.view(-1, 28*28), X_test.view(-1, 28*28)\n",
    "\n",
    "print(\"학습 세트 입력 데이터:\", X_train.shape)\n",
    "print(\"테스트 세트 입력 데이터:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56edd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 타깃을 묶어 텐서 데이터세트를 생성\n",
    "train_dset = TensorDataset(X_train, y_train)\n",
    "test_dset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# 한 번에 128개의 데이터 샘플을 배치로 사용하는 데이터로더를 생성\n",
    "train_loader = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91f5f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module) :\n",
    "    def __init__(self, num_features) :\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        out = self.hidden_layer1(X)\n",
    "        out = self.hidden_layer2(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd25fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# 784개의 값을 입력받는 DNN 모델 객체를 생성\n",
    "model = DNN(784).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6e3a1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader :\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 정확도를 계산\n",
    "        y_predicted = torch.argmax(hypothesis, 1)\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "        \n",
    "        # 현재 배치의 오차와 정확도를 저장\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a229beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수를 정의합니다 - 학습 함수에서 부분적 재사용\n",
    "def evaluate(model, criterion, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in loader :\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # 정확도를 계산\n",
    "        y_predicted = torch.argmax(hypothesis, 1)\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "        \n",
    "        # 현재 배치의 오차와 정확도를 저장\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7183f38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:0.0005, acc:1.0000, val_loss:0.1004, val_acc:0.9795\n",
      "epoch:2, loss:0.0005, acc:1.0000, val_loss:0.1008, val_acc:0.9793\n",
      "epoch:3, loss:0.0004, acc:1.0000, val_loss:0.1028, val_acc:0.9790\n",
      "epoch:4, loss:0.0004, acc:1.0000, val_loss:0.1029, val_acc:0.9798\n",
      "epoch:5, loss:0.0004, acc:1.0000, val_loss:0.1027, val_acc:0.9796\n",
      "epoch:6, loss:0.0004, acc:1.0000, val_loss:0.1070, val_acc:0.9794\n",
      "epoch:7, loss:0.0003, acc:1.0000, val_loss:0.1061, val_acc:0.9794\n",
      "epoch:8, loss:0.0003, acc:1.0000, val_loss:0.1043, val_acc:0.9798\n",
      "epoch:9, loss:0.0003, acc:1.0000, val_loss:0.1059, val_acc:0.9798\n",
      "epoch:10, loss:0.0003, acc:1.0000, val_loss:0.1068, val_acc:0.9800\n",
      "epoch:11, loss:0.0003, acc:1.0000, val_loss:0.1089, val_acc:0.9795\n",
      "epoch:12, loss:0.0002, acc:1.0000, val_loss:0.1115, val_acc:0.9797\n",
      "epoch:13, loss:0.0002, acc:1.0000, val_loss:0.1092, val_acc:0.9792\n",
      "epoch:14, loss:0.0002, acc:1.0000, val_loss:0.1114, val_acc:0.9793\n",
      "epoch:15, loss:0.0002, acc:1.0000, val_loss:0.1135, val_acc:0.9794\n",
      "epoch:16, loss:0.0002, acc:1.0000, val_loss:0.1128, val_acc:0.9788\n",
      "epoch:17, loss:0.0002, acc:1.0000, val_loss:0.1142, val_acc:0.9798\n",
      "epoch:18, loss:0.0002, acc:1.0000, val_loss:0.1143, val_acc:0.9801\n",
      "epoch:19, loss:0.0001, acc:1.0000, val_loss:0.1168, val_acc:0.9799\n",
      "epoch:20, loss:0.0001, acc:1.0000, val_loss:0.1174, val_acc:0.9793\n",
      "epoch:21, loss:0.0003, acc:0.9999, val_loss:0.1353, val_acc:0.9769\n",
      "epoch:22, loss:0.0019, acc:0.9995, val_loss:0.1149, val_acc:0.9797\n",
      "epoch:23, loss:0.0002, acc:1.0000, val_loss:0.1149, val_acc:0.9799\n",
      "epoch:24, loss:0.0001, acc:1.0000, val_loss:0.1156, val_acc:0.9796\n",
      "epoch:25, loss:0.0001, acc:1.0000, val_loss:0.1158, val_acc:0.9800\n",
      "epoch:26, loss:0.0001, acc:1.0000, val_loss:0.1155, val_acc:0.9797\n",
      "epoch:27, loss:0.0001, acc:1.0000, val_loss:0.1162, val_acc:0.9796\n",
      "epoch:28, loss:0.0001, acc:1.0000, val_loss:0.1167, val_acc:0.9799\n",
      "epoch:29, loss:0.0001, acc:1.0000, val_loss:0.1168, val_acc:0.9799\n",
      "epoch:30, loss:0.0001, acc:1.0000, val_loss:0.1172, val_acc:0.9798\n",
      "epoch:31, loss:0.0001, acc:1.0000, val_loss:0.1176, val_acc:0.9800\n",
      "epoch:32, loss:0.0001, acc:1.0000, val_loss:0.1179, val_acc:0.9799\n",
      "epoch:33, loss:0.0001, acc:1.0000, val_loss:0.1185, val_acc:0.9800\n",
      "epoch:34, loss:0.0001, acc:1.0000, val_loss:0.1186, val_acc:0.9798\n",
      "epoch:35, loss:0.0001, acc:1.0000, val_loss:0.1198, val_acc:0.9796\n",
      "epoch:36, loss:0.0001, acc:1.0000, val_loss:0.1204, val_acc:0.9797\n",
      "epoch:37, loss:0.0001, acc:1.0000, val_loss:0.1201, val_acc:0.9798\n",
      "epoch:38, loss:0.0001, acc:1.0000, val_loss:0.1209, val_acc:0.9796\n",
      "epoch:39, loss:0.0001, acc:1.0000, val_loss:0.1219, val_acc:0.9796\n",
      "epoch:40, loss:0.0001, acc:1.0000, val_loss:0.1222, val_acc:0.9798\n",
      "epoch:41, loss:0.0001, acc:1.0000, val_loss:0.1233, val_acc:0.9796\n",
      "epoch:42, loss:0.0001, acc:1.0000, val_loss:0.1233, val_acc:0.9798\n",
      "epoch:43, loss:0.0001, acc:1.0000, val_loss:0.1231, val_acc:0.9799\n",
      "epoch:44, loss:0.0001, acc:1.0000, val_loss:0.1237, val_acc:0.9799\n",
      "epoch:45, loss:0.0000, acc:1.0000, val_loss:0.1253, val_acc:0.9799\n",
      "epoch:46, loss:0.0001, acc:1.0000, val_loss:0.1294, val_acc:0.9792\n",
      "epoch:47, loss:0.0023, acc:0.9993, val_loss:0.1327, val_acc:0.9783\n",
      "epoch:48, loss:0.0002, acc:1.0000, val_loss:0.1257, val_acc:0.9792\n",
      "epoch:49, loss:0.0001, acc:1.0000, val_loss:0.1250, val_acc:0.9791\n",
      "epoch:50, loss:0.0001, acc:1.0000, val_loss:0.1251, val_acc:0.9799\n",
      "epoch:51, loss:0.0001, acc:1.0000, val_loss:0.1248, val_acc:0.9798\n",
      "epoch:52, loss:0.0001, acc:1.0000, val_loss:0.1251, val_acc:0.9799\n",
      "epoch:53, loss:0.0001, acc:1.0000, val_loss:0.1249, val_acc:0.9799\n",
      "epoch:54, loss:0.0001, acc:1.0000, val_loss:0.1253, val_acc:0.9800\n",
      "epoch:55, loss:0.0001, acc:1.0000, val_loss:0.1251, val_acc:0.9801\n",
      "epoch:56, loss:0.0000, acc:1.0000, val_loss:0.1253, val_acc:0.9804\n",
      "epoch:57, loss:0.0000, acc:1.0000, val_loss:0.1259, val_acc:0.9799\n",
      "epoch:58, loss:0.0000, acc:1.0000, val_loss:0.1259, val_acc:0.9798\n",
      "epoch:59, loss:0.0000, acc:1.0000, val_loss:0.1264, val_acc:0.9802\n",
      "epoch:60, loss:0.0000, acc:1.0000, val_loss:0.1262, val_acc:0.9801\n",
      "epoch:61, loss:0.0000, acc:1.0000, val_loss:0.1270, val_acc:0.9800\n",
      "epoch:62, loss:0.0000, acc:1.0000, val_loss:0.1273, val_acc:0.9799\n",
      "epoch:63, loss:0.0000, acc:1.0000, val_loss:0.1276, val_acc:0.9798\n",
      "epoch:64, loss:0.0000, acc:1.0000, val_loss:0.1284, val_acc:0.9798\n",
      "epoch:65, loss:0.0000, acc:1.0000, val_loss:0.1285, val_acc:0.9801\n",
      "epoch:66, loss:0.0000, acc:1.0000, val_loss:0.1293, val_acc:0.9796\n",
      "epoch:67, loss:0.0000, acc:1.0000, val_loss:0.1295, val_acc:0.9798\n",
      "epoch:68, loss:0.0000, acc:1.0000, val_loss:0.1306, val_acc:0.9801\n",
      "epoch:69, loss:0.0000, acc:1.0000, val_loss:0.1303, val_acc:0.9797\n",
      "epoch:70, loss:0.0000, acc:1.0000, val_loss:0.1309, val_acc:0.9800\n",
      "epoch:71, loss:0.0000, acc:1.0000, val_loss:0.1316, val_acc:0.9803\n",
      "epoch:72, loss:0.0000, acc:1.0000, val_loss:0.1315, val_acc:0.9801\n",
      "epoch:73, loss:0.0000, acc:1.0000, val_loss:0.1325, val_acc:0.9797\n",
      "epoch:74, loss:0.0000, acc:1.0000, val_loss:0.1331, val_acc:0.9798\n",
      "epoch:75, loss:0.0000, acc:1.0000, val_loss:0.1336, val_acc:0.9801\n",
      "epoch:76, loss:0.0000, acc:1.0000, val_loss:0.1345, val_acc:0.9803\n",
      "epoch:77, loss:0.0000, acc:1.0000, val_loss:0.1340, val_acc:0.9799\n",
      "epoch:78, loss:0.0000, acc:1.0000, val_loss:0.1358, val_acc:0.9800\n",
      "epoch:79, loss:0.0000, acc:1.0000, val_loss:0.1364, val_acc:0.9797\n",
      "epoch:80, loss:0.0001, acc:1.0000, val_loss:0.1581, val_acc:0.9770\n",
      "epoch:81, loss:0.0021, acc:0.9994, val_loss:0.1440, val_acc:0.9785\n",
      "epoch:82, loss:0.0001, acc:1.0000, val_loss:0.1411, val_acc:0.9791\n",
      "epoch:83, loss:0.0000, acc:1.0000, val_loss:0.1401, val_acc:0.9793\n",
      "epoch:84, loss:0.0000, acc:1.0000, val_loss:0.1395, val_acc:0.9795\n",
      "epoch:85, loss:0.0000, acc:1.0000, val_loss:0.1394, val_acc:0.9795\n",
      "epoch:86, loss:0.0000, acc:1.0000, val_loss:0.1391, val_acc:0.9793\n",
      "epoch:87, loss:0.0000, acc:1.0000, val_loss:0.1388, val_acc:0.9794\n",
      "epoch:88, loss:0.0000, acc:1.0000, val_loss:0.1391, val_acc:0.9795\n",
      "epoch:89, loss:0.0000, acc:1.0000, val_loss:0.1389, val_acc:0.9793\n",
      "epoch:90, loss:0.0000, acc:1.0000, val_loss:0.1389, val_acc:0.9795\n",
      "epoch:91, loss:0.0000, acc:1.0000, val_loss:0.1388, val_acc:0.9796\n",
      "epoch:92, loss:0.0000, acc:1.0000, val_loss:0.1391, val_acc:0.9794\n",
      "epoch:93, loss:0.0000, acc:1.0000, val_loss:0.1392, val_acc:0.9793\n",
      "epoch:94, loss:0.0000, acc:1.0000, val_loss:0.1391, val_acc:0.9796\n",
      "epoch:95, loss:0.0000, acc:1.0000, val_loss:0.1393, val_acc:0.9797\n",
      "epoch:96, loss:0.0000, acc:1.0000, val_loss:0.1391, val_acc:0.9797\n",
      "epoch:97, loss:0.0000, acc:1.0000, val_loss:0.1397, val_acc:0.9793\n",
      "epoch:98, loss:0.0000, acc:1.0000, val_loss:0.1399, val_acc:0.9795\n",
      "epoch:99, loss:0.0000, acc:1.0000, val_loss:0.1397, val_acc:0.9794\n",
      "epoch:100, loss:0.0000, acc:1.0000, val_loss:0.1398, val_acc:0.9798\n"
     ]
    }
   ],
   "source": [
    "# 100회에 걸쳐 모델을 학습\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    \n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    # 현재 에포크의 학습 결과를 출력\n",
    "    print(f\"epoch:{epoch}, loss:{loss:.4f}, acc:{acc:.4f}, val_loss:{test_loss:.4f}, val_acc:{test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718020cb",
   "metadata": {},
   "source": [
    "# STEP 06. Intermediate 002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "387d47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 입력 데이터: torch.Size([60000, 28, 28])\n",
      "학습 세트 타깃: torch.Size([60000])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 28, 28])\n",
      "테스트 세트 타깃: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 학습 세트와 테스트 세트의 입력 데이터와 타깃을 준비\n",
    "X_train, y_train = train_dataset.data / 255, train_dataset.targets\n",
    "X_test, y_test = test_dataset.data / 255, test_dataset.targets\n",
    "\n",
    "# 학습 세트와 테스트 세트의 데이터 형태를 확인\n",
    "print(\"학습 세트 입력 데이터:\", X_train.shape)\n",
    "print(\"학습 세트 타깃:\", y_train.shape)\n",
    "print(\"테스트 세트 입력 데이터:\", X_test.shape)\n",
    "print(\"테스트 세트 타깃:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b7b2693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 입력 데이터: torch.Size([60000, 1, 28, 28])\n",
      "테스트 세트 입력 데이터: torch.Size([10000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 2차원(높이, 너비) 형태인 이미지 데이터를 3차원(채널, 높이, 너비) 형태로 변환\n",
    "X_train, X_test = X_train.unsqueeze(1), X_test.unsqueeze(1)\n",
    "\n",
    "print(\"학습 세트 입력 데이터:\", X_train.shape)\n",
    "print(\"테스트 세트 입력 데이터:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fed035b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터와 타깃을 묶어 텐서 데이터세트를 생성\n",
    "train_dset = TensorDataset(X_train, y_train)\n",
    "test_dset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# 한 번에 128개의 데이터 샘플을 배치로 사용하는 데이터로더를 생성\n",
    "train_loader = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3cb9b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)), \n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.Dropout(0.5))\n",
    "        \n",
    "        self.hidden_layer3 = nn.Linear(128*5*5, 128)\n",
    "        \n",
    "        self.output_layer = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        out = self.hidden_layer1(X)\n",
    "        out = self.hidden_layer2(out)\n",
    "        \n",
    "        out = out.view(out.shape[0], -1) # 전결합층을 사용하기 위해 1차원 배열 형태로 변환\n",
    "        out = self.hidden_layer3(out)\n",
    "        \n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b3ebc35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# 784개의 값을 입력받는 DNN 모델 객체를 생성\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6defd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss:0.9098, acc:0.7472, val_loss:0.3893, val_acc:0.8794\n",
      "epoch:2, loss:0.3278, acc:0.9014, val_loss:0.2449, val_acc:0.9271\n",
      "epoch:3, loss:0.2257, acc:0.9326, val_loss:0.1743, val_acc:0.9482\n",
      "epoch:4, loss:0.1731, acc:0.9488, val_loss:0.1384, val_acc:0.9581\n",
      "epoch:5, loss:0.1443, acc:0.9567, val_loss:0.1150, val_acc:0.9651\n",
      "epoch:6, loss:0.1268, acc:0.9623, val_loss:0.1032, val_acc:0.9707\n",
      "epoch:7, loss:0.1149, acc:0.9649, val_loss:0.0927, val_acc:0.9721\n",
      "epoch:8, loss:0.1054, acc:0.9692, val_loss:0.0915, val_acc:0.9718\n",
      "epoch:9, loss:0.0984, acc:0.9701, val_loss:0.0834, val_acc:0.9743\n",
      "epoch:10, loss:0.0911, acc:0.9733, val_loss:0.0782, val_acc:0.9759\n",
      "epoch:11, loss:0.0868, acc:0.9728, val_loss:0.0706, val_acc:0.9771\n",
      "epoch:12, loss:0.0830, acc:0.9745, val_loss:0.0711, val_acc:0.9765\n",
      "epoch:13, loss:0.0800, acc:0.9760, val_loss:0.0673, val_acc:0.9785\n",
      "epoch:14, loss:0.0757, acc:0.9777, val_loss:0.0662, val_acc:0.9776\n",
      "epoch:15, loss:0.0728, acc:0.9772, val_loss:0.0651, val_acc:0.9781\n",
      "epoch:16, loss:0.0700, acc:0.9785, val_loss:0.0629, val_acc:0.9791\n",
      "epoch:17, loss:0.0676, acc:0.9785, val_loss:0.0589, val_acc:0.9813\n",
      "epoch:18, loss:0.0657, acc:0.9800, val_loss:0.0581, val_acc:0.9810\n",
      "epoch:19, loss:0.0624, acc:0.9803, val_loss:0.0558, val_acc:0.9825\n",
      "epoch:20, loss:0.0622, acc:0.9808, val_loss:0.0562, val_acc:0.9817\n",
      "epoch:21, loss:0.0591, acc:0.9823, val_loss:0.0553, val_acc:0.9818\n",
      "epoch:22, loss:0.0590, acc:0.9815, val_loss:0.0591, val_acc:0.9823\n",
      "epoch:23, loss:0.0573, acc:0.9821, val_loss:0.0511, val_acc:0.9835\n",
      "epoch:24, loss:0.0567, acc:0.9823, val_loss:0.0514, val_acc:0.9841\n",
      "epoch:25, loss:0.0551, acc:0.9831, val_loss:0.0506, val_acc:0.9842\n",
      "epoch:26, loss:0.0527, acc:0.9838, val_loss:0.0467, val_acc:0.9844\n",
      "epoch:27, loss:0.0530, acc:0.9837, val_loss:0.0493, val_acc:0.9829\n",
      "epoch:28, loss:0.0492, acc:0.9844, val_loss:0.0502, val_acc:0.9831\n",
      "epoch:29, loss:0.0488, acc:0.9849, val_loss:0.0512, val_acc:0.9825\n",
      "epoch:30, loss:0.0487, acc:0.9845, val_loss:0.0508, val_acc:0.9838\n",
      "epoch:31, loss:0.0474, acc:0.9854, val_loss:0.0471, val_acc:0.9844\n",
      "epoch:32, loss:0.0465, acc:0.9853, val_loss:0.0477, val_acc:0.9843\n",
      "epoch:33, loss:0.0460, acc:0.9854, val_loss:0.0472, val_acc:0.9851\n",
      "epoch:34, loss:0.0458, acc:0.9860, val_loss:0.0449, val_acc:0.9848\n",
      "epoch:35, loss:0.0451, acc:0.9861, val_loss:0.0454, val_acc:0.9850\n",
      "epoch:36, loss:0.0430, acc:0.9866, val_loss:0.0453, val_acc:0.9854\n",
      "epoch:37, loss:0.0440, acc:0.9859, val_loss:0.0469, val_acc:0.9847\n",
      "epoch:38, loss:0.0433, acc:0.9865, val_loss:0.0427, val_acc:0.9850\n",
      "epoch:39, loss:0.0400, acc:0.9874, val_loss:0.0448, val_acc:0.9852\n",
      "epoch:40, loss:0.0394, acc:0.9877, val_loss:0.0420, val_acc:0.9860\n",
      "epoch:41, loss:0.0396, acc:0.9877, val_loss:0.0435, val_acc:0.9861\n",
      "epoch:42, loss:0.0402, acc:0.9871, val_loss:0.0433, val_acc:0.9860\n",
      "epoch:43, loss:0.0394, acc:0.9871, val_loss:0.0420, val_acc:0.9850\n",
      "epoch:44, loss:0.0390, acc:0.9878, val_loss:0.0421, val_acc:0.9867\n",
      "epoch:45, loss:0.0376, acc:0.9884, val_loss:0.0436, val_acc:0.9860\n",
      "epoch:46, loss:0.0380, acc:0.9883, val_loss:0.0423, val_acc:0.9852\n",
      "epoch:47, loss:0.0373, acc:0.9883, val_loss:0.0382, val_acc:0.9861\n",
      "epoch:48, loss:0.0354, acc:0.9884, val_loss:0.0398, val_acc:0.9871\n",
      "epoch:49, loss:0.0372, acc:0.9882, val_loss:0.0413, val_acc:0.9857\n",
      "epoch:50, loss:0.0345, acc:0.9893, val_loss:0.0391, val_acc:0.9867\n",
      "epoch:51, loss:0.0349, acc:0.9887, val_loss:0.0419, val_acc:0.9865\n",
      "epoch:52, loss:0.0347, acc:0.9889, val_loss:0.0417, val_acc:0.9858\n",
      "epoch:53, loss:0.0343, acc:0.9892, val_loss:0.0409, val_acc:0.9869\n",
      "epoch:54, loss:0.0339, acc:0.9889, val_loss:0.0422, val_acc:0.9869\n",
      "epoch:55, loss:0.0343, acc:0.9890, val_loss:0.0406, val_acc:0.9870\n",
      "epoch:56, loss:0.0338, acc:0.9889, val_loss:0.0410, val_acc:0.9860\n",
      "epoch:57, loss:0.0332, acc:0.9892, val_loss:0.0398, val_acc:0.9879\n",
      "epoch:58, loss:0.0309, acc:0.9896, val_loss:0.0397, val_acc:0.9866\n",
      "epoch:59, loss:0.0316, acc:0.9897, val_loss:0.0382, val_acc:0.9876\n",
      "epoch:60, loss:0.0305, acc:0.9901, val_loss:0.0387, val_acc:0.9876\n",
      "epoch:61, loss:0.0324, acc:0.9895, val_loss:0.0410, val_acc:0.9875\n",
      "epoch:62, loss:0.0321, acc:0.9897, val_loss:0.0393, val_acc:0.9869\n",
      "epoch:63, loss:0.0305, acc:0.9902, val_loss:0.0354, val_acc:0.9888\n",
      "epoch:64, loss:0.0313, acc:0.9898, val_loss:0.0388, val_acc:0.9878\n",
      "epoch:65, loss:0.0311, acc:0.9903, val_loss:0.0353, val_acc:0.9873\n",
      "epoch:66, loss:0.0301, acc:0.9897, val_loss:0.0423, val_acc:0.9869\n",
      "epoch:67, loss:0.0295, acc:0.9902, val_loss:0.0395, val_acc:0.9867\n",
      "epoch:68, loss:0.0275, acc:0.9911, val_loss:0.0398, val_acc:0.9864\n",
      "epoch:69, loss:0.0301, acc:0.9900, val_loss:0.0384, val_acc:0.9885\n",
      "epoch:70, loss:0.0286, acc:0.9912, val_loss:0.0383, val_acc:0.9884\n",
      "epoch:71, loss:0.0290, acc:0.9904, val_loss:0.0388, val_acc:0.9869\n",
      "epoch:72, loss:0.0274, acc:0.9914, val_loss:0.0342, val_acc:0.9891\n",
      "epoch:73, loss:0.0273, acc:0.9912, val_loss:0.0390, val_acc:0.9872\n",
      "epoch:74, loss:0.0267, acc:0.9913, val_loss:0.0362, val_acc:0.9893\n",
      "epoch:75, loss:0.0269, acc:0.9912, val_loss:0.0366, val_acc:0.9889\n",
      "epoch:76, loss:0.0263, acc:0.9917, val_loss:0.0381, val_acc:0.9881\n",
      "epoch:77, loss:0.0272, acc:0.9910, val_loss:0.0367, val_acc:0.9883\n",
      "epoch:78, loss:0.0264, acc:0.9914, val_loss:0.0380, val_acc:0.9885\n",
      "epoch:79, loss:0.0279, acc:0.9906, val_loss:0.0370, val_acc:0.9884\n",
      "epoch:80, loss:0.0265, acc:0.9913, val_loss:0.0386, val_acc:0.9894\n",
      "epoch:81, loss:0.0262, acc:0.9915, val_loss:0.0387, val_acc:0.9880\n",
      "epoch:82, loss:0.0252, acc:0.9919, val_loss:0.0357, val_acc:0.9887\n",
      "epoch:83, loss:0.0251, acc:0.9920, val_loss:0.0384, val_acc:0.9884\n",
      "epoch:84, loss:0.0249, acc:0.9917, val_loss:0.0365, val_acc:0.9890\n",
      "epoch:85, loss:0.0261, acc:0.9919, val_loss:0.0356, val_acc:0.9892\n",
      "epoch:86, loss:0.0240, acc:0.9921, val_loss:0.0375, val_acc:0.9884\n",
      "epoch:87, loss:0.0247, acc:0.9920, val_loss:0.0393, val_acc:0.9877\n",
      "epoch:88, loss:0.0256, acc:0.9913, val_loss:0.0325, val_acc:0.9897\n",
      "epoch:89, loss:0.0243, acc:0.9925, val_loss:0.0358, val_acc:0.9872\n",
      "epoch:90, loss:0.0246, acc:0.9919, val_loss:0.0390, val_acc:0.9884\n",
      "epoch:91, loss:0.0228, acc:0.9920, val_loss:0.0360, val_acc:0.9887\n",
      "epoch:92, loss:0.0237, acc:0.9926, val_loss:0.0379, val_acc:0.9881\n",
      "epoch:93, loss:0.0237, acc:0.9919, val_loss:0.0340, val_acc:0.9879\n",
      "epoch:94, loss:0.0222, acc:0.9926, val_loss:0.0370, val_acc:0.9871\n",
      "epoch:95, loss:0.0228, acc:0.9924, val_loss:0.0352, val_acc:0.9879\n",
      "epoch:96, loss:0.0219, acc:0.9928, val_loss:0.0341, val_acc:0.9894\n",
      "epoch:97, loss:0.0228, acc:0.9923, val_loss:0.0330, val_acc:0.9890\n",
      "epoch:98, loss:0.0222, acc:0.9925, val_loss:0.0351, val_acc:0.9888\n",
      "epoch:99, loss:0.0228, acc:0.9923, val_loss:0.0422, val_acc:0.9864\n",
      "epoch:100, loss:0.0223, acc:0.9926, val_loss:0.0371, val_acc:0.9885\n"
     ]
    }
   ],
   "source": [
    "# 100회에 걸쳐 모델을 학습\n",
    "n_epochs = 100\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    \n",
    "    test_loss, test_acc = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    # 현재 에포크의 학습 결과를 출력\n",
    "    print(f\"epoch:{epoch}, loss:{loss:.4f}, acc:{acc:.4f}, val_loss:{test_loss:.4f}, val_acc:{test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08da56",
   "metadata": {},
   "source": [
    "# STEP 07. Higher 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7024b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-11-22 13:49:06--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 34.64.4.16, 34.64.4.80, 34.64.4.48, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|34.64.4.16|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: 'cats_and_dogs_filtered.zip.1'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 2.74M 24s\n",
      "    50K .......... .......... .......... .......... ..........  0% 6.29M 17s\n",
      "   100K .......... .......... .......... .......... ..........  0% 3.34M 18s\n",
      "   150K .......... .......... .......... .......... ..........  0% 2.38M 20s\n",
      "   200K .......... .......... .......... .......... ..........  0% 34.9M 17s\n",
      "   250K .......... .......... .......... .......... ..........  0% 2.55M 18s\n",
      "   300K .......... .......... .......... .......... ..........  0% 6.25M 17s\n",
      "   350K .......... .......... .......... .......... ..........  0% 34.0M 15s\n",
      "   400K .......... .......... .......... .......... ..........  0% 33.2M 14s\n",
      "   450K .......... .......... .......... .......... ..........  0% 3.07M 14s\n",
      "   500K .......... .......... .......... .......... ..........  0% 14.2M 13s\n",
      "   550K .......... .......... .......... .......... ..........  0% 16.5M 13s\n",
      "   600K .......... .......... .......... .......... ..........  0% 8.12M 12s\n",
      "   650K .......... .......... .......... .......... ..........  1% 8.99M 12s\n",
      "   700K .......... .......... .......... .......... ..........  1% 5.23M 12s\n",
      "   750K .......... .......... .......... .......... ..........  1% 1.75M 13s\n",
      "   800K .......... .......... .......... .......... ..........  1% 32.2M 13s\n",
      "   850K .......... .......... .......... .......... ..........  1% 29.3M 12s\n",
      "   900K .......... .......... .......... .......... ..........  1% 41.4M 12s\n",
      "   950K .......... .......... .......... .......... ..........  1% 28.7M 11s\n",
      "  1000K .......... .......... .......... .......... ..........  1% 2.70M 12s\n",
      "  1050K .......... .......... .......... .......... ..........  1% 82.7M 11s\n",
      "  1100K .......... .......... .......... .......... ..........  1%  101M 11s\n",
      "  1150K .......... .......... .......... .......... ..........  1%  184M 10s\n",
      "  1200K .......... .......... .......... .......... ..........  1% 3.78M 11s\n",
      "  1250K .......... .......... .......... .......... ..........  1% 4.06M 11s\n",
      "  1300K .......... .......... .......... .......... ..........  2% 47.2M 10s\n",
      "  1350K .......... .......... .......... .......... ..........  2%  126M 10s\n",
      "  1400K .......... .......... .......... .......... ..........  2% 2.97M 10s\n",
      "  1450K .......... .......... .......... .......... ..........  2% 68.0M 10s\n",
      "  1500K .......... .......... .......... .......... ..........  2% 65.4M 10s\n",
      "  1550K .......... .......... .......... .......... ..........  2% 20.7M 10s\n",
      "  1600K .......... .......... .......... .......... ..........  2% 26.0M 9s\n",
      "  1650K .......... .......... .......... .......... ..........  2% 5.68M 9s\n",
      "  1700K .......... .......... .......... .......... ..........  2% 3.41M 10s\n",
      "  1750K .......... .......... .......... .......... ..........  2% 86.6M 9s\n",
      "  1800K .......... .......... .......... .......... ..........  2%  102M 9s\n",
      "  1850K .......... .......... .......... .......... ..........  2% 2.49M 10s\n",
      "  1900K .......... .......... .......... .......... ..........  2% 19.2M 9s\n",
      "  1950K .......... .......... .......... .......... ..........  2% 74.1M 9s\n",
      "  2000K .......... .......... .......... .......... ..........  3% 65.8M 9s\n",
      "  2050K .......... .......... .......... .......... ..........  3% 82.6M 9s\n",
      "  2100K .......... .......... .......... .......... ..........  3% 9.45M 9s\n",
      "  2150K .......... .......... .......... .......... ..........  3% 96.2M 9s\n",
      "  2200K .......... .......... .......... .......... ..........  3% 7.51M 9s\n",
      "  2250K .......... .......... .......... .......... ..........  3% 15.7M 8s\n",
      "  2300K .......... .......... .......... .......... ..........  3% 5.33M 9s\n",
      "  2350K .......... .......... .......... .......... ..........  3% 90.4M 8s\n",
      "  2400K .......... .......... .......... .......... ..........  3% 13.9M 8s\n",
      "  2450K .......... .......... .......... .......... ..........  3% 6.75M 8s\n",
      "  2500K .......... .......... .......... .......... ..........  3% 24.2M 8s\n",
      "  2550K .......... .......... .......... .......... ..........  3% 5.53M 8s\n",
      "  2600K .......... .......... .......... .......... ..........  3% 33.3M 8s\n",
      "  2650K .......... .......... .......... .......... ..........  4% 6.28M 8s\n",
      "  2700K .......... .......... .......... .......... ..........  4%  120M 8s\n",
      "  2750K .......... .......... .......... .......... ..........  4% 16.4M 8s\n",
      "  2800K .......... .......... .......... .......... ..........  4% 2.78M 8s\n",
      "  2850K .......... .......... .......... .......... ..........  4% 79.0M 8s\n",
      "  2900K .......... .......... .......... .......... ..........  4%  158M 8s\n",
      "  2950K .......... .......... .......... .......... ..........  4%  155M 8s\n",
      "  3000K .......... .......... .......... .......... ..........  4% 4.12M 8s\n",
      "  3050K .......... .......... .......... .......... ..........  4% 74.4M 8s\n",
      "  3100K .......... .......... .......... .......... ..........  4%  120M 8s\n",
      "  3150K .......... .......... .......... .......... ..........  4% 2.07M 8s\n",
      "  3200K .......... .......... .......... .......... ..........  4% 95.9M 8s\n",
      "  3250K .......... .......... .......... .......... ..........  4%  110M 8s\n",
      "  3300K .......... .......... .......... .......... ..........  5% 2.20M 8s\n",
      "  3350K .......... .......... .......... .......... ..........  5% 9.20M 8s\n",
      "  3400K .......... .......... .......... .......... ..........  5% 1.03M 9s\n",
      "  3450K .......... .......... .......... .......... ..........  5%  207M 9s\n",
      "  3500K .......... .......... .......... .......... ..........  5%  932M 8s\n",
      "  3550K .......... .......... .......... .......... ..........  5%  330M 8s\n",
      "  3600K .......... .......... .......... .......... ..........  5%  999M 8s\n",
      "  3650K .......... .......... .......... .......... ..........  5%  729M 8s\n",
      "  3700K .......... .......... .......... .......... ..........  5% 1.03G 8s\n",
      "  3750K .......... .......... .......... .......... ..........  5%  441M 8s\n",
      "  3800K .......... .......... .......... .......... ..........  5% 2.64M 8s\n",
      "  3850K .......... .......... .......... .......... ..........  5% 3.73M 8s\n",
      "  3900K .......... .......... .......... .......... ..........  5%  118M 8s\n",
      "  3950K .......... .......... .......... .......... ..........  5%  192M 8s\n",
      "  4000K .......... .......... .......... .......... ..........  6% 3.96M 8s\n",
      "  4050K .......... .......... .......... .......... ..........  6%  194M 8s\n",
      "  4100K .......... .......... .......... .......... ..........  6%  568M 8s\n",
      "  4150K .......... .......... .......... .......... ..........  6%  648M 8s\n",
      "  4200K .......... .......... .......... .......... ..........  6% 5.78M 8s\n",
      "  4250K .......... .......... .......... .......... ..........  6%  121M 8s\n",
      "  4300K .......... .......... .......... .......... ..........  6% 11.2M 8s\n",
      "  4350K .......... .......... .......... .......... ..........  6% 10.3M 8s\n",
      "  4400K .......... .......... .......... .......... ..........  6% 6.30M 8s\n",
      "  4450K .......... .......... .......... .......... ..........  6% 79.8M 8s\n",
      "  4500K .......... .......... .......... .......... ..........  6% 19.5M 8s\n",
      "  4550K .......... .......... .......... .......... ..........  6% 4.26M 8s\n",
      "  4600K .......... .......... .......... .......... ..........  6%  104M 8s\n",
      "  4650K .......... .......... .......... .......... ..........  7% 51.4M 7s\n",
      "  4700K .......... .......... .......... .......... ..........  7% 61.8M 7s\n",
      "  4750K .......... .......... .......... .......... ..........  7% 79.0M 7s\n",
      "  4800K .......... .......... .......... .......... ..........  7% 6.45M 7s\n",
      "  4850K .......... .......... .......... .......... ..........  7% 89.4M 7s\n",
      "  4900K .......... .......... .......... .......... ..........  7% 1.82M 8s\n",
      "  4950K .......... .......... .......... .......... ..........  7% 84.2M 7s\n",
      "  5000K .......... .......... .......... .......... ..........  7% 88.9M 7s\n",
      "  5050K .......... .......... .......... .......... ..........  7%  108M 7s\n",
      "  5100K .......... .......... .......... .......... ..........  7% 95.7M 7s\n",
      "  5150K .......... .......... .......... .......... ..........  7%  144M 7s\n",
      "  5200K .......... .......... .......... .......... ..........  7%  172M 7s\n",
      "  5250K .......... .......... .......... .......... ..........  7%  142M 7s\n",
      "  5300K .......... .......... .......... .......... ..........  7%  101M 7s\n",
      "  5350K .......... .......... .......... .......... ..........  8% 55.0M 7s\n",
      "  5400K .......... .......... .......... .......... ..........  8% 17.2M 7s\n",
      "  5450K .......... .......... .......... .......... ..........  8% 15.8M 7s\n",
      "  5500K .......... .......... .......... .......... ..........  8% 15.1M 7s\n",
      "  5550K .......... .......... .......... .......... ..........  8% 3.15M 7s\n",
      "  5600K .......... .......... .......... .......... ..........  8% 75.6M 7s\n",
      "  5650K .......... .......... .......... .......... ..........  8%  109M 7s\n",
      "  5700K .......... .......... .......... .......... ..........  8%  158M 7s\n",
      "  5750K .......... .......... .......... .......... ..........  8%  119M 7s\n",
      "  5800K .......... .......... .......... .......... ..........  8%  154M 7s\n",
      "  5850K .......... .......... .......... .......... ..........  8% 4.69M 7s\n",
      "  5900K .......... .......... .......... .......... ..........  8% 95.3M 7s\n",
      "  5950K .......... .......... .......... .......... ..........  8%  103M 7s\n",
      "  6000K .......... .......... .......... .......... ..........  9% 7.38M 7s\n",
      "  6050K .......... .......... .......... .......... ..........  9% 11.3M 7s\n",
      "  6100K .......... .......... .......... .......... ..........  9% 8.39M 7s\n",
      "  6150K .......... .......... .......... .......... ..........  9% 64.7M 6s\n",
      "  6200K .......... .......... .......... .......... ..........  9% 10.1M 6s\n",
      "  6250K .......... .......... .......... .......... ..........  9% 76.8M 6s\n",
      "  6300K .......... .......... .......... .......... ..........  9% 18.2M 6s\n",
      "  6350K .......... .......... .......... .......... ..........  9%  130M 6s\n",
      "  6400K .......... .......... .......... .......... ..........  9% 4.94M 6s\n",
      "  6450K .......... .......... .......... .......... ..........  9% 82.5M 6s\n",
      "  6500K .......... .......... .......... .......... ..........  9%  114M 6s\n",
      "  6550K .......... .......... .......... .......... ..........  9% 7.28M 6s\n",
      "  6600K .......... .......... .......... .......... ..........  9%  143M 6s\n",
      "  6650K .......... .......... .......... .......... .......... 10%  155M 6s\n",
      "  6700K .......... .......... .......... .......... .......... 10% 7.63M 6s\n",
      "  6750K .......... .......... .......... .......... .......... 10% 64.3M 6s\n",
      "  6800K .......... .......... .......... .......... .......... 10% 78.9M 6s\n",
      "  6850K .......... .......... .......... .......... .......... 10% 21.3M 6s\n",
      "  6900K .......... .......... .......... .......... .......... 10% 6.31M 6s\n",
      "  6950K .......... .......... .......... .......... .......... 10% 77.9M 6s\n",
      "  7000K .......... .......... .......... .......... .......... 10% 15.9M 6s\n",
      "  7050K .......... .......... .......... .......... .......... 10%  165M 6s\n",
      "  7100K .......... .......... .......... .......... .......... 10% 28.1M 6s\n",
      "  7150K .......... .......... .......... .......... .......... 10% 16.9M 6s\n",
      "  7200K .......... .......... .......... .......... .......... 10% 13.1M 6s\n",
      "  7250K .......... .......... .......... .......... .......... 10% 51.6M 6s\n",
      "  7300K .......... .......... .......... .......... .......... 10% 19.9M 6s\n",
      "  7350K .......... .......... .......... .......... .......... 11% 5.83M 6s\n",
      "  7400K .......... .......... .......... .......... .......... 11%  377M 6s\n",
      "  7450K .......... .......... .......... .......... .......... 11%  881M 6s\n",
      "  7500K .......... .......... .......... .......... .......... 11% 5.22M 6s\n",
      "  7550K .......... .......... .......... .......... .......... 11% 95.3M 6s\n",
      "  7600K .......... .......... .......... .......... .......... 11%  132M 6s\n",
      "  7650K .......... .......... .......... .......... .......... 11%  178M 6s\n",
      "  7700K .......... .......... .......... .......... .......... 11% 4.32M 6s\n",
      "  7750K .......... .......... .......... .......... .......... 11%  502M 6s\n",
      "  7800K .......... .......... .......... .......... .......... 11%  690M 6s\n",
      "  7850K .......... .......... .......... .......... .......... 11% 54.2M 6s\n",
      "  7900K .......... .......... .......... .......... .......... 11% 4.20M 6s\n",
      "  7950K .......... .......... .......... .......... .......... 11%  102M 6s\n",
      "  8000K .......... .......... .......... .......... .......... 12% 62.9M 6s\n",
      "  8050K .......... .......... .......... .......... .......... 12%  117M 6s\n",
      "  8100K .......... .......... .......... .......... .......... 12% 4.66M 6s\n",
      "  8150K .......... .......... .......... .......... .......... 12% 86.7M 6s\n",
      "  8200K .......... .......... .......... .......... .......... 12% 68.5M 6s\n",
      "  8250K .......... .......... .......... .......... .......... 12%  170M 5s\n",
      "  8300K .......... .......... .......... .......... .......... 12% 4.04M 6s\n",
      "  8350K .......... .......... .......... .......... .......... 12% 71.5M 6s\n",
      "  8400K .......... .......... .......... .......... .......... 12%  154M 5s\n",
      "  8450K .......... .......... .......... .......... .......... 12%  103M 5s\n",
      "  8500K .......... .......... .......... .......... .......... 12%  105M 5s\n",
      "  8550K .......... .......... .......... .......... .......... 12%  153M 5s\n",
      "  8600K .......... .......... .......... .......... .......... 12%  137M 5s\n",
      "  8650K .......... .......... .......... .......... .......... 12% 5.82M 5s\n",
      "  8700K .......... .......... .......... .......... .......... 13% 63.0M 5s\n",
      "  8750K .......... .......... .......... .......... .......... 13%  113M 5s\n",
      "  8800K .......... .......... .......... .......... .......... 13% 4.67M 5s\n",
      "  8850K .......... .......... .......... .......... .......... 13%  121M 5s\n",
      "  8900K .......... .......... .......... .......... .......... 13%  109M 5s\n",
      "  8950K .......... .......... .......... .......... .......... 13%  102M 5s\n",
      "  9000K .......... .......... .......... .......... .......... 13%  122M 5s\n",
      "  9050K .......... .......... .......... .......... .......... 13% 15.5M 5s\n",
      "  9100K .......... .......... .......... .......... .......... 13% 20.8M 5s\n",
      "  9150K .......... .......... .......... .......... .......... 13% 15.2M 5s\n",
      "  9200K .......... .......... .......... .......... .......... 13% 2.75M 5s\n",
      "  9250K .......... .......... .......... .......... .......... 13%  311M 5s\n",
      "  9300K .......... .......... .......... .......... .......... 13%  578M 5s\n",
      "  9350K .......... .......... .......... .......... .......... 14%  235M 5s\n",
      "  9400K .......... .......... .......... .......... .......... 14%  745M 5s\n",
      "  9450K .......... .......... .......... .......... .......... 14%  564M 5s\n",
      "  9500K .......... .......... .......... .......... .......... 14%  413M 5s\n",
      "  9550K .......... .......... .......... .......... .......... 14%  577M 5s\n",
      "  9600K .......... .......... .......... .......... .......... 14% 25.0M 5s\n",
      "  9650K .......... .......... .......... .......... .......... 14% 6.14M 5s\n",
      "  9700K .......... .......... .......... .......... .......... 14%  499M 5s\n",
      "  9750K .......... .......... .......... .......... .......... 14% 3.48M 5s\n",
      "  9800K .......... .......... .......... .......... .......... 14%  382M 5s\n",
      "  9850K .......... .......... .......... .......... .......... 14%  320M 5s\n",
      "  9900K .......... .......... .......... .......... .......... 14% 57.9M 5s\n",
      "  9950K .......... .......... .......... .......... .......... 14% 9.77M 5s\n",
      " 10000K .......... .......... .......... .......... .......... 15%  307M 5s\n",
      " 10050K .......... .......... .......... .......... .......... 15% 46.2M 5s\n",
      " 10100K .......... .......... .......... .......... .......... 15% 30.7M 5s\n",
      " 10150K .......... .......... .......... .......... .......... 15% 1016K 5s\n",
      " 10200K .......... .......... .......... .......... .......... 15% 66.9M 5s\n",
      " 10250K .......... .......... .......... .......... .......... 15%  159M 5s\n",
      " 10300K .......... .......... .......... .......... .......... 15% 88.8M 5s\n",
      " 10350K .......... .......... .......... .......... .......... 15%  112M 5s\n",
      " 10400K .......... .......... .......... .......... .......... 15%  178M 5s\n",
      " 10450K .......... .......... .......... .......... .......... 15%  176M 5s\n",
      " 10500K .......... .......... .......... .......... .......... 15% 2.34M 5s\n",
      " 10550K .......... .......... .......... .......... .......... 15%  117M 5s\n",
      " 10600K .......... .......... .......... .......... .......... 15% 47.3M 5s\n",
      " 10650K .......... .......... .......... .......... .......... 15% 3.71M 5s\n",
      " 10700K .......... .......... .......... .......... .......... 16% 62.7M 5s\n",
      " 10750K .......... .......... .......... .......... .......... 16% 90.3M 5s\n",
      " 10800K .......... .......... .......... .......... .......... 16%  167M 5s\n",
      " 10850K .......... .......... .......... .......... .......... 16%  133M 5s\n",
      " 10900K .......... .......... .......... .......... .......... 16%  168M 5s\n",
      " 10950K .......... .......... .......... .......... .......... 16%  159M 5s\n",
      " 11000K .......... .......... .......... .......... .......... 16% 68.8M 5s\n",
      " 11050K .......... .......... .......... .......... .......... 16%  114M 5s\n",
      " 11100K .......... .......... .......... .......... .......... 16%  115M 5s\n",
      " 11150K .......... .......... .......... .......... .......... 16% 1.94M 5s\n",
      " 11200K .......... .......... .......... .......... .......... 16% 76.7M 5s\n",
      " 11250K .......... .......... .......... .......... .......... 16%  113M 5s\n",
      " 11300K .......... .......... .......... .......... .......... 16% 73.8M 5s\n",
      " 11350K .......... .......... .......... .......... .......... 17% 64.5M 5s\n",
      " 11400K .......... .......... .......... .......... .......... 17%  165M 5s\n",
      " 11450K .......... .......... .......... .......... .......... 17%  119M 5s\n",
      " 11500K .......... .......... .......... .......... .......... 17%  173M 5s\n",
      " 11550K .......... .......... .......... .......... .......... 17%  120M 5s\n",
      " 11600K .......... .......... .......... .......... .......... 17% 25.7M 5s\n",
      " 11650K .......... .......... .......... .......... .......... 17%  163M 5s\n",
      " 11700K .......... .......... .......... .......... .......... 17%  104M 5s\n",
      " 11750K .......... .......... .......... .......... .......... 17% 8.51M 5s\n",
      " 11800K .......... .......... .......... .......... .......... 17% 2.47M 5s\n",
      " 11850K .......... .......... .......... .......... .......... 17%  507M 5s\n",
      " 11900K .......... .......... .......... .......... .......... 17%  439M 5s\n",
      " 11950K .......... .......... .......... .......... .......... 17%  399M 5s\n",
      " 12000K .......... .......... .......... .......... .......... 17%  738M 5s\n",
      " 12050K .......... .......... .......... .......... .......... 18%  201M 5s\n",
      " 12100K .......... .......... .......... .......... .......... 18%  513M 5s\n",
      " 12150K .......... .......... .......... .......... .......... 18%  505M 5s\n",
      " 12200K .......... .......... .......... .......... .......... 18% 43.5M 5s\n",
      " 12250K .......... .......... .......... .......... .......... 18% 5.54M 5s\n",
      " 12300K .......... .......... .......... .......... .......... 18%  159M 5s\n",
      " 12350K .......... .......... .......... .......... .......... 18%  205M 5s\n",
      " 12400K .......... .......... .......... .......... .......... 18% 34.8M 5s\n",
      " 12450K .......... .......... .......... .......... .......... 18%  223M 5s\n",
      " 12500K .......... .......... .......... .......... .......... 18% 4.24M 5s\n",
      " 12550K .......... .......... .......... .......... .......... 18% 94.8M 5s\n",
      " 12600K .......... .......... .......... .......... .......... 18%  110M 4s\n",
      " 12650K .......... .......... .......... .......... .......... 18% 91.5M 4s\n",
      " 12700K .......... .......... .......... .......... .......... 19% 72.3M 4s\n",
      " 12750K .......... .......... .......... .......... .......... 19% 7.28M 4s\n",
      " 12800K .......... .......... .......... .......... .......... 19% 85.6M 4s\n",
      " 12850K .......... .......... .......... .......... .......... 19% 3.82M 4s\n",
      " 12900K .......... .......... .......... .......... .......... 19% 73.5M 4s\n",
      " 12950K .......... .......... .......... .......... .......... 19% 69.4M 4s\n",
      " 13000K .......... .......... .......... .......... .......... 19%  104M 4s\n",
      " 13050K .......... .......... .......... .......... .......... 19%  166M 4s\n",
      " 13100K .......... .......... .......... .......... .......... 19%  148M 4s\n",
      " 13150K .......... .......... .......... .......... .......... 19% 8.01M 4s\n",
      " 13200K .......... .......... .......... .......... .......... 19%  128M 4s\n",
      " 13250K .......... .......... .......... .......... .......... 19% 1.81M 4s\n",
      " 13300K .......... .......... .......... .......... .......... 19% 41.0M 4s\n",
      " 13350K .......... .......... .......... .......... .......... 20% 59.9M 4s\n",
      " 13400K .......... .......... .......... .......... .......... 20%  200M 4s\n",
      " 13450K .......... .......... .......... .......... .......... 20% 95.3M 4s\n",
      " 13500K .......... .......... .......... .......... .......... 20%  432M 4s\n",
      " 13550K .......... .......... .......... .......... .......... 20%  513M 4s\n",
      " 13600K .......... .......... .......... .......... .......... 20%  751M 4s\n",
      " 13650K .......... .......... .......... .......... .......... 20% 6.56M 4s\n",
      " 13700K .......... .......... .......... .......... .......... 20%  151M 4s\n",
      " 13750K .......... .......... .......... .......... .......... 20% 81.7M 4s\n",
      " 13800K .......... .......... .......... .......... .......... 20%  101M 4s\n",
      " 13850K .......... .......... .......... .......... .......... 20%  118M 4s\n",
      " 13900K .......... .......... .......... .......... .......... 20%  129M 4s\n",
      " 13950K .......... .......... .......... .......... .......... 20% 4.39M 4s\n",
      " 14000K .......... .......... .......... .......... .......... 20%  106M 4s\n",
      " 14050K .......... .......... .......... .......... .......... 21% 50.3M 4s\n",
      " 14100K .......... .......... .......... .......... .......... 21%  162M 4s\n",
      " 14150K .......... .......... .......... .......... .......... 21% 6.03M 4s\n",
      " 14200K .......... .......... .......... .......... .......... 21% 58.9M 4s\n",
      " 14250K .......... .......... .......... .......... .......... 21% 70.2M 4s\n",
      " 14300K .......... .......... .......... .......... .......... 21% 79.6M 4s\n",
      " 14350K .......... .......... .......... .......... .......... 21% 30.9M 4s\n",
      " 14400K .......... .......... .......... .......... .......... 21% 49.8M 4s\n",
      " 14450K .......... .......... .......... .......... .......... 21% 27.9M 4s\n",
      " 14500K .......... .......... .......... .......... .......... 21% 24.8M 4s\n",
      " 14550K .......... .......... .......... .......... .......... 21% 10.5M 4s\n",
      " 14600K .......... .......... .......... .......... .......... 21%  194M 4s\n",
      " 14650K .......... .......... .......... .......... .......... 21% 22.3M 4s\n",
      " 14700K .......... .......... .......... .......... .......... 22% 13.2M 4s\n",
      " 14750K .......... .......... .......... .......... .......... 22% 43.5M 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14800K .......... .......... .......... .......... .......... 22% 19.6M 4s\n",
      " 14850K .......... .......... .......... .......... .......... 22% 15.2M 4s\n",
      " 14900K .......... .......... .......... .......... .......... 22% 60.5M 4s\n",
      " 14950K .......... .......... .......... .......... .......... 22% 16.8M 4s\n",
      " 15000K .......... .......... .......... .......... .......... 22% 6.05M 4s\n",
      " 15050K .......... .......... .......... .......... .......... 22%  109M 4s\n",
      " 15100K .......... .......... .......... .......... .......... 22% 76.9M 4s\n",
      " 15150K .......... .......... .......... .......... .......... 22% 66.6M 4s\n",
      " 15200K .......... .......... .......... .......... .......... 22% 28.0M 4s\n",
      " 15250K .......... .......... .......... .......... .......... 22% 24.1M 4s\n",
      " 15300K .......... .......... .......... .......... .......... 22% 21.9M 4s\n",
      " 15350K .......... .......... .......... .......... .......... 22% 22.5M 4s\n",
      " 15400K .......... .......... .......... .......... .......... 23% 27.3M 4s\n",
      " 15450K .......... .......... .......... .......... .......... 23% 15.5M 4s\n",
      " 15500K .......... .......... .......... .......... .......... 23% 29.7M 4s\n",
      " 15550K .......... .......... .......... .......... .......... 23% 18.8M 4s\n",
      " 15600K .......... .......... .......... .......... .......... 23% 27.1M 4s\n",
      " 15650K .......... .......... .......... .......... .......... 23% 5.15M 4s\n",
      " 15700K .......... .......... .......... .......... .......... 23%  119M 4s\n",
      " 15750K .......... .......... .......... .......... .......... 23% 42.2M 4s\n",
      " 15800K .......... .......... .......... .......... .......... 23%  165M 4s\n",
      " 15850K .......... .......... .......... .......... .......... 23% 3.72M 4s\n",
      " 15900K .......... .......... .......... .......... .......... 23% 80.3M 4s\n",
      " 15950K .......... .......... .......... .......... .......... 23%  131M 4s\n",
      " 16000K .......... .......... .......... .......... .......... 23%  176M 4s\n",
      " 16050K .......... .......... .......... .......... .......... 24% 59.7M 4s\n",
      " 16100K .......... .......... .......... .......... .......... 24%  170M 4s\n",
      " 16150K .......... .......... .......... .......... .......... 24% 89.1M 4s\n",
      " 16200K .......... .......... .......... .......... .......... 24% 2.15M 4s\n",
      " 16250K .......... .......... .......... .......... .......... 24%  157M 4s\n",
      " 16300K .......... .......... .......... .......... .......... 24% 74.5M 4s\n",
      " 16350K .......... .......... .......... .......... .......... 24% 75.0M 4s\n",
      " 16400K .......... .......... .......... .......... .......... 24%  165M 4s\n",
      " 16450K .......... .......... .......... .......... .......... 24%  131M 4s\n",
      " 16500K .......... .......... .......... .......... .......... 24% 84.7M 4s\n",
      " 16550K .......... .......... .......... .......... .......... 24%  113M 4s\n",
      " 16600K .......... .......... .......... .......... .......... 24%  171M 4s\n",
      " 16650K .......... .......... .......... .......... .......... 24%  245M 4s\n",
      " 16700K .......... .......... .......... .......... .......... 25% 89.5M 4s\n",
      " 16750K .......... .......... .......... .......... .......... 25% 88.0M 4s\n",
      " 16800K .......... .......... .......... .......... .......... 25%  230M 4s\n",
      " 16850K .......... .......... .......... .......... .......... 25% 28.3M 4s\n",
      " 16900K .......... .......... .......... .......... .......... 25%  459M 4s\n",
      " 16950K .......... .......... .......... .......... .......... 25%  852M 4s\n",
      " 17000K .......... .......... .......... .......... .......... 25%  604M 4s\n",
      " 17050K .......... .......... .......... .......... .......... 25% 3.52M 4s\n",
      " 17100K .......... .......... .......... .......... .......... 25% 96.7M 4s\n",
      " 17150K .......... .......... .......... .......... .......... 25% 80.3M 4s\n",
      " 17200K .......... .......... .......... .......... .......... 25%  131M 4s\n",
      " 17250K .......... .......... .......... .......... .......... 25%  158M 4s\n",
      " 17300K .......... .......... .......... .......... .......... 25% 30.0M 4s\n",
      " 17350K .......... .......... .......... .......... .......... 25%  123M 4s\n",
      " 17400K .......... .......... .......... .......... .......... 26% 43.7M 4s\n",
      " 17450K .......... .......... .......... .......... .......... 26% 2.86M 4s\n",
      " 17500K .......... .......... .......... .......... .......... 26% 68.7M 4s\n",
      " 17550K .......... .......... .......... .......... .......... 26% 76.6M 4s\n",
      " 17600K .......... .......... .......... .......... .......... 26%  168M 4s\n",
      " 17650K .......... .......... .......... .......... .......... 26% 70.3M 4s\n",
      " 17700K .......... .......... .......... .......... .......... 26%  171M 4s\n",
      " 17750K .......... .......... .......... .......... .......... 26%  181M 4s\n",
      " 17800K .......... .......... .......... .......... .......... 26%  103M 4s\n",
      " 17850K .......... .......... .......... .......... .......... 26%  153M 4s\n",
      " 17900K .......... .......... .......... .......... .......... 26%  255M 4s\n",
      " 17950K .......... .......... .......... .......... .......... 26% 10.5M 4s\n",
      " 18000K .......... .......... .......... .......... .......... 26%  129M 4s\n",
      " 18050K .......... .......... .......... .......... .......... 27% 87.4M 4s\n",
      " 18100K .......... .......... .......... .......... .......... 27%  133M 3s\n",
      " 18150K .......... .......... .......... .......... .......... 27% 36.1M 3s\n",
      " 18200K .......... .......... .......... .......... .......... 27% 1.99M 4s\n",
      " 18250K .......... .......... .......... .......... .......... 27% 31.9M 4s\n",
      " 18300K .......... .......... .......... .......... .......... 27% 67.6M 4s\n",
      " 18350K .......... .......... .......... .......... .......... 27%  198M 4s\n",
      " 18400K .......... .......... .......... .......... .......... 27%  292M 3s\n",
      " 18450K .......... .......... .......... .......... .......... 27%  523M 3s\n",
      " 18500K .......... .......... .......... .......... .......... 27%  357M 3s\n",
      " 18550K .......... .......... .......... .......... .......... 27%  849M 3s\n",
      " 18600K .......... .......... .......... .......... .......... 27%  448M 3s\n",
      " 18650K .......... .......... .......... .......... .......... 27%  925M 3s\n",
      " 18700K .......... .......... .......... .......... .......... 27%  986M 3s\n",
      " 18750K .......... .......... .......... .......... .......... 28%  180M 3s\n",
      " 18800K .......... .......... .......... .......... .......... 28%  636M 3s\n",
      " 18850K .......... .......... .......... .......... .......... 28%  838M 3s\n",
      " 18900K .......... .......... .......... .......... .......... 28%  417M 3s\n",
      " 18950K .......... .......... .......... .......... .......... 28%  551M 3s\n",
      " 19000K .......... .......... .......... .......... .......... 28% 11.7M 3s\n",
      " 19050K .......... .......... .......... .......... .......... 28%  628M 3s\n",
      " 19100K .......... .......... .......... .......... .......... 28%  601M 3s\n",
      " 19150K .......... .......... .......... .......... .......... 28% 1.74M 3s\n",
      " 19200K .......... .......... .......... .......... .......... 28% 88.8M 3s\n",
      " 19250K .......... .......... .......... .......... .......... 28%  101M 3s\n",
      " 19300K .......... .......... .......... .......... .......... 28% 74.1M 3s\n",
      " 19350K .......... .......... .......... .......... .......... 28%  149M 3s\n",
      " 19400K .......... .......... .......... .......... .......... 29% 78.0M 3s\n",
      " 19450K .......... .......... .......... .......... .......... 29% 86.8M 3s\n",
      " 19500K .......... .......... .......... .......... .......... 29%  162M 3s\n",
      " 19550K .......... .......... .......... .......... .......... 29% 89.7M 3s\n",
      " 19600K .......... .......... .......... .......... .......... 29% 16.0M 3s\n",
      " 19650K .......... .......... .......... .......... .......... 29% 59.8M 3s\n",
      " 19700K .......... .......... .......... .......... .......... 29% 59.1M 3s\n",
      " 19750K .......... .......... .......... .......... .......... 29%  440M 3s\n",
      " 19800K .......... .......... .......... .......... .......... 29%  559M 3s\n",
      " 19850K .......... .......... .......... .......... .......... 29%  645M 3s\n",
      " 19900K .......... .......... .......... .......... .......... 29%  752M 3s\n",
      " 19950K .......... .......... .......... .......... .......... 29%  508M 3s\n",
      " 20000K .......... .......... .......... .......... .......... 29%  593M 3s\n",
      " 20050K .......... .......... .......... .......... .......... 30% 1.05G 3s\n",
      " 20100K .......... .......... .......... .......... .......... 30% 3.96M 3s\n",
      " 20150K .......... .......... .......... .......... .......... 30% 80.8M 3s\n",
      " 20200K .......... .......... .......... .......... .......... 30%  195M 3s\n",
      " 20250K .......... .......... .......... .......... .......... 30% 92.8M 3s\n",
      " 20300K .......... .......... .......... .......... .......... 30%  198M 3s\n",
      " 20350K .......... .......... .......... .......... .......... 30%  178M 3s\n",
      " 20400K .......... .......... .......... .......... .......... 30%  205M 3s\n",
      " 20450K .......... .......... .......... .......... .......... 30%  135M 3s\n",
      " 20500K .......... .......... .......... .......... .......... 30% 14.6M 3s\n",
      " 20550K .......... .......... .......... .......... .......... 30%  405M 3s\n",
      " 20600K .......... .......... .......... .......... .......... 30%  582M 3s\n",
      " 20650K .......... .......... .......... .......... .......... 30% 1003M 3s\n",
      " 20700K .......... .......... .......... .......... .......... 30%  713M 3s\n",
      " 20750K .......... .......... .......... .......... .......... 31%  146M 3s\n",
      " 20800K .......... .......... .......... .......... .......... 31% 56.9M 3s\n",
      " 20850K .......... .......... .......... .......... .......... 31% 16.5M 3s\n",
      " 20900K .......... .......... .......... .......... .......... 31%  497M 3s\n",
      " 20950K .......... .......... .......... .......... .......... 31% 40.2M 3s\n",
      " 21000K .......... .......... .......... .......... .......... 31% 57.4M 3s\n",
      " 21050K .......... .......... .......... .......... .......... 31% 6.23M 3s\n",
      " 21100K .......... .......... .......... .......... .......... 31%  490M 3s\n",
      " 21150K .......... .......... .......... .......... .......... 31%  574M 3s\n",
      " 21200K .......... .......... .......... .......... .......... 31%  930M 3s\n",
      " 21250K .......... .......... .......... .......... .......... 31%  642M 3s\n",
      " 21300K .......... .......... .......... .......... .......... 31%  112M 3s\n",
      " 21350K .......... .......... .......... .......... .......... 31% 54.1M 3s\n",
      " 21400K .......... .......... .......... .......... .......... 32% 2.58M 3s\n",
      " 21450K .......... .......... .......... .......... .......... 32% 73.0M 3s\n",
      " 21500K .......... .......... .......... .......... .......... 32% 64.0M 3s\n",
      " 21550K .......... .......... .......... .......... .......... 32% 66.9M 3s\n",
      " 21600K .......... .......... .......... .......... .......... 32%  168M 3s\n",
      " 21650K .......... .......... .......... .......... .......... 32%  175M 3s\n",
      " 21700K .......... .......... .......... .......... .......... 32%  129M 3s\n",
      " 21750K .......... .......... .......... .......... .......... 32%  299M 3s\n",
      " 21800K .......... .......... .......... .......... .......... 32%  761M 3s\n",
      " 21850K .......... .......... .......... .......... .......... 32%  986M 3s\n",
      " 21900K .......... .......... .......... .......... .......... 32% 1001M 3s\n",
      " 21950K .......... .......... .......... .......... .......... 32%  504M 3s\n",
      " 22000K .......... .......... .......... .......... .......... 32%  930M 3s\n",
      " 22050K .......... .......... .......... .......... .......... 32% 37.3M 3s\n",
      " 22100K .......... .......... .......... .......... .......... 33%  294M 3s\n",
      " 22150K .......... .......... .......... .......... .......... 33%  911M 3s\n",
      " 22200K .......... .......... .......... .......... .......... 33%  724M 3s\n",
      " 22250K .......... .......... .......... .......... .......... 33%  994M 3s\n",
      " 22300K .......... .......... .......... .......... .......... 33% 41.2M 3s\n",
      " 22350K .......... .......... .......... .......... .......... 33% 23.3M 3s\n",
      " 22400K .......... .......... .......... .......... .......... 33% 84.2M 3s\n",
      " 22450K .......... .......... .......... .......... .......... 33% 46.2M 3s\n",
      " 22500K .......... .......... .......... .......... .......... 33% 44.3M 3s\n",
      " 22550K .......... .......... .......... .......... .......... 33% 18.3M 3s\n",
      " 22600K .......... .......... .......... .......... .......... 33%  804M 3s\n",
      " 22650K .......... .......... .......... .......... .......... 33% 57.1M 3s\n",
      " 22700K .......... .......... .......... .......... .......... 33% 58.1M 3s\n",
      " 22750K .......... .......... .......... .......... .......... 34% 36.2M 3s\n",
      " 22800K .......... .......... .......... .......... .......... 34% 17.1M 3s\n",
      " 22850K .......... .......... .......... .......... .......... 34% 57.3M 3s\n",
      " 22900K .......... .......... .......... .......... .......... 34% 37.8M 3s\n",
      " 22950K .......... .......... .......... .......... .......... 34% 29.7M 3s\n",
      " 23000K .......... .......... .......... .......... .......... 34% 65.9M 3s\n",
      " 23050K .......... .......... .......... .......... .......... 34% 36.7M 3s\n",
      " 23100K .......... .......... .......... .......... .......... 34% 41.9M 3s\n",
      " 23150K .......... .......... .......... .......... .......... 34% 25.0M 3s\n",
      " 23200K .......... .......... .......... .......... .......... 34%  111M 3s\n",
      " 23250K .......... .......... .......... .......... .......... 34% 48.3M 3s\n",
      " 23300K .......... .......... .......... .......... .......... 34% 11.8M 3s\n",
      " 23350K .......... .......... .......... .......... .......... 34%  490M 3s\n",
      " 23400K .......... .......... .......... .......... .......... 35%  485M 3s\n",
      " 23450K .......... .......... .......... .......... .......... 35%  269M 3s\n",
      " 23500K .......... .......... .......... .......... .......... 35% 24.9M 3s\n",
      " 23550K .......... .......... .......... .......... .......... 35% 17.3M 3s\n",
      " 23600K .......... .......... .......... .......... .......... 35%  362M 3s\n",
      " 23650K .......... .......... .......... .......... .......... 35%  695M 3s\n",
      " 23700K .......... .......... .......... .......... .......... 35% 54.2M 3s\n",
      " 23750K .......... .......... .......... .......... .......... 35% 35.8M 3s\n",
      " 23800K .......... .......... .......... .......... .......... 35% 11.7M 3s\n",
      " 23850K .......... .......... .......... .......... .......... 35%  288M 3s\n",
      " 23900K .......... .......... .......... .......... .......... 35%  750M 3s\n",
      " 23950K .......... .......... .......... .......... .......... 35% 8.99M 3s\n",
      " 24000K .......... .......... .......... .......... .......... 35% 42.1M 3s\n",
      " 24050K .......... .......... .......... .......... .......... 35%  108M 3s\n",
      " 24100K .......... .......... .......... .......... .......... 36% 61.2M 3s\n",
      " 24150K .......... .......... .......... .......... .......... 36%  205M 3s\n",
      " 24200K .......... .......... .......... .......... .......... 36%  152M 3s\n",
      " 24250K .......... .......... .......... .......... .......... 36%  125M 3s\n",
      " 24300K .......... .......... .......... .......... .......... 36%  371M 3s\n",
      " 24350K .......... .......... .......... .......... .......... 36% 17.6M 3s\n",
      " 24400K .......... .......... .......... .......... .......... 36%  927M 3s\n",
      " 24450K .......... .......... .......... .......... .......... 36%  215M 3s\n",
      " 24500K .......... .......... .......... .......... .......... 36% 45.3M 3s\n",
      " 24550K .......... .......... .......... .......... .......... 36% 47.7M 3s\n",
      " 24600K .......... .......... .......... .......... .......... 36% 21.5M 3s\n",
      " 24650K .......... .......... .......... .......... .......... 36%  148M 3s\n",
      " 24700K .......... .......... .......... .......... .......... 36% 51.9M 3s\n",
      " 24750K .......... .......... .......... .......... .......... 37% 32.6M 3s\n",
      " 24800K .......... .......... .......... .......... .......... 37% 54.4M 3s\n",
      " 24850K .......... .......... .......... .......... .......... 37% 33.6M 3s\n",
      " 24900K .......... .......... .......... .......... .......... 37% 80.2M 3s\n",
      " 24950K .......... .......... .......... .......... .......... 37% 34.5M 3s\n",
      " 25000K .......... .......... .......... .......... .......... 37% 45.6M 3s\n",
      " 25050K .......... .......... .......... .......... .......... 37% 7.92M 3s\n",
      " 25100K .......... .......... .......... .......... .......... 37%  393M 2s\n",
      " 25150K .......... .......... .......... .......... .......... 37%  168M 2s\n",
      " 25200K .......... .......... .......... .......... .......... 37%  482M 2s\n",
      " 25250K .......... .......... .......... .......... .......... 37%  455M 2s\n",
      " 25300K .......... .......... .......... .......... .......... 37%  826M 2s\n",
      " 25350K .......... .......... .......... .......... .......... 37%  121M 2s\n",
      " 25400K .......... .......... .......... .......... .......... 37% 23.0M 2s\n",
      " 25450K .......... .......... .......... .......... .......... 38% 37.0M 2s\n",
      " 25500K .......... .......... .......... .......... .......... 38% 36.0M 2s\n",
      " 25550K .......... .......... .......... .......... .......... 38% 26.2M 2s\n",
      " 25600K .......... .......... .......... .......... .......... 38% 31.6M 2s\n",
      " 25650K .......... .......... .......... .......... .......... 38% 67.6M 2s\n",
      " 25700K .......... .......... .......... .......... .......... 38% 45.6M 2s\n",
      " 25750K .......... .......... .......... .......... .......... 38% 34.4M 2s\n",
      " 25800K .......... .......... .......... .......... .......... 38% 23.7M 2s\n",
      " 25850K .......... .......... .......... .......... .......... 38%  733M 2s\n",
      " 25900K .......... .......... .......... .......... .......... 38% 67.4M 2s\n",
      " 25950K .......... .......... .......... .......... .......... 38% 39.4M 2s\n",
      " 26000K .......... .......... .......... .......... .......... 38% 37.1M 2s\n",
      " 26050K .......... .......... .......... .......... .......... 38% 43.5M 2s\n",
      " 26100K .......... .......... .......... .......... .......... 39% 20.1M 2s\n",
      " 26150K .......... .......... .......... .......... .......... 39%  437M 2s\n",
      " 26200K .......... .......... .......... .......... .......... 39% 86.8M 2s\n",
      " 26250K .......... .......... .......... .......... .......... 39% 33.5M 2s\n",
      " 26300K .......... .......... .......... .......... .......... 39% 27.3M 2s\n",
      " 26350K .......... .......... .......... .......... .......... 39% 85.7M 2s\n",
      " 26400K .......... .......... .......... .......... .......... 39%  121M 2s\n",
      " 26450K .......... .......... .......... .......... .......... 39% 36.4M 2s\n",
      " 26500K .......... .......... .......... .......... .......... 39% 46.0M 2s\n",
      " 26550K .......... .......... .......... .......... .......... 39% 25.3M 2s\n",
      " 26600K .......... .......... .......... .......... .......... 39%  439M 2s\n",
      " 26650K .......... .......... .......... .......... .......... 39% 45.7M 2s\n",
      " 26700K .......... .......... .......... .......... .......... 39% 37.4M 2s\n",
      " 26750K .......... .......... .......... .......... .......... 40% 45.1M 2s\n",
      " 26800K .......... .......... .......... .......... .......... 40% 4.54M 2s\n",
      " 26850K .......... .......... .......... .......... .......... 40%  404M 2s\n",
      " 26900K .......... .......... .......... .......... .......... 40%  812M 2s\n",
      " 26950K .......... .......... .......... .......... .......... 40%  447M 2s\n",
      " 27000K .......... .......... .......... .......... .......... 40%  629M 2s\n",
      " 27050K .......... .......... .......... .......... .......... 40%  956M 2s\n",
      " 27100K .......... .......... .......... .......... .......... 40%  655M 2s\n",
      " 27150K .......... .......... .......... .......... .......... 40%  263M 2s\n",
      " 27200K .......... .......... .......... .......... .......... 40%  823M 2s\n",
      " 27250K .......... .......... .......... .......... .......... 40%  158M 2s\n",
      " 27300K .......... .......... .......... .......... .......... 40% 7.58M 2s\n",
      " 27350K .......... .......... .......... .......... .......... 40%  349M 2s\n",
      " 27400K .......... .......... .......... .......... .......... 40%  389M 2s\n",
      " 27450K .......... .......... .......... .......... .......... 41%  211M 2s\n",
      " 27500K .......... .......... .......... .......... .......... 41%  491M 2s\n",
      " 27550K .......... .......... .......... .......... .......... 41%  268M 2s\n",
      " 27600K .......... .......... .......... .......... .......... 41%  151M 2s\n",
      " 27650K .......... .......... .......... .......... .......... 41%  221M 2s\n",
      " 27700K .......... .......... .......... .......... .......... 41% 65.7M 2s\n",
      " 27750K .......... .......... .......... .......... .......... 41% 26.4M 2s\n",
      " 27800K .......... .......... .......... .......... .......... 41% 88.9M 2s\n",
      " 27850K .......... .......... .......... .......... .......... 41% 85.0M 2s\n",
      " 27900K .......... .......... .......... .......... .......... 41% 27.6M 2s\n",
      " 27950K .......... .......... .......... .......... .......... 41% 50.1M 2s\n",
      " 28000K .......... .......... .......... .......... .......... 41% 35.6M 2s\n",
      " 28050K .......... .......... .......... .......... .......... 41%  102M 2s\n",
      " 28100K .......... .......... .......... .......... .......... 42% 51.0M 2s\n",
      " 28150K .......... .......... .......... .......... .......... 42% 35.3M 2s\n",
      " 28200K .......... .......... .......... .......... .......... 42% 36.1M 2s\n",
      " 28250K .......... .......... .......... .......... .......... 42% 25.7M 2s\n",
      " 28300K .......... .......... .......... .......... .......... 42% 56.6M 2s\n",
      " 28350K .......... .......... .......... .......... .......... 42% 15.7M 2s\n",
      " 28400K .......... .......... .......... .......... .......... 42%  595M 2s\n",
      " 28450K .......... .......... .......... .......... .......... 42%  934M 2s\n",
      " 28500K .......... .......... .......... .......... .......... 42% 45.7M 2s\n",
      " 28550K .......... .......... .......... .......... .......... 42%  458M 2s\n",
      " 28600K .......... .......... .......... .......... .......... 42%  318M 2s\n",
      " 28650K .......... .......... .......... .......... .......... 42% 14.9M 2s\n",
      " 28700K .......... .......... .......... .......... .......... 42%  581M 2s\n",
      " 28750K .......... .......... .......... .......... .......... 42%  124M 2s\n",
      " 28800K .......... .......... .......... .......... .......... 43%  257M 2s\n",
      " 28850K .......... .......... .......... .......... .......... 43% 98.5M 2s\n",
      " 28900K .......... .......... .......... .......... .......... 43% 70.8M 2s\n",
      " 28950K .......... .......... .......... .......... .......... 43% 56.5M 2s\n",
      " 29000K .......... .......... .......... .......... .......... 43% 72.6M 2s\n",
      " 29050K .......... .......... .......... .......... .......... 43% 14.1M 2s\n",
      " 29100K .......... .......... .......... .......... .......... 43%  932M 2s\n",
      " 29150K .......... .......... .......... .......... .......... 43% 67.2M 2s\n",
      " 29200K .......... .......... .......... .......... .......... 43% 32.1M 2s\n",
      " 29250K .......... .......... .......... .......... .......... 43% 17.6M 2s\n",
      " 29300K .......... .......... .......... .......... .......... 43%  291M 2s\n",
      " 29350K .......... .......... .......... .......... .......... 43% 67.3M 2s\n",
      " 29400K .......... .......... .......... .......... .......... 43% 12.1M 2s\n",
      " 29450K .......... .......... .......... .......... .......... 44%  261M 2s\n",
      " 29500K .......... .......... .......... .......... .......... 44%  256M 2s\n",
      " 29550K .......... .......... .......... .......... .......... 44%  138M 2s\n",
      " 29600K .......... .......... .......... .......... .......... 44% 93.5M 2s\n",
      " 29650K .......... .......... .......... .......... .......... 44% 34.5M 2s\n",
      " 29700K .......... .......... .......... .......... .......... 44% 92.2M 2s\n",
      " 29750K .......... .......... .......... .......... .......... 44% 22.1M 2s\n",
      " 29800K .......... .......... .......... .......... .......... 44%  660M 2s\n",
      " 29850K .......... .......... .......... .......... .......... 44% 78.3M 2s\n",
      " 29900K .......... .......... .......... .......... .......... 44% 47.1M 2s\n",
      " 29950K .......... .......... .......... .......... .......... 44% 2.66M 2s\n",
      " 30000K .......... .......... .......... .......... .......... 44% 98.4M 2s\n",
      " 30050K .......... .......... .......... .......... .......... 44%  104M 2s\n",
      " 30100K .......... .......... .......... .......... .......... 45%  224M 2s\n",
      " 30150K .......... .......... .......... .......... .......... 45% 57.4M 2s\n",
      " 30200K .......... .......... .......... .......... .......... 45%  426M 2s\n",
      " 30250K .......... .......... .......... .......... .......... 45%  909M 2s\n",
      " 30300K .......... .......... .......... .......... .......... 45%  660M 2s\n",
      " 30350K .......... .......... .......... .......... .......... 45%  470M 2s\n",
      " 30400K .......... .......... .......... .......... .......... 45%  263M 2s\n",
      " 30450K .......... .......... .......... .......... .......... 45%  627M 2s\n",
      " 30500K .......... .......... .......... .......... .......... 45%  747M 2s\n",
      " 30550K .......... .......... .......... .......... .......... 45%  663M 2s\n",
      " 30600K .......... .......... .......... .......... .......... 45%  800M 2s\n",
      " 30650K .......... .......... .......... .......... .......... 45% 1.04G 2s\n",
      " 30700K .......... .......... .......... .......... .......... 45%  401M 2s\n",
      " 30750K .......... .......... .......... .......... .......... 45%  675M 2s\n",
      " 30800K .......... .......... .......... .......... .......... 46%  327M 2s\n",
      " 30850K .......... .......... .......... .......... .......... 46%  653M 2s\n",
      " 30900K .......... .......... .......... .......... .......... 46%  503M 2s\n",
      " 30950K .......... .......... .......... .......... .......... 46%  505M 2s\n",
      " 31000K .......... .......... .......... .......... .......... 46% 41.8M 2s\n",
      " 31050K .......... .......... .......... .......... .......... 46%  492M 2s\n",
      " 31100K .......... .......... .......... .......... .......... 46% 3.13M 2s\n",
      " 31150K .......... .......... .......... .......... .......... 46%  121M 2s\n",
      " 31200K .......... .......... .......... .......... .......... 46%  105M 2s\n",
      " 31250K .......... .......... .......... .......... .......... 46%  213M 2s\n",
      " 31300K .......... .......... .......... .......... .......... 46%  167M 2s\n",
      " 31350K .......... .......... .......... .......... .......... 46%  209M 2s\n",
      " 31400K .......... .......... .......... .......... .......... 46%  176M 2s\n",
      " 31450K .......... .......... .......... .......... .......... 47%  111M 2s\n",
      " 31500K .......... .......... .......... .......... .......... 47%  173M 2s\n",
      " 31550K .......... .......... .......... .......... .......... 47%  139M 2s\n",
      " 31600K .......... .......... .......... .......... .......... 47%  140M 2s\n",
      " 31650K .......... .......... .......... .......... .......... 47%  677M 2s\n",
      " 31700K .......... .......... .......... .......... .......... 47%  979M 2s\n",
      " 31750K .......... .......... .......... .......... .......... 47%  595M 2s\n",
      " 31800K .......... .......... .......... .......... .......... 47%  749M 2s\n",
      " 31850K .......... .......... .......... .......... .......... 47%  574M 2s\n",
      " 31900K .......... .......... .......... .......... .......... 47%  698M 2s\n",
      " 31950K .......... .......... .......... .......... .......... 47% 33.0M 2s\n",
      " 32000K .......... .......... .......... .......... .......... 47%  893M 2s\n",
      " 32050K .......... .......... .......... .......... .......... 47%  342M 2s\n",
      " 32100K .......... .......... .......... .......... .......... 47%  144M 2s\n",
      " 32150K .......... .......... .......... .......... .......... 48% 61.3M 2s\n",
      " 32200K .......... .......... .......... .......... .......... 48% 75.2M 2s\n",
      " 32250K .......... .......... .......... .......... .......... 48% 72.6M 2s\n",
      " 32300K .......... .......... .......... .......... .......... 48% 10.2M 2s\n",
      " 32350K .......... .......... .......... .......... .......... 48%  376M 2s\n",
      " 32400K .......... .......... .......... .......... .......... 48%  941M 2s\n",
      " 32450K .......... .......... .......... .......... .......... 48%  159M 2s\n",
      " 32500K .......... .......... .......... .......... .......... 48%  423M 2s\n",
      " 32550K .......... .......... .......... .......... .......... 48% 49.9M 2s\n",
      " 32600K .......... .......... .......... .......... .......... 48% 31.1M 2s\n",
      " 32650K .......... .......... .......... .......... .......... 48% 43.0M 2s\n",
      " 32700K .......... .......... .......... .......... .......... 48% 53.7M 2s\n",
      " 32750K .......... .......... .......... .......... .......... 48% 73.3M 2s\n",
      " 32800K .......... .......... .......... .......... .......... 49% 95.1M 2s\n",
      " 32850K .......... .......... .......... .......... .......... 49% 19.1M 2s\n",
      " 32900K .......... .......... .......... .......... .......... 49% 98.2M 2s\n",
      " 32950K .......... .......... .......... .......... .......... 49%  135M 2s\n",
      " 33000K .......... .......... .......... .......... .......... 49%  105M 2s\n",
      " 33050K .......... .......... .......... .......... .......... 49% 55.7M 2s\n",
      " 33100K .......... .......... .......... .......... .......... 49% 41.9M 2s\n",
      " 33150K .......... .......... .......... .......... .......... 49% 47.6M 2s\n",
      " 33200K .......... .......... .......... .......... .......... 49% 84.8M 2s\n",
      " 33250K .......... .......... .......... .......... .......... 49% 20.0M 2s\n",
      " 33300K .......... .......... .......... .......... .......... 49%  142M 2s\n",
      " 33350K .......... .......... .......... .......... .......... 49% 65.8M 2s\n",
      " 33400K .......... .......... .......... .......... .......... 49%  860M 2s\n",
      " 33450K .......... .......... .......... .......... .......... 50% 80.1M 2s\n",
      " 33500K .......... .......... .......... .......... .......... 50% 70.6M 2s\n",
      " 33550K .......... .......... .......... .......... .......... 50% 10.8M 2s\n",
      " 33600K .......... .......... .......... .......... .......... 50%  397M 2s\n",
      " 33650K .......... .......... .......... .......... .......... 50%  304M 2s\n",
      " 33700K .......... .......... .......... .......... .......... 50%  579M 2s\n",
      " 33750K .......... .......... .......... .......... .......... 50%  472M 2s\n",
      " 33800K .......... .......... .......... .......... .......... 50% 16.4M 2s\n",
      " 33850K .......... .......... .......... .......... .......... 50%  599M 2s\n",
      " 33900K .......... .......... .......... .......... .......... 50%  206M 2s\n",
      " 33950K .......... .......... .......... .......... .......... 50% 47.8M 2s\n",
      " 34000K .......... .......... .......... .......... .......... 50%  123M 2s\n",
      " 34050K .......... .......... .......... .......... .......... 50% 54.1M 2s\n",
      " 34100K .......... .......... .......... .......... .......... 50% 54.0M 2s\n",
      " 34150K .......... .......... .......... .......... .......... 51% 54.4M 2s\n",
      " 34200K .......... .......... .......... .......... .......... 51% 14.3M 2s\n",
      " 34250K .......... .......... .......... .......... .......... 51%  914M 2s\n",
      " 34300K .......... .......... .......... .......... .......... 51%  645M 2s\n",
      " 34350K .......... .......... .......... .......... .......... 51% 90.1M 2s\n",
      " 34400K .......... .......... .......... .......... .......... 51%  131M 2s\n",
      " 34450K .......... .......... .......... .......... .......... 51%  113M 2s\n",
      " 34500K .......... .......... .......... .......... .......... 51% 51.9M 2s\n",
      " 34550K .......... .......... .......... .......... .......... 51% 48.1M 2s\n",
      " 34600K .......... .......... .......... .......... .......... 51%  104M 2s\n",
      " 34650K .......... .......... .......... .......... .......... 51% 57.6M 2s\n",
      " 34700K .......... .......... .......... .......... .......... 51% 2.29M 2s\n",
      " 34750K .......... .......... .......... .......... .......... 51%  125M 2s\n",
      " 34800K .......... .......... .......... .......... .......... 52% 35.6M 2s\n",
      " 34850K .......... .......... .......... .......... .......... 52% 96.3M 2s\n",
      " 34900K .......... .......... .......... .......... .......... 52%  214M 2s\n",
      " 34950K .......... .......... .......... .......... .......... 52% 57.6M 2s\n",
      " 35000K .......... .......... .......... .......... .......... 52%  214M 2s\n",
      " 35050K .......... .......... .......... .......... .......... 52%  219M 2s\n",
      " 35100K .......... .......... .......... .......... .......... 52% 68.8M 2s\n",
      " 35150K .......... .......... .......... .......... .......... 52%  568M 2s\n",
      " 35200K .......... .......... .......... .......... .......... 52% 1007M 2s\n",
      " 35250K .......... .......... .......... .......... .......... 52%  768M 2s\n",
      " 35300K .......... .......... .......... .......... .......... 52%  963M 2s\n",
      " 35350K .......... .......... .......... .......... .......... 52%  729M 2s\n",
      " 35400K .......... .......... .......... .......... .......... 52%  959M 2s\n",
      " 35450K .......... .......... .......... .......... .......... 52%  990M 2s\n",
      " 35500K .......... .......... .......... .......... .......... 53%  231M 2s\n",
      " 35550K .......... .......... .......... .......... .......... 53%  775M 2s\n",
      " 35600K .......... .......... .......... .......... .......... 53%  990M 2s\n",
      " 35650K .......... .......... .......... .......... .......... 53%  711M 2s\n",
      " 35700K .......... .......... .......... .......... .......... 53%  957M 2s\n",
      " 35750K .......... .......... .......... .......... .......... 53% 19.1M 2s\n",
      " 35800K .......... .......... .......... .......... .......... 53%  489M 1s\n",
      " 35850K .......... .......... .......... .......... .......... 53%  579M 1s\n",
      " 35900K .......... .......... .......... .......... .......... 53%  260M 1s\n",
      " 35950K .......... .......... .......... .......... .......... 53%  468M 1s\n",
      " 36000K .......... .......... .......... .......... .......... 53%  935M 1s\n",
      " 36050K .......... .......... .......... .......... .......... 53% 6.68M 1s\n",
      " 36100K .......... .......... .......... .......... .......... 53%  431M 1s\n",
      " 36150K .......... .......... .......... .......... .......... 54%  256M 1s\n",
      " 36200K .......... .......... .......... .......... .......... 54%  376M 1s\n",
      " 36250K .......... .......... .......... .......... .......... 54%  781M 1s\n",
      " 36300K .......... .......... .......... .......... .......... 54%  980M 1s\n",
      " 36350K .......... .......... .......... .......... .......... 54% 96.9M 1s\n",
      " 36400K .......... .......... .......... .......... .......... 54%  512M 1s\n",
      " 36450K .......... .......... .......... .......... .......... 54%  601M 1s\n",
      " 36500K .......... .......... .......... .......... .......... 54% 99.4M 1s\n",
      " 36550K .......... .......... .......... .......... .......... 54%  607M 1s\n",
      " 36600K .......... .......... .......... .......... .......... 54%  132M 1s\n",
      " 36650K .......... .......... .......... .......... .......... 54% 98.9M 1s\n",
      " 36700K .......... .......... .......... .......... .......... 54% 3.00M 1s\n",
      " 36750K .......... .......... .......... .......... .......... 54%  102M 1s\n",
      " 36800K .......... .......... .......... .......... .......... 55%  111M 1s\n",
      " 36850K .......... .......... .......... .......... .......... 55% 47.4M 1s\n",
      " 36900K .......... .......... .......... .......... .......... 55% 82.8M 1s\n",
      " 36950K .......... .......... .......... .......... .......... 55%  194M 1s\n",
      " 37000K .......... .......... .......... .......... .......... 55%  206M 1s\n",
      " 37050K .......... .......... .......... .......... .......... 55% 90.8M 1s\n",
      " 37100K .......... .......... .......... .......... .......... 55%  277M 1s\n",
      " 37150K .......... .......... .......... .......... .......... 55%  197M 1s\n",
      " 37200K .......... .......... .......... .......... .......... 55%  311M 1s\n",
      " 37250K .......... .......... .......... .......... .......... 55%  280M 1s\n",
      " 37300K .......... .......... .......... .......... .......... 55%  234M 1s\n",
      " 37350K .......... .......... .......... .......... .......... 55%  286M 1s\n",
      " 37400K .......... .......... .......... .......... .......... 55%  248M 1s\n",
      " 37450K .......... .......... .......... .......... .......... 55%  313M 1s\n",
      " 37500K .......... .......... .......... .......... .......... 56% 3.26M 1s\n",
      " 37550K .......... .......... .......... .......... .......... 56% 10.8M 1s\n",
      " 37600K .......... .......... .......... .......... .......... 56% 78.7M 1s\n",
      " 37650K .......... .......... .......... .......... .......... 56% 86.7M 1s\n",
      " 37700K .......... .......... .......... .......... .......... 56% 62.9M 1s\n",
      " 37750K .......... .......... .......... .......... .......... 56%  200M 1s\n",
      " 37800K .......... .......... .......... .......... .......... 56%  176M 1s\n",
      " 37850K .......... .......... .......... .......... .......... 56%  134M 1s\n",
      " 37900K .......... .......... .......... .......... .......... 56%  433M 1s\n",
      " 37950K .......... .......... .......... .......... .......... 56%  400M 1s\n",
      " 38000K .......... .......... .......... .......... .......... 56%  350M 1s\n",
      " 38050K .......... .......... .......... .......... .......... 56%  482M 1s\n",
      " 38100K .......... .......... .......... .......... .......... 56%  168M 1s\n",
      " 38150K .......... .......... .......... .......... .......... 57%  148M 1s\n",
      " 38200K .......... .......... .......... .......... .......... 57%  451M 1s\n",
      " 38250K .......... .......... .......... .......... .......... 57%  298M 1s\n",
      " 38300K .......... .......... .......... .......... .......... 57%  475M 1s\n",
      " 38350K .......... .......... .......... .......... .......... 57%  466M 1s\n",
      " 38400K .......... .......... .......... .......... .......... 57%  574M 1s\n",
      " 38450K .......... .......... .......... .......... .......... 57%  973M 1s\n",
      " 38500K .......... .......... .......... .......... .......... 57%  337M 1s\n",
      " 38550K .......... .......... .......... .......... .......... 57%  848M 1s\n",
      " 38600K .......... .......... .......... .......... .......... 57% 1001M 1s\n",
      " 38650K .......... .......... .......... .......... .......... 57%  717M 1s\n",
      " 38700K .......... .......... .......... .......... .......... 57%  961M 1s\n",
      " 38750K .......... .......... .......... .......... .......... 57%  614M 1s\n",
      " 38800K .......... .......... .......... .......... .......... 57%  994M 1s\n",
      " 38850K .......... .......... .......... .......... .......... 58%  234M 1s\n",
      " 38900K .......... .......... .......... .......... .......... 58%  719M 1s\n",
      " 38950K .......... .......... .......... .......... .......... 58%  452M 1s\n",
      " 39000K .......... .......... .......... .......... .......... 58% 2.10M 1s\n",
      " 39050K .......... .......... .......... .......... .......... 58%  121M 1s\n",
      " 39100K .......... .......... .......... .......... .......... 58%  230M 1s\n",
      " 39150K .......... .......... .......... .......... .......... 58% 80.2M 1s\n",
      " 39200K .......... .......... .......... .......... .......... 58%  229M 1s\n",
      " 39250K .......... .......... .......... .......... .......... 58%  241M 1s\n",
      " 39300K .......... .......... .......... .......... .......... 58%  175M 1s\n",
      " 39350K .......... .......... .......... .......... .......... 58%  223M 1s\n",
      " 39400K .......... .......... .......... .......... .......... 58% 74.3M 1s\n",
      " 39450K .......... .......... .......... .......... .......... 58%  230M 1s\n",
      " 39500K .......... .......... .......... .......... .......... 59%  103M 1s\n",
      " 39550K .......... .......... .......... .......... .......... 59%  128M 1s\n",
      " 39600K .......... .......... .......... .......... .......... 59%  227M 1s\n",
      " 39650K .......... .......... .......... .......... .......... 59%  167M 1s\n",
      " 39700K .......... .......... .......... .......... .......... 59%  233M 1s\n",
      " 39750K .......... .......... .......... .......... .......... 59%  217M 1s\n",
      " 39800K .......... .......... .......... .......... .......... 59% 62.5M 1s\n",
      " 39850K .......... .......... .......... .......... .......... 59%  263M 1s\n",
      " 39900K .......... .......... .......... .......... .......... 59%  604M 1s\n",
      " 39950K .......... .......... .......... .......... .......... 59%  788M 1s\n",
      " 40000K .......... .......... .......... .......... .......... 59%  703M 1s\n",
      " 40050K .......... .......... .......... .......... .......... 59%  977M 1s\n",
      " 40100K .......... .......... .......... .......... .......... 59%  743M 1s\n",
      " 40150K .......... .......... .......... .......... .......... 60%  846M 1s\n",
      " 40200K .......... .......... .......... .......... .......... 60% 5.05M 1s\n",
      " 40250K .......... .......... .......... .......... .......... 60%  617M 1s\n",
      " 40300K .......... .......... .......... .......... .......... 60%  574M 1s\n",
      " 40350K .......... .......... .......... .......... .......... 60%  402M 1s\n",
      " 40400K .......... .......... .......... .......... .......... 60%  954M 1s\n",
      " 40450K .......... .......... .......... .......... .......... 60%  941M 1s\n",
      " 40500K .......... .......... .......... .......... .......... 60% 33.0M 1s\n",
      " 40550K .......... .......... .......... .......... .......... 60%  477M 1s\n",
      " 40600K .......... .......... .......... .......... .......... 60%  648M 1s\n",
      " 40650K .......... .......... .......... .......... .......... 60%  453M 1s\n",
      " 40700K .......... .......... .......... .......... .......... 60%  950M 1s\n",
      " 40750K .......... .......... .......... .......... .......... 60%  489M 1s\n",
      " 40800K .......... .......... .......... .......... .......... 60%  674M 1s\n",
      " 40850K .......... .......... .......... .......... .......... 61%  263M 1s\n",
      " 40900K .......... .......... .......... .......... .......... 61%  245M 1s\n",
      " 40950K .......... .......... .......... .......... .......... 61%  613M 1s\n",
      " 41000K .......... .......... .......... .......... .......... 61%  969M 1s\n",
      " 41050K .......... .......... .......... .......... .......... 61% 33.0M 1s\n",
      " 41100K .......... .......... .......... .......... .......... 61%  763M 1s\n",
      " 41150K .......... .......... .......... .......... .......... 61% 73.6M 1s\n",
      " 41200K .......... .......... .......... .......... .......... 61% 61.6M 1s\n",
      " 41250K .......... .......... .......... .......... .......... 61%  107M 1s\n",
      " 41300K .......... .......... .......... .......... .......... 61%  126M 1s\n",
      " 41350K .......... .......... .......... .......... .......... 61% 67.1M 1s\n",
      " 41400K .......... .......... .......... .......... .......... 61% 57.3M 1s\n",
      " 41450K .......... .......... .......... .......... .......... 61% 70.3M 1s\n",
      " 41500K .......... .......... .......... .......... .......... 62% 4.03M 1s\n",
      " 41550K .......... .......... .......... .......... .......... 62% 20.6M 1s\n",
      " 41600K .......... .......... .......... .......... .......... 62%  182M 1s\n",
      " 41650K .......... .......... .......... .......... .......... 62%  838M 1s\n",
      " 41700K .......... .......... .......... .......... .......... 62%  200M 1s\n",
      " 41750K .......... .......... .......... .......... .......... 62%  714M 1s\n",
      " 41800K .......... .......... .......... .......... .......... 62%  675M 1s\n",
      " 41850K .......... .......... .......... .......... .......... 62%  141M 1s\n",
      " 41900K .......... .......... .......... .......... .......... 62%  370M 1s\n",
      " 41950K .......... .......... .......... .......... .......... 62%  393M 1s\n",
      " 42000K .......... .......... .......... .......... .......... 62%  675M 1s\n",
      " 42050K .......... .......... .......... .......... .......... 62%  614M 1s\n",
      " 42100K .......... .......... .......... .......... .......... 62%  804M 1s\n",
      " 42150K .......... .......... .......... .......... .......... 62%  385M 1s\n",
      " 42200K .......... .......... .......... .......... .......... 63%  421M 1s\n",
      " 42250K .......... .......... .......... .......... .......... 63%  591M 1s\n",
      " 42300K .......... .......... .......... .......... .......... 63%  588M 1s\n",
      " 42350K .......... .......... .......... .......... .......... 63%  519M 1s\n",
      " 42400K .......... .......... .......... .......... .......... 63%  664M 1s\n",
      " 42450K .......... .......... .......... .......... .......... 63% 92.5M 1s\n",
      " 42500K .......... .......... .......... .......... .......... 63% 83.2M 1s\n",
      " 42550K .......... .......... .......... .......... .......... 63% 52.8M 1s\n",
      " 42600K .......... .......... .......... .......... .......... 63% 48.5M 1s\n",
      " 42650K .......... .......... .......... .......... .......... 63% 50.1M 1s\n",
      " 42700K .......... .......... .......... .......... .......... 63% 95.5M 1s\n",
      " 42750K .......... .......... .......... .......... .......... 63% 1.69M 1s\n",
      " 42800K .......... .......... .......... .......... .......... 63% 87.7M 1s\n",
      " 42850K .......... .......... .......... .......... .......... 64% 67.9M 1s\n",
      " 42900K .......... .......... .......... .......... .......... 64%  123M 1s\n",
      " 42950K .......... .......... .......... .......... .......... 64%  230M 1s\n",
      " 43000K .......... .......... .......... .......... .......... 64%  142M 1s\n",
      " 43050K .......... .......... .......... .......... .......... 64%  282M 1s\n",
      " 43100K .......... .......... .......... .......... .......... 64%  202M 1s\n",
      " 43150K .......... .......... .......... .......... .......... 64%  232M 1s\n",
      " 43200K .......... .......... .......... .......... .......... 64%  284M 1s\n",
      " 43250K .......... .......... .......... .......... .......... 64%  199M 1s\n",
      " 43300K .......... .......... .......... .......... .......... 64%  271M 1s\n",
      " 43350K .......... .......... .......... .......... .......... 64%  173M 1s\n",
      " 43400K .......... .......... .......... .......... .......... 64%  935M 1s\n",
      " 43450K .......... .......... .......... .......... .......... 64%  988M 1s\n",
      " 43500K .......... .......... .......... .......... .......... 65%  720M 1s\n",
      " 43550K .......... .......... .......... .......... .......... 65%  356M 1s\n",
      " 43600K .......... .......... .......... .......... .......... 65%  832M 1s\n",
      " 43650K .......... .......... .......... .......... .......... 65%  662M 1s\n",
      " 43700K .......... .......... .......... .......... .......... 65% 1017M 1s\n",
      " 43750K .......... .......... .......... .......... .......... 65%  628M 1s\n",
      " 43800K .......... .......... .......... .......... .......... 65% 2.21M 1s\n",
      " 43850K .......... .......... .......... .......... .......... 65% 95.3M 1s\n",
      " 43900K .......... .......... .......... .......... .......... 65% 97.8M 1s\n",
      " 43950K .......... .......... .......... .......... .......... 65%  112M 1s\n",
      " 44000K .......... .......... .......... .......... .......... 65% 58.9M 1s\n",
      " 44050K .......... .......... .......... .......... .......... 65%  183M 1s\n",
      " 44100K .......... .......... .......... .......... .......... 65%  192M 1s\n",
      " 44150K .......... .......... .......... .......... .......... 65%  154M 1s\n",
      " 44200K .......... .......... .......... .......... .......... 66%  112M 1s\n",
      " 44250K .......... .......... .......... .......... .......... 66%  139M 1s\n",
      " 44300K .......... .......... .......... .......... .......... 66%  250M 1s\n",
      " 44350K .......... .......... .......... .......... .......... 66% 87.4M 1s\n",
      " 44400K .......... .......... .......... .......... .......... 66%  162M 1s\n",
      " 44450K .......... .......... .......... .......... .......... 66%  251M 1s\n",
      " 44500K .......... .......... .......... .......... .......... 66%  265M 1s\n",
      " 44550K .......... .......... .......... .......... .......... 66%  167M 1s\n",
      " 44600K .......... .......... .......... .......... .......... 66%  252M 1s\n",
      " 44650K .......... .......... .......... .......... .......... 66%  185M 1s\n",
      " 44700K .......... .......... .......... .......... .......... 66%  466M 1s\n",
      " 44750K .......... .......... .......... .......... .......... 66%  814M 1s\n",
      " 44800K .......... .......... .......... .......... .......... 66% 14.7M 1s\n",
      " 44850K .......... .......... .......... .......... .......... 67%  204M 1s\n",
      " 44900K .......... .......... .......... .......... .......... 67%  222M 1s\n",
      " 44950K .......... .......... .......... .......... .......... 67%  261M 1s\n",
      " 45000K .......... .......... .......... .......... .......... 67%  541M 1s\n",
      " 45050K .......... .......... .......... .......... .......... 67%  622M 1s\n",
      " 45100K .......... .......... .......... .......... .......... 67%  403M 1s\n",
      " 45150K .......... .......... .......... .......... .......... 67%  781M 1s\n",
      " 45200K .......... .......... .......... .......... .......... 67% 1011M 1s\n",
      " 45250K .......... .......... .......... .......... .......... 67%  346M 1s\n",
      " 45300K .......... .......... .......... .......... .......... 67%  906M 1s\n",
      " 45350K .......... .......... .......... .......... .......... 67%  696M 1s\n",
      " 45400K .......... .......... .......... .......... .......... 67%  996M 1s\n",
      " 45450K .......... .......... .......... .......... .......... 67% 1.02G 1s\n",
      " 45500K .......... .......... .......... .......... .......... 67%  734M 1s\n",
      " 45550K .......... .......... .......... .......... .......... 68% 22.8M 1s\n",
      " 45600K .......... .......... .......... .......... .......... 68%  384M 1s\n",
      " 45650K .......... .......... .......... .......... .......... 68%  642M 1s\n",
      " 45700K .......... .......... .......... .......... .......... 68%  666M 1s\n",
      " 45750K .......... .......... .......... .......... .......... 68% 78.5M 1s\n",
      " 45800K .......... .......... .......... .......... .......... 68% 47.3M 1s\n",
      " 45850K .......... .......... .......... .......... .......... 68%  888M 1s\n",
      " 45900K .......... .......... .......... .......... .......... 68% 75.2M 1s\n",
      " 45950K .......... .......... .......... .......... .......... 68% 66.2M 1s\n",
      " 46000K .......... .......... .......... .......... .......... 68% 5.22M 1s\n",
      " 46050K .......... .......... .......... .......... .......... 68%  361M 1s\n",
      " 46100K .......... .......... .......... .......... .......... 68%  872M 1s\n",
      " 46150K .......... .......... .......... .......... .......... 68%  361M 1s\n",
      " 46200K .......... .......... .......... .......... .......... 69%  238M 1s\n",
      " 46250K .......... .......... .......... .......... .......... 69%  830M 1s\n",
      " 46300K .......... .......... .......... .......... .......... 69%  518M 1s\n",
      " 46350K .......... .......... .......... .......... .......... 69%  613M 1s\n",
      " 46400K .......... .......... .......... .......... .......... 69%  745M 1s\n",
      " 46450K .......... .......... .......... .......... .......... 69%  107M 1s\n",
      " 46500K .......... .......... .......... .......... .......... 69%  115M 1s\n",
      " 46550K .......... .......... .......... .......... .......... 69%  124M 1s\n",
      " 46600K .......... .......... .......... .......... .......... 69% 61.3M 1s\n",
      " 46650K .......... .......... .......... .......... .......... 69% 43.8M 1s\n",
      " 46700K .......... .......... .......... .......... .......... 69% 79.4M 1s\n",
      " 46750K .......... .......... .......... .......... .......... 69% 6.62M 1s\n",
      " 46800K .......... .......... .......... .......... .......... 69%  319M 1s\n",
      " 46850K .......... .......... .......... .......... .......... 70%  600M 1s\n",
      " 46900K .......... .......... .......... .......... .......... 70%  230M 1s\n",
      " 46950K .......... .......... .......... .......... .......... 70%  578M 1s\n",
      " 47000K .......... .......... .......... .......... .......... 70%  982M 1s\n",
      " 47050K .......... .......... .......... .......... .......... 70%  143M 1s\n",
      " 47100K .......... .......... .......... .......... .......... 70%  508M 1s\n",
      " 47150K .......... .......... .......... .......... .......... 70% 58.4M 1s\n",
      " 47200K .......... .......... .......... .......... .......... 70%  133M 1s\n",
      " 47250K .......... .......... .......... .......... .......... 70%  113M 1s\n",
      " 47300K .......... .......... .......... .......... .......... 70% 71.2M 1s\n",
      " 47350K .......... .......... .......... .......... .......... 70% 5.43M 1s\n",
      " 47400K .......... .......... .......... .......... .......... 70%  366M 1s\n",
      " 47450K .......... .......... .......... .......... .......... 70%  317M 1s\n",
      " 47500K .......... .......... .......... .......... .......... 70%  935M 1s\n",
      " 47550K .......... .......... .......... .......... .......... 71%  267M 1s\n",
      " 47600K .......... .......... .......... .......... .......... 71%  359M 1s\n",
      " 47650K .......... .......... .......... .......... .......... 71%  518M 1s\n",
      " 47700K .......... .......... .......... .......... .......... 71%  967M 1s\n",
      " 47750K .......... .......... .......... .......... .......... 71%  476M 1s\n",
      " 47800K .......... .......... .......... .......... .......... 71%  116M 1s\n",
      " 47850K .......... .......... .......... .......... .......... 71%  899M 1s\n",
      " 47900K .......... .......... .......... .......... .......... 71%  124M 1s\n",
      " 47950K .......... .......... .......... .......... .......... 71% 53.4M 1s\n",
      " 48000K .......... .......... .......... .......... .......... 71% 8.84M 1s\n",
      " 48050K .......... .......... .......... .......... .......... 71%  437M 1s\n",
      " 48100K .......... .......... .......... .......... .......... 71%  448M 1s\n",
      " 48150K .......... .......... .......... .......... .......... 71%  563M 1s\n",
      " 48200K .......... .......... .......... .......... .......... 72%  211M 1s\n",
      " 48250K .......... .......... .......... .......... .......... 72%  930M 1s\n",
      " 48300K .......... .......... .......... .......... .......... 72% 13.2M 1s\n",
      " 48350K .......... .......... .......... .......... .......... 72%  503M 1s\n",
      " 48400K .......... .......... .......... .......... .......... 72%  243M 1s\n",
      " 48450K .......... .......... .......... .......... .......... 72%  596M 1s\n",
      " 48500K .......... .......... .......... .......... .......... 72%  990M 1s\n",
      " 48550K .......... .......... .......... .......... .......... 72%  115M 1s\n",
      " 48600K .......... .......... .......... .......... .......... 72% 76.7M 1s\n",
      " 48650K .......... .......... .......... .......... .......... 72% 75.0M 1s\n",
      " 48700K .......... .......... .......... .......... .......... 72% 79.3M 1s\n",
      " 48750K .......... .......... .......... .......... .......... 72% 6.11M 1s\n",
      " 48800K .......... .......... .......... .......... .......... 72%  384M 1s\n",
      " 48850K .......... .......... .......... .......... .......... 72%  526M 1s\n",
      " 48900K .......... .......... .......... .......... .......... 73%  279M 1s\n",
      " 48950K .......... .......... .......... .......... .......... 73%  598M 1s\n",
      " 49000K .......... .......... .......... .......... .......... 73%  961M 1s\n",
      " 49050K .......... .......... .......... .......... .......... 73%  163M 1s\n",
      " 49100K .......... .......... .......... .......... .......... 73%  903M 1s\n",
      " 49150K .......... .......... .......... .......... .......... 73%  132M 1s\n",
      " 49200K .......... .......... .......... .......... .......... 73% 77.0M 1s\n",
      " 49250K .......... .......... .......... .......... .......... 73%  612M 1s\n",
      " 49300K .......... .......... .......... .......... .......... 73% 39.4M 1s\n",
      " 49350K .......... .......... .......... .......... .......... 73% 11.8M 1s\n",
      " 49400K .......... .......... .......... .......... .......... 73%  519M 1s\n",
      " 49450K .......... .......... .......... .......... .......... 73%  424M 1s\n",
      " 49500K .......... .......... .......... .......... .......... 73%  846M 1s\n",
      " 49550K .......... .......... .......... .......... .......... 74%  268M 1s\n",
      " 49600K .......... .......... .......... .......... .......... 74% 9.77M 1s\n",
      " 49650K .......... .......... .......... .......... .......... 74%  140M 1s\n",
      " 49700K .......... .......... .......... .......... .......... 74%  264M 1s\n",
      " 49750K .......... .......... .......... .......... .......... 74%  480M 1s\n",
      " 49800K .......... .......... .......... .......... .......... 74%  355M 1s\n",
      " 49850K .......... .......... .......... .......... .......... 74%  625M 1s\n",
      " 49900K .......... .......... .......... .......... .......... 74%  925M 1s\n",
      " 49950K .......... .......... .......... .......... .......... 74% 32.1M 1s\n",
      " 50000K .......... .......... .......... .......... .......... 74%  490M 1s\n",
      " 50050K .......... .......... .......... .......... .......... 74%  385M 1s\n",
      " 50100K .......... .......... .......... .......... .......... 74% 72.2M 1s\n",
      " 50150K .......... .......... .......... .......... .......... 74% 2.88M 1s\n",
      " 50200K .......... .......... .......... .......... .......... 75% 56.7M 1s\n",
      " 50250K .......... .......... .......... .......... .......... 75%  102M 1s\n",
      " 50300K .......... .......... .......... .......... .......... 75%  146M 1s\n",
      " 50350K .......... .......... .......... .......... .......... 75%  119M 1s\n",
      " 50400K .......... .......... .......... .......... .......... 75%  276M 1s\n",
      " 50450K .......... .......... .......... .......... .......... 75%  297M 1s\n",
      " 50500K .......... .......... .......... .......... .......... 75%  114M 1s\n",
      " 50550K .......... .......... .......... .......... .......... 75%  265M 1s\n",
      " 50600K .......... .......... .......... .......... .......... 75%  215M 1s\n",
      " 50650K .......... .......... .......... .......... .......... 75%  303M 1s\n",
      " 50700K .......... .......... .......... .......... .......... 75%  313M 1s\n",
      " 50750K .......... .......... .......... .......... .......... 75% 88.2M 1s\n",
      " 50800K .......... .......... .......... .......... .......... 75%  176M 1s\n",
      " 50850K .......... .......... .......... .......... .......... 75%  148M 1s\n",
      " 50900K .......... .......... .......... .......... .......... 76%  271M 1s\n",
      " 50950K .......... .......... .......... .......... .......... 76%  228M 1s\n",
      " 51000K .......... .......... .......... .......... .......... 76%  840M 1s\n",
      " 51050K .......... .......... .......... .......... .......... 76%  689M 1s\n",
      " 51100K .......... .......... .......... .......... .......... 76%  982M 1s\n",
      " 51150K .......... .......... .......... .......... .......... 76%  804M 1s\n",
      " 51200K .......... .......... .......... .......... .......... 76%  574M 1s\n",
      " 51250K .......... .......... .......... .......... .......... 76%  861M 1s\n",
      " 51300K .......... .......... .......... .......... .......... 76%  548M 1s\n",
      " 51350K .......... .......... .......... .......... .......... 76%  420M 1s\n",
      " 51400K .......... .......... .......... .......... .......... 76%  814M 1s\n",
      " 51450K .......... .......... .......... .......... .......... 76%  548M 1s\n",
      " 51500K .......... .......... .......... .......... .......... 76%  836M 1s\n",
      " 51550K .......... .......... .......... .......... .......... 77% 6.20M 1s\n",
      " 51600K .......... .......... .......... .......... .......... 77%  574M 1s\n",
      " 51650K .......... .......... .......... .......... .......... 77%  629M 1s\n",
      " 51700K .......... .......... .......... .......... .......... 77%  572M 1s\n",
      " 51750K .......... .......... .......... .......... .......... 77%  421M 1s\n",
      " 51800K .......... .......... .......... .......... .......... 77% 40.1M 1s\n",
      " 51850K .......... .......... .......... .......... .......... 77%  574M 1s\n",
      " 51900K .......... .......... .......... .......... .......... 77%  941M 1s\n",
      " 51950K .......... .......... .......... .......... .......... 77%  351M 1s\n",
      " 52000K .......... .......... .......... .......... .......... 77% 70.8M 1s\n",
      " 52050K .......... .......... .......... .......... .......... 77%  873M 1s\n",
      " 52100K .......... .......... .......... .......... .......... 77%  112M 1s\n",
      " 52150K .......... .......... .......... .......... .......... 77%  113M 1s\n",
      " 52200K .......... .......... .......... .......... .......... 77% 80.6M 1s\n",
      " 52250K .......... .......... .......... .......... .......... 78%  139M 1s\n",
      " 52300K .......... .......... .......... .......... .......... 78% 66.6M 1s\n",
      " 52350K .......... .......... .......... .......... .......... 78% 35.5M 1s\n",
      " 52400K .......... .......... .......... .......... .......... 78%  120M 1s\n",
      " 52450K .......... .......... .......... .......... .......... 78% 49.5M 1s\n",
      " 52500K .......... .......... .......... .......... .......... 78% 56.5M 1s\n",
      " 52550K .......... .......... .......... .......... .......... 78% 69.8M 1s\n",
      " 52600K .......... .......... .......... .......... .......... 78% 24.4M 1s\n",
      " 52650K .......... .......... .......... .......... .......... 78%  909M 1s\n",
      " 52700K .......... .......... .......... .......... .......... 78% 64.9M 1s\n",
      " 52750K .......... .......... .......... .......... .......... 78% 79.3M 1s\n",
      " 52800K .......... .......... .......... .......... .......... 78% 72.0M 1s\n",
      " 52850K .......... .......... .......... .......... .......... 78% 79.6M 1s\n",
      " 52900K .......... .......... .......... .......... .......... 79% 48.1M 1s\n",
      " 52950K .......... .......... .......... .......... .......... 79% 80.8M 1s\n",
      " 53000K .......... .......... .......... .......... .......... 79% 20.9M 1s\n",
      " 53050K .......... .......... .......... .......... .......... 79%  450M 1s\n",
      " 53100K .......... .......... .......... .......... .......... 79%  315M 1s\n",
      " 53150K .......... .......... .......... .......... .......... 79% 54.3M 1s\n",
      " 53200K .......... .......... .......... .......... .......... 79% 41.0M 1s\n",
      " 53250K .......... .......... .......... .......... .......... 79%  101M 1s\n",
      " 53300K .......... .......... .......... .......... .......... 79% 66.8M 1s\n",
      " 53350K .......... .......... .......... .......... .......... 79% 66.1M 1s\n",
      " 53400K .......... .......... .......... .......... .......... 79% 5.79M 1s\n",
      " 53450K .......... .......... .......... .......... .......... 79%  386M 1s\n",
      " 53500K .......... .......... .......... .......... .......... 79%  344M 1s\n",
      " 53550K .......... .......... .......... .......... .......... 80%  279M 1s\n",
      " 53600K .......... .......... .......... .......... .......... 80%  135M 1s\n",
      " 53650K .......... .......... .......... .......... .......... 80% 69.3M 1s\n",
      " 53700K .......... .......... .......... .......... .......... 80% 72.4M 1s\n",
      " 53750K .......... .......... .......... .......... .......... 80% 71.2M 1s\n",
      " 53800K .......... .......... .......... .......... .......... 80% 25.8M 1s\n",
      " 53850K .......... .......... .......... .......... .......... 80%  147M 1s\n",
      " 53900K .......... .......... .......... .......... .......... 80%  137M 0s\n",
      " 53950K .......... .......... .......... .......... .......... 80% 47.0M 0s\n",
      " 54000K .......... .......... .......... .......... .......... 80% 80.3M 0s\n",
      " 54050K .......... .......... .......... .......... .......... 80% 48.0M 0s\n",
      " 54100K .......... .......... .......... .......... .......... 80% 62.1M 0s\n",
      " 54150K .......... .......... .......... .......... .......... 80% 59.2M 0s\n",
      " 54200K .......... .......... .......... .......... .......... 80% 31.8M 0s\n",
      " 54250K .......... .......... .......... .......... .......... 81%  418M 0s\n",
      " 54300K .......... .......... .......... .......... .......... 81% 95.1M 0s\n",
      " 54350K .......... .......... .......... .......... .......... 81% 44.5M 0s\n",
      " 54400K .......... .......... .......... .......... .......... 81% 92.6M 0s\n",
      " 54450K .......... .......... .......... .......... .......... 81% 56.2M 0s\n",
      " 54500K .......... .......... .......... .......... .......... 81% 66.8M 0s\n",
      " 54550K .......... .......... .......... .......... .......... 81% 15.5M 0s\n",
      " 54600K .......... .......... .......... .......... .......... 81%  507M 0s\n",
      " 54650K .......... .......... .......... .......... .......... 81%  829M 0s\n",
      " 54700K .......... .......... .......... .......... .......... 81% 17.0M 0s\n",
      " 54750K .......... .......... .......... .......... .......... 81%  336M 0s\n",
      " 54800K .......... .......... .......... .......... .......... 81%  111M 0s\n",
      " 54850K .......... .......... .......... .......... .......... 81% 60.7M 0s\n",
      " 54900K .......... .......... .......... .......... .......... 82%  516M 0s\n",
      " 54950K .......... .......... .......... .......... .......... 82%  111M 0s\n",
      " 55000K .......... .......... .......... .......... .......... 82%  124M 0s\n",
      " 55050K .......... .......... .......... .......... .......... 82% 76.8M 0s\n",
      " 55100K .......... .......... .......... .......... .......... 82% 90.5M 0s\n",
      " 55150K .......... .......... .......... .......... .......... 82% 34.0M 0s\n",
      " 55200K .......... .......... .......... .......... .......... 82% 26.1M 0s\n",
      " 55250K .......... .......... .......... .......... .......... 82% 12.5M 0s\n",
      " 55300K .......... .......... .......... .......... .......... 82%  362M 0s\n",
      " 55350K .......... .......... .......... .......... .......... 82%  312M 0s\n",
      " 55400K .......... .......... .......... .......... .......... 82%  538M 0s\n",
      " 55450K .......... .......... .......... .......... .......... 82%  663M 0s\n",
      " 55500K .......... .......... .......... .......... .......... 82% 14.1M 0s\n",
      " 55550K .......... .......... .......... .......... .......... 82%  347M 0s\n",
      " 55600K .......... .......... .......... .......... .......... 83%  207M 0s\n",
      " 55650K .......... .......... .......... .......... .......... 83%  701M 0s\n",
      " 55700K .......... .......... .......... .......... .......... 83%  332M 0s\n",
      " 55750K .......... .......... .......... .......... .......... 83%  489M 0s\n",
      " 55800K .......... .......... .......... .......... .......... 83% 92.0M 0s\n",
      " 55850K .......... .......... .......... .......... .......... 83% 78.0M 0s\n",
      " 55900K .......... .......... .......... .......... .......... 83% 30.7M 0s\n",
      " 55950K .......... .......... .......... .......... .......... 83% 23.4M 0s\n",
      " 56000K .......... .......... .......... .......... .......... 83%  334M 0s\n",
      " 56050K .......... .......... .......... .......... .......... 83% 73.8M 0s\n",
      " 56100K .......... .......... .......... .......... .......... 83% 86.1M 0s\n",
      " 56150K .......... .......... .......... .......... .......... 83% 91.4M 0s\n",
      " 56200K .......... .......... .......... .......... .......... 83%  893M 0s\n",
      " 56250K .......... .......... .......... .......... .......... 84% 63.3M 0s\n",
      " 56300K .......... .......... .......... .......... .......... 84% 8.69M 0s\n",
      " 56350K .......... .......... .......... .......... .......... 84%  370M 0s\n",
      " 56400K .......... .......... .......... .......... .......... 84%  595M 0s\n",
      " 56450K .......... .......... .......... .......... .......... 84%  652M 0s\n",
      " 56500K .......... .......... .......... .......... .......... 84%  632M 0s\n",
      " 56550K .......... .......... .......... .......... .......... 84%  150M 0s\n",
      " 56600K .......... .......... .......... .......... .......... 84%  703M 0s\n",
      " 56650K .......... .......... .......... .......... .......... 84% 51.9M 0s\n",
      " 56700K .......... .......... .......... .......... .......... 84% 94.9M 0s\n",
      " 56750K .......... .......... .......... .......... .......... 84% 65.4M 0s\n",
      " 56800K .......... .......... .......... .......... .......... 84%  146M 0s\n",
      " 56850K .......... .......... .......... .......... .......... 84% 22.9M 0s\n",
      " 56900K .......... .......... .......... .......... .......... 85%  904M 0s\n",
      " 56950K .......... .......... .......... .......... .......... 85%  102M 0s\n",
      " 57000K .......... .......... .......... .......... .......... 85% 86.1M 0s\n",
      " 57050K .......... .......... .......... .......... .......... 85% 64.0M 0s\n",
      " 57100K .......... .......... .......... .......... .......... 85% 54.5M 0s\n",
      " 57150K .......... .......... .......... .......... .......... 85% 16.6M 0s\n",
      " 57200K .......... .......... .......... .......... .......... 85%  214M 0s\n",
      " 57250K .......... .......... .......... .......... .......... 85%  909M 0s\n",
      " 57300K .......... .......... .......... .......... .......... 85% 41.7M 0s\n",
      " 57350K .......... .......... .......... .......... .......... 85%  448M 0s\n",
      " 57400K .......... .......... .......... .......... .......... 85% 61.7M 0s\n",
      " 57450K .......... .......... .......... .......... .......... 85%  140M 0s\n",
      " 57500K .......... .......... .......... .......... .......... 85% 57.9M 0s\n",
      " 57550K .......... .......... .......... .......... .......... 85% 47.6M 0s\n",
      " 57600K .......... .......... .......... .......... .......... 86% 14.0M 0s\n",
      " 57650K .......... .......... .......... .......... .......... 86%  563M 0s\n",
      " 57700K .......... .......... .......... .......... .......... 86%  587M 0s\n",
      " 57750K .......... .......... .......... .......... .......... 86% 88.5M 0s\n",
      " 57800K .......... .......... .......... .......... .......... 86%  108M 0s\n",
      " 57850K .......... .......... .......... .......... .......... 86%  102M 0s\n",
      " 57900K .......... .......... .......... .......... .......... 86%  127M 0s\n",
      " 57950K .......... .......... .......... .......... .......... 86% 3.39M 0s\n",
      " 58000K .......... .......... .......... .......... .......... 86%  769M 0s\n",
      " 58050K .......... .......... .......... .......... .......... 86%  321M 0s\n",
      " 58100K .......... .......... .......... .......... .......... 86%  507M 0s\n",
      " 58150K .......... .......... .......... .......... .......... 86% 51.7M 0s\n",
      " 58200K .......... .......... .......... .......... .......... 86% 2.43M 0s\n",
      " 58250K .......... .......... .......... .......... .......... 87% 63.4M 0s\n",
      " 58300K .......... .......... .......... .......... .......... 87% 80.1M 0s\n",
      " 58350K .......... .......... .......... .......... .......... 87% 74.5M 0s\n",
      " 58400K .......... .......... .......... .......... .......... 87%  173M 0s\n",
      " 58450K .......... .......... .......... .......... .......... 87% 1.94M 0s\n",
      " 58500K .......... .......... .......... .......... .......... 87% 76.1M 0s\n",
      " 58550K .......... .......... .......... .......... .......... 87%  145M 0s\n",
      " 58600K .......... .......... .......... .......... .......... 87% 71.4M 0s\n",
      " 58650K .......... .......... .......... .......... .......... 87%  169M 0s\n",
      " 58700K .......... .......... .......... .......... .......... 87%  179M 0s\n",
      " 58750K .......... .......... .......... .......... .......... 87% 97.2M 0s\n",
      " 58800K .......... .......... .......... .......... .......... 87% 65.3M 0s\n",
      " 58850K .......... .......... .......... .......... .......... 87%  166M 0s\n",
      " 58900K .......... .......... .......... .......... .......... 87%  180M 0s\n",
      " 58950K .......... .......... .......... .......... .......... 88% 64.6M 0s\n",
      " 59000K .......... .......... .......... .......... .......... 88%  104M 0s\n",
      " 59050K .......... .......... .......... .......... .......... 88%  574M 0s\n",
      " 59100K .......... .......... .......... .......... .......... 88% 5.25M 0s\n",
      " 59150K .......... .......... .......... .......... .......... 88%  382M 0s\n",
      " 59200K .......... .......... .......... .......... .......... 88%  362M 0s\n",
      " 59250K .......... .......... .......... .......... .......... 88%  641M 0s\n",
      " 59300K .......... .......... .......... .......... .......... 88%  965M 0s\n",
      " 59350K .......... .......... .......... .......... .......... 88%  526M 0s\n",
      " 59400K .......... .......... .......... .......... .......... 88%  943M 0s\n",
      " 59450K .......... .......... .......... .......... .......... 88% 1001M 0s\n",
      " 59500K .......... .......... .......... .......... .......... 88%  729M 0s\n",
      " 59550K .......... .......... .......... .......... .......... 88% 7.73M 0s\n",
      " 59600K .......... .......... .......... .......... .......... 89%  208M 0s\n",
      " 59650K .......... .......... .......... .......... .......... 89%  171M 0s\n",
      " 59700K .......... .......... .......... .......... .......... 89%  261M 0s\n",
      " 59750K .......... .......... .......... .......... .......... 89%  245M 0s\n",
      " 59800K .......... .......... .......... .......... .......... 89%  395M 0s\n",
      " 59850K .......... .......... .......... .......... .......... 89%  593M 0s\n",
      " 59900K .......... .......... .......... .......... .......... 89%  376M 0s\n",
      " 59950K .......... .......... .......... .......... .......... 89%  740M 0s\n",
      " 60000K .......... .......... .......... .......... .......... 89%  684M 0s\n",
      " 60050K .......... .......... .......... .......... .......... 89%  990M 0s\n",
      " 60100K .......... .......... .......... .......... .......... 89%  476M 0s\n",
      " 60150K .......... .......... .......... .......... .......... 89%  628M 0s\n",
      " 60200K .......... .......... .......... .......... .......... 89%  999M 0s\n",
      " 60250K .......... .......... .......... .......... .......... 90%  638M 0s\n",
      " 60300K .......... .......... .......... .......... .......... 90% 3.17M 0s\n",
      " 60350K .......... .......... .......... .......... .......... 90%  105M 0s\n",
      " 60400K .......... .......... .......... .......... .......... 90% 75.4M 0s\n",
      " 60450K .......... .......... .......... .......... .......... 90%  214M 0s\n",
      " 60500K .......... .......... .......... .......... .......... 90%  224M 0s\n",
      " 60550K .......... .......... .......... .......... .......... 90%  149M 0s\n",
      " 60600K .......... .......... .......... .......... .......... 90%  239M 0s\n",
      " 60650K .......... .......... .......... .......... .......... 90%  165M 0s\n",
      " 60700K .......... .......... .......... .......... .......... 90%  222M 0s\n",
      " 60750K .......... .......... .......... .......... .......... 90%  240M 0s\n",
      " 60800K .......... .......... .......... .......... .......... 90% 63.7M 0s\n",
      " 60850K .......... .......... .......... .......... .......... 90%  107M 0s\n",
      " 60900K .......... .......... .......... .......... .......... 90%  295M 0s\n",
      " 60950K .......... .......... .......... .......... .......... 91%  100M 0s\n",
      " 61000K .......... .......... .......... .......... .......... 91%  526M 0s\n",
      " 61050K .......... .......... .......... .......... .......... 91%  642M 0s\n",
      " 61100K .......... .......... .......... .......... .......... 91%  673M 0s\n",
      " 61150K .......... .......... .......... .......... .......... 91%  497M 0s\n",
      " 61200K .......... .......... .......... .......... .......... 91%  606M 0s\n",
      " 61250K .......... .......... .......... .......... .......... 91%  682M 0s\n",
      " 61300K .......... .......... .......... .......... .......... 91%  988M 0s\n",
      " 61350K .......... .......... .......... .......... .......... 91%  217M 0s\n",
      " 61400K .......... .......... .......... .......... .......... 91%  512M 0s\n",
      " 61450K .......... .......... .......... .......... .......... 91% 1009M 0s\n",
      " 61500K .......... .......... .......... .......... .......... 91%  399M 0s\n",
      " 61550K .......... .......... .......... .......... .......... 91%  784M 0s\n",
      " 61600K .......... .......... .......... .......... .......... 92% 47.0M 0s\n",
      " 61650K .......... .......... .......... .......... .......... 92% 96.3M 0s\n",
      " 61700K .......... .......... .......... .......... .......... 92% 67.7M 0s\n",
      " 61750K .......... .......... .......... .......... .......... 92% 77.5M 0s\n",
      " 61800K .......... .......... .......... .......... .......... 92% 52.2M 0s\n",
      " 61850K .......... .......... .......... .......... .......... 92% 78.8M 0s\n",
      " 61900K .......... .......... .......... .......... .......... 92% 6.57M 0s\n",
      " 61950K .......... .......... .......... .......... .......... 92%  658M 0s\n",
      " 62000K .......... .......... .......... .......... .......... 92%  152M 0s\n",
      " 62050K .......... .......... .......... .......... .......... 92%  758M 0s\n",
      " 62100K .......... .......... .......... .......... .......... 92% 70.3M 0s\n",
      " 62150K .......... .......... .......... .......... .......... 92% 74.3M 0s\n",
      " 62200K .......... .......... .......... .......... .......... 92% 1.13M 0s\n",
      " 62250K .......... .......... .......... .......... .......... 92% 27.1M 0s\n",
      " 62300K .......... .......... .......... .......... .......... 93% 64.0M 0s\n",
      " 62350K .......... .......... .......... .......... .......... 93% 80.3M 0s\n",
      " 62400K .......... .......... .......... .......... .......... 93% 76.1M 0s\n",
      " 62450K .......... .......... .......... .......... .......... 93%  595M 0s\n",
      " 62500K .......... .......... .......... .......... .......... 93%  679M 0s\n",
      " 62550K .......... .......... .......... .......... .......... 93%  935M 0s\n",
      " 62600K .......... .......... .......... .......... .......... 93%  996M 0s\n",
      " 62650K .......... .......... .......... .......... .......... 93%  711M 0s\n",
      " 62700K .......... .......... .......... .......... .......... 93%  894M 0s\n",
      " 62750K .......... .......... .......... .......... .......... 93%  563M 0s\n",
      " 62800K .......... .......... .......... .......... .......... 93% 1017M 0s\n",
      " 62850K .......... .......... .......... .......... .......... 93%  227M 0s\n",
      " 62900K .......... .......... .......... .......... .......... 93%  932M 0s\n",
      " 62950K .......... .......... .......... .......... .......... 94%  367M 0s\n",
      " 63000K .......... .......... .......... .......... .......... 94%  641M 0s\n",
      " 63050K .......... .......... .......... .......... .......... 94%  923M 0s\n",
      " 63100K .......... .......... .......... .......... .......... 94% 1.02G 0s\n",
      " 63150K .......... .......... .......... .......... .......... 94%  500M 0s\n",
      " 63200K .......... .......... .......... .......... .......... 94%  973M 0s\n",
      " 63250K .......... .......... .......... .......... .......... 94% 1.01G 0s\n",
      " 63300K .......... .......... .......... .......... .......... 94% 8.79M 0s\n",
      " 63350K .......... .......... .......... .......... .......... 94%  494M 0s\n",
      " 63400K .......... .......... .......... .......... .......... 94%  422M 0s\n",
      " 63450K .......... .......... .......... .......... .......... 94%  743M 0s\n",
      " 63500K .......... .......... .......... .......... .......... 94% 1.01G 0s\n",
      " 63550K .......... .......... .......... .......... .......... 94%  606M 0s\n",
      " 63600K .......... .......... .......... .......... .......... 95% 1.05G 0s\n",
      " 63650K .......... .......... .......... .......... .......... 95%  276M 0s\n",
      " 63700K .......... .......... .......... .......... .......... 95%  967M 0s\n",
      " 63750K .......... .......... .......... .......... .......... 95%  818M 0s\n",
      " 63800K .......... .......... .......... .......... .......... 95%  212M 0s\n",
      " 63850K .......... .......... .......... .......... .......... 95%  113M 0s\n",
      " 63900K .......... .......... .......... .......... .......... 95%  684M 0s\n",
      " 63950K .......... .......... .......... .......... .......... 95% 21.9M 0s\n",
      " 64000K .......... .......... .......... .......... .......... 95%  620M 0s\n",
      " 64050K .......... .......... .......... .......... .......... 95%  644M 0s\n",
      " 64100K .......... .......... .......... .......... .......... 95%  472M 0s\n",
      " 64150K .......... .......... .......... .......... .......... 95%  610M 0s\n",
      " 64200K .......... .......... .......... .......... .......... 95%  941M 0s\n",
      " 64250K .......... .......... .......... .......... .......... 95%  977M 0s\n",
      " 64300K .......... .......... .......... .......... .......... 96%  362M 0s\n",
      " 64350K .......... .......... .......... .......... .......... 96%  593M 0s\n",
      " 64400K .......... .......... .......... .......... .......... 96% 7.32M 0s\n",
      " 64450K .......... .......... .......... .......... .......... 96%  519M 0s\n",
      " 64500K .......... .......... .......... .......... .......... 96%  437M 0s\n",
      " 64550K .......... .......... .......... .......... .......... 96%  361M 0s\n",
      " 64600K .......... .......... .......... .......... .......... 96%  967M 0s\n",
      " 64650K .......... .......... .......... .......... .......... 96%  971M 0s\n",
      " 64700K .......... .......... .......... .......... .......... 96%  686M 0s\n",
      " 64750K .......... .......... .......... .......... .......... 96%  768M 0s\n",
      " 64800K .......... .......... .......... .......... .......... 96%  524M 0s\n",
      " 64850K .......... .......... .......... .......... .......... 96% 42.8M 0s\n",
      " 64900K .......... .......... .......... .......... .......... 96%  728M 0s\n",
      " 64950K .......... .......... .......... .......... .......... 97%  229M 0s\n",
      " 65000K .......... .......... .......... .......... .......... 97%  395M 0s\n",
      " 65050K .......... .......... .......... .......... .......... 97%  894M 0s\n",
      " 65100K .......... .......... .......... .......... .......... 97% 75.7M 0s\n",
      " 65150K .......... .......... .......... .......... .......... 97%  402M 0s\n",
      " 65200K .......... .......... .......... .......... .......... 97%  769M 0s\n",
      " 65250K .......... .......... .......... .......... .......... 97% 2.28M 0s\n",
      " 65300K .......... .......... .......... .......... .......... 97% 66.7M 0s\n",
      " 65350K .......... .......... .......... .......... .......... 97% 87.2M 0s\n",
      " 65400K .......... .......... .......... .......... .......... 97%  120M 0s\n",
      " 65450K .......... .......... .......... .......... .......... 97%  103M 0s\n",
      " 65500K .......... .......... .......... .......... .......... 97%  112M 0s\n",
      " 65550K .......... .......... .......... .......... .......... 97%  197M 0s\n",
      " 65600K .......... .......... .......... .......... .......... 97%  265M 0s\n",
      " 65650K .......... .......... .......... .......... .......... 98% 80.9M 0s\n",
      " 65700K .......... .......... .......... .......... .......... 98%  239M 0s\n",
      " 65750K .......... .......... .......... .......... .......... 98%  153M 0s\n",
      " 65800K .......... .......... .......... .......... .......... 98%  163M 0s\n",
      " 65850K .......... .......... .......... .......... .......... 98%  276M 0s\n",
      " 65900K .......... .......... .......... .......... .......... 98%  669M 0s\n",
      " 65950K .......... .......... .......... .......... .......... 98%  759M 0s\n",
      " 66000K .......... .......... .......... .......... .......... 98% 1009M 0s\n",
      " 66050K .......... .......... .......... .......... .......... 98%  691M 0s\n",
      " 66100K .......... .......... .......... .......... .......... 98%  888M 0s\n",
      " 66150K .......... .......... .......... .......... .......... 98%  661M 0s\n",
      " 66200K .......... .......... .......... .......... .......... 98%  996M 0s\n",
      " 66250K .......... .......... .......... .......... .......... 98%  576M 0s\n",
      " 66300K .......... .......... .......... .......... .......... 99%  247M 0s\n",
      " 66350K .......... .......... .......... .......... .......... 99% 49.7M 0s\n",
      " 66400K .......... .......... .......... .......... .......... 99% 75.7M 0s\n",
      " 66450K .......... .......... .......... .......... .......... 99%  221M 0s\n",
      " 66500K .......... .......... .......... .......... .......... 99%  150M 0s\n",
      " 66550K .......... .......... .......... .......... .......... 99%  176M 0s\n",
      " 66600K .......... .......... .......... .......... .......... 99%  506M 0s\n",
      " 66650K .......... .......... .......... .......... .......... 99%  471M 0s\n",
      " 66700K .......... .......... .......... .......... .......... 99%  505M 0s\n",
      " 66750K .......... .......... .......... .......... .......... 99%  762M 0s\n",
      " 66800K .......... .......... .......... .......... .......... 99%  607M 0s\n",
      " 66850K .......... .......... .......... .......... .......... 99%  508M 0s\n",
      " 66900K .......... .......... .......... .......... .......... 99%  389M 0s\n",
      " 66950K .......... .......... .......... .......... ........  100%  966M=2.3s\n",
      "\n",
      "2021-11-22 13:49:09 (27.9 MB/s) - 'cats_and_dogs_filtered.zip.1' saved [68606236/68606236]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 개와 고양이 데이터셋을 다운로드\n",
    "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
    "# 현재 경로에 압축해제\n",
    "!unzip cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d456b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d0b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 세트에 적용할 데이터 변환을 설정 - 사이즈 조절 + 랜덤으로 좌우반전\n",
    "train_config = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    "\n",
    "# 테스트 세트에 적용할 데이터 변환을 설정 - 사이즈만 조절\n",
    "test_config = transforms.Compose([transforms.Resize((224,224)), \n",
    "                                 transforms.ToTensor()\n",
    "                                 ])\n",
    "\n",
    "# 이미지를 불러와 위의 설정을 반영한 데이터세트 자료구조로 변환\n",
    "train_dset = datasets.ImageFolder('./cats_and_dogs_filtered/train/', train_config)\n",
    "test_dset = datasets.ImageFolder('./cats_and_dogs_filtered/validation/', test_config)\n",
    "\n",
    "# 한 번에 32개의 데이터 샘플을 배치로 사용하는 데이터 로더 생성 - 33+ ~  : out of memory\n",
    "train_loader = DataLoader(train_dset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2aa7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 사전 학습 모델인 VGG16 모델 객체를 생성하고 가중치를 불러옴\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# 모델의 구조를 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15d722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 가중치를 더이상 학습하지 않도록 설정\n",
    "for param in model.features.parameters() :\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdcd3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4096, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 출력층을 한 개의 노드를 가진 전곃합층으로 교체\n",
    "model.classifier[-1] = nn.Sequential(\n",
    "                                    nn.Linear(model.classifier[-1].in_features, 1),\n",
    "                                    nn.Sigmoid()\n",
    "                                    )\n",
    "\n",
    "# 그래픽카드 사용이 가능할 경우 그래픽카드로 연산하도록 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# 모델의 연산을 그래픽 카드에서 하도록 설정\n",
    "print(model.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6761af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f8abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # 모델을 학습 모드로 설정\n",
    "    model.train()\n",
    "    \n",
    "    # 배치 학습을 실행\n",
    "    for X_batch, y_batch in loader :\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 확률로 표현된 추론값을 타깃을 나타내는 정수 형태로 변환\n",
    "        y_predicted = hypothesis >= 0.5\n",
    "        # 현재 배치의 정확도를 계산\n",
    "        acc = (y_predicted == y_batch).float().mean()\n",
    "        # 현재 배치의 오차와 정확도를 저장\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # 현재 에포크의 오차와 정확도를 반환\n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394ab319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        # 배치 단위로 추론을 실행\n",
    "        for X_batch, y_batch in loader :\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            \n",
    "            y_predicted = hypothesis >= 0.5\n",
    "            acc = (y_predicted == y_batch).float().mean()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9232ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.0073, acc : 0.9990, val_loss : 0.0414, val_acc : 0.9844\n",
      "epoch : 2, loss : 0.0070, acc : 0.9990, val_loss : 0.0411, val_acc : 0.9863\n",
      "epoch : 3, loss : 0.0071, acc : 0.9980, val_loss : 0.0413, val_acc : 0.9863\n",
      "epoch : 4, loss : 0.0057, acc : 0.9995, val_loss : 0.0424, val_acc : 0.9854\n",
      "epoch : 5, loss : 0.0063, acc : 0.9980, val_loss : 0.0410, val_acc : 0.9844\n",
      "epoch : 6, loss : 0.0054, acc : 0.9985, val_loss : 0.0422, val_acc : 0.9854\n",
      "Early Stopping Process...\n",
      "총 소요시간 : 185.72, epoch당 평균 소요시간 : 30.95 \n"
     ]
    }
   ],
   "source": [
    "from time import time as time\n",
    "\n",
    "# 100회에 걸쳐 모델을 학습시킵니다\n",
    "\n",
    "n_epochs = 100\n",
    "patience = 3\n",
    "before_loss = 100\n",
    "\n",
    "s_time = time()\n",
    "\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    \n",
    "    val_loss, val_acc = validation(model, criterion, test_loader)\n",
    "    \n",
    "    print(f\"epoch : {epoch}, loss : {loss:.4f}, acc : {acc:.4f}, val_loss : {val_loss:.4f}, val_acc : {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < before_loss :\n",
    "        before_loss = val_loss\n",
    "    else :\n",
    "        patience -= 1\n",
    "    \n",
    "    if patience == 0 :\n",
    "        print(\"Early Stopping Process...\")\n",
    "        break\n",
    "        \n",
    "e_time = time()\n",
    "\n",
    "print(f\"총 소요시간 : {e_time-s_time:.2f}, epoch당 평균 소요시간 : {(e_time-s_time)/epoch:.2f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e48f3",
   "metadata": {},
   "source": [
    "# STEP 08. Higher 002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "618f04a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ml' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# github에서 서울 기상 데이터셋을 다운\n",
    "!git clone https://github.com/baek2sm/ml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93885139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "558886b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26181, 24, 3) (26181,)\n"
     ]
    }
   ],
   "source": [
    "# 서울 기상 데이터셋을 불러옴\n",
    "dataset = joblib.load(\"./ml/datasets/weather.pickle\")\n",
    "\n",
    "data, target = dataset['data'], dataset['target']\n",
    "\n",
    "print(data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96298ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = 20000\n",
    "\n",
    "X_train, X_test = data[:train_length], data[train_length:]\n",
    "y_train, y_test = target[:train_length], target[train_length:]\n",
    "\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "dset_train, dset_test = TensorDataset(X_train, y_train), TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dset_train, batch_size = 256, shuffle=True)\n",
    "test_loader = DataLoader(dset_test, batch_size = 256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e9fcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.cell = nn.RNN(3, 3, batch_first=True)\n",
    "        self.fc = nn.Linear(24*3, 1)\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        out, hidden_state = self.cell(X)\n",
    "        out = out.contiguous()\n",
    "        out = self.fc(out.view(-1, 24*3))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dff88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습에 사용하는 머신 : cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n학습에 사용하는 머신 : {device}\\n\")\n",
    "\n",
    "model = RNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3ee613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader) :\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for X_batch, y_batch in loader :\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195b336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, loader) :\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        for X_batch, y_batch in loader :\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e72f800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 322.79, val_loss : 162.12\n",
      "epoch : 2, loss : 292.96, val_loss : 143.27\n",
      "epoch : 3, loss : 265.05, val_loss : 126.78\n",
      "epoch : 4, loss : 239.06, val_loss : 112.62\n",
      "epoch : 5, loss : 216.47, val_loss : 100.36\n",
      "epoch : 6, loss : 195.41, val_loss : 89.87\n",
      "epoch : 7, loss : 178.36, val_loss : 80.83\n",
      "epoch : 8, loss : 160.97, val_loss : 73.08\n",
      "epoch : 9, loss : 147.62, val_loss : 66.32\n",
      "epoch : 10, loss : 134.19, val_loss : 60.41\n",
      "epoch : 11, loss : 122.57, val_loss : 55.34\n",
      "epoch : 12, loss : 112.44, val_loss : 50.93\n",
      "epoch : 13, loss : 103.08, val_loss : 47.25\n",
      "epoch : 14, loss : 94.85, val_loss : 44.24\n",
      "epoch : 15, loss : 88.28, val_loss : 41.58\n",
      "epoch : 16, loss : 81.69, val_loss : 39.30\n",
      "epoch : 17, loss : 75.88, val_loss : 37.41\n",
      "epoch : 18, loss : 70.87, val_loss : 35.82\n",
      "epoch : 19, loss : 66.24, val_loss : 34.48\n",
      "epoch : 20, loss : 62.31, val_loss : 33.33\n",
      "epoch : 21, loss : 58.79, val_loss : 32.33\n",
      "epoch : 22, loss : 55.55, val_loss : 31.49\n",
      "epoch : 23, loss : 52.56, val_loss : 30.70\n",
      "epoch : 24, loss : 50.32, val_loss : 30.08\n",
      "epoch : 25, loss : 47.83, val_loss : 29.44\n",
      "epoch : 26, loss : 45.81, val_loss : 28.80\n",
      "epoch : 27, loss : 43.91, val_loss : 28.20\n",
      "epoch : 28, loss : 42.25, val_loss : 27.66\n",
      "epoch : 29, loss : 40.70, val_loss : 27.19\n",
      "epoch : 30, loss : 39.42, val_loss : 26.74\n",
      "epoch : 31, loss : 38.03, val_loss : 26.29\n",
      "epoch : 32, loss : 37.04, val_loss : 25.87\n",
      "epoch : 33, loss : 35.94, val_loss : 25.52\n",
      "epoch : 34, loss : 34.92, val_loss : 25.21\n",
      "epoch : 35, loss : 34.01, val_loss : 24.85\n",
      "epoch : 36, loss : 33.25, val_loss : 24.58\n",
      "epoch : 37, loss : 32.47, val_loss : 24.32\n",
      "epoch : 38, loss : 31.78, val_loss : 24.16\n",
      "epoch : 39, loss : 31.25, val_loss : 23.94\n",
      "epoch : 40, loss : 30.67, val_loss : 23.80\n",
      "epoch : 41, loss : 29.96, val_loss : 23.66\n",
      "epoch : 42, loss : 29.64, val_loss : 23.53\n",
      "epoch : 43, loss : 29.30, val_loss : 23.47\n",
      "epoch : 44, loss : 28.80, val_loss : 23.42\n",
      "epoch : 45, loss : 28.46, val_loss : 23.41\n",
      "epoch : 46, loss : 28.16, val_loss : 23.41\n",
      "epoch : 47, loss : 28.15, val_loss : 23.30\n",
      "epoch : 48, loss : 27.58, val_loss : 23.25\n",
      "epoch : 49, loss : 27.41, val_loss : 23.24\n",
      "epoch : 50, loss : 27.11, val_loss : 23.17\n",
      "epoch : 51, loss : 26.77, val_loss : 23.22\n",
      "epoch : 52, loss : 26.62, val_loss : 23.30\n",
      "epoch : 53, loss : 26.60, val_loss : 23.25\n",
      "epoch : 54, loss : 26.46, val_loss : 23.30\n",
      "epoch : 55, loss : 26.05, val_loss : 23.22\n",
      "epoch : 56, loss : 26.13, val_loss : 23.23\n",
      "epoch : 57, loss : 25.94, val_loss : 23.26\n",
      "epoch : 58, loss : 25.72, val_loss : 23.10\n",
      "epoch : 59, loss : 25.57, val_loss : 23.16\n",
      "epoch : 60, loss : 25.35, val_loss : 23.28\n",
      "epoch : 61, loss : 25.23, val_loss : 23.11\n",
      "epoch : 62, loss : 25.24, val_loss : 23.15\n",
      "epoch : 63, loss : 25.03, val_loss : 22.92\n",
      "epoch : 64, loss : 24.99, val_loss : 23.02\n",
      "epoch : 65, loss : 24.86, val_loss : 22.69\n",
      "epoch : 66, loss : 24.55, val_loss : 22.73\n",
      "epoch : 67, loss : 24.71, val_loss : 22.55\n",
      "epoch : 68, loss : 24.41, val_loss : 22.61\n",
      "epoch : 69, loss : 24.34, val_loss : 22.44\n",
      "epoch : 70, loss : 24.19, val_loss : 22.32\n",
      "epoch : 71, loss : 24.24, val_loss : 22.11\n",
      "epoch : 72, loss : 23.90, val_loss : 22.24\n",
      "epoch : 73, loss : 23.90, val_loss : 21.87\n",
      "epoch : 74, loss : 23.62, val_loss : 21.73\n",
      "epoch : 75, loss : 23.58, val_loss : 21.58\n",
      "epoch : 76, loss : 23.45, val_loss : 21.53\n",
      "epoch : 77, loss : 23.47, val_loss : 21.32\n",
      "epoch : 78, loss : 23.27, val_loss : 21.27\n",
      "epoch : 79, loss : 23.01, val_loss : 21.12\n",
      "epoch : 80, loss : 22.94, val_loss : 20.87\n",
      "epoch : 81, loss : 22.73, val_loss : 20.76\n",
      "epoch : 82, loss : 22.72, val_loss : 20.63\n",
      "epoch : 83, loss : 22.66, val_loss : 20.48\n",
      "epoch : 84, loss : 22.37, val_loss : 20.36\n",
      "epoch : 85, loss : 22.32, val_loss : 20.23\n",
      "epoch : 86, loss : 22.35, val_loss : 20.08\n",
      "epoch : 87, loss : 21.97, val_loss : 19.89\n",
      "epoch : 88, loss : 21.84, val_loss : 19.67\n",
      "epoch : 89, loss : 21.72, val_loss : 19.64\n",
      "epoch : 90, loss : 21.54, val_loss : 19.41\n",
      "epoch : 91, loss : 21.34, val_loss : 19.35\n",
      "epoch : 92, loss : 21.39, val_loss : 19.22\n",
      "epoch : 93, loss : 21.19, val_loss : 19.08\n",
      "epoch : 94, loss : 20.91, val_loss : 18.87\n",
      "epoch : 95, loss : 20.82, val_loss : 18.68\n",
      "epoch : 96, loss : 20.63, val_loss : 18.53\n",
      "epoch : 97, loss : 20.51, val_loss : 18.40\n",
      "epoch : 98, loss : 20.29, val_loss : 18.24\n",
      "epoch : 99, loss : 20.17, val_loss : 18.14\n",
      "epoch : 100, loss : 19.97, val_loss : 18.00\n",
      "epoch : 101, loss : 20.09, val_loss : 17.84\n",
      "epoch : 102, loss : 19.77, val_loss : 17.70\n",
      "epoch : 103, loss : 19.51, val_loss : 17.56\n",
      "epoch : 104, loss : 19.35, val_loss : 17.43\n",
      "epoch : 105, loss : 19.21, val_loss : 17.34\n",
      "epoch : 106, loss : 18.92, val_loss : 17.22\n",
      "epoch : 107, loss : 18.74, val_loss : 17.06\n",
      "epoch : 108, loss : 18.66, val_loss : 16.93\n",
      "epoch : 109, loss : 18.39, val_loss : 16.85\n",
      "epoch : 110, loss : 18.17, val_loss : 16.69\n",
      "epoch : 111, loss : 18.03, val_loss : 16.66\n",
      "epoch : 112, loss : 17.83, val_loss : 16.52\n",
      "epoch : 113, loss : 17.62, val_loss : 16.39\n",
      "epoch : 114, loss : 17.30, val_loss : 16.24\n",
      "epoch : 115, loss : 17.10, val_loss : 16.08\n",
      "epoch : 116, loss : 16.94, val_loss : 16.01\n",
      "epoch : 117, loss : 16.64, val_loss : 15.99\n",
      "epoch : 118, loss : 16.57, val_loss : 15.98\n",
      "epoch : 119, loss : 16.36, val_loss : 15.77\n",
      "epoch : 120, loss : 16.17, val_loss : 15.86\n",
      "epoch : 121, loss : 16.04, val_loss : 15.60\n",
      "epoch : 122, loss : 15.86, val_loss : 15.75\n",
      "epoch : 123, loss : 15.68, val_loss : 15.77\n",
      "epoch : 124, loss : 15.44, val_loss : 15.67\n",
      "epoch : 125, loss : 15.34, val_loss : 15.38\n",
      "epoch : 126, loss : 15.28, val_loss : 15.35\n",
      "epoch : 127, loss : 15.11, val_loss : 15.44\n",
      "epoch : 128, loss : 14.96, val_loss : 15.29\n",
      "epoch : 129, loss : 14.90, val_loss : 15.07\n",
      "epoch : 130, loss : 14.79, val_loss : 15.13\n",
      "epoch : 131, loss : 14.63, val_loss : 15.12\n",
      "epoch : 132, loss : 14.53, val_loss : 14.95\n",
      "epoch : 133, loss : 14.51, val_loss : 15.18\n",
      "epoch : 134, loss : 14.43, val_loss : 14.90\n",
      "epoch : 135, loss : 14.31, val_loss : 14.92\n",
      "epoch : 136, loss : 14.20, val_loss : 14.80\n",
      "epoch : 137, loss : 14.15, val_loss : 14.77\n",
      "epoch : 138, loss : 13.98, val_loss : 14.72\n",
      "epoch : 139, loss : 13.94, val_loss : 14.75\n",
      "epoch : 140, loss : 13.81, val_loss : 14.64\n",
      "epoch : 141, loss : 13.75, val_loss : 14.57\n",
      "epoch : 142, loss : 13.70, val_loss : 14.55\n",
      "epoch : 143, loss : 13.60, val_loss : 14.44\n",
      "epoch : 144, loss : 13.59, val_loss : 14.47\n",
      "epoch : 145, loss : 13.48, val_loss : 14.36\n",
      "epoch : 146, loss : 13.44, val_loss : 14.34\n",
      "epoch : 147, loss : 13.34, val_loss : 14.31\n",
      "epoch : 148, loss : 13.28, val_loss : 14.27\n",
      "epoch : 149, loss : 13.23, val_loss : 14.26\n",
      "epoch : 150, loss : 13.18, val_loss : 14.21\n",
      "epoch : 151, loss : 13.15, val_loss : 14.23\n",
      "epoch : 152, loss : 13.03, val_loss : 14.14\n",
      "epoch : 153, loss : 12.99, val_loss : 14.12\n",
      "epoch : 154, loss : 12.97, val_loss : 14.10\n",
      "epoch : 155, loss : 12.97, val_loss : 14.09\n",
      "epoch : 156, loss : 12.89, val_loss : 14.10\n",
      "epoch : 157, loss : 12.83, val_loss : 14.04\n",
      "epoch : 158, loss : 12.72, val_loss : 14.03\n",
      "epoch : 159, loss : 12.76, val_loss : 14.00\n",
      "epoch : 160, loss : 12.73, val_loss : 13.99\n",
      "epoch : 161, loss : 12.64, val_loss : 13.95\n",
      "epoch : 162, loss : 12.61, val_loss : 13.94\n",
      "epoch : 163, loss : 12.55, val_loss : 13.91\n",
      "epoch : 164, loss : 12.47, val_loss : 13.91\n",
      "epoch : 165, loss : 12.42, val_loss : 13.87\n",
      "epoch : 166, loss : 12.38, val_loss : 13.85\n",
      "epoch : 167, loss : 12.49, val_loss : 13.86\n",
      "epoch : 168, loss : 12.35, val_loss : 13.84\n",
      "epoch : 169, loss : 12.33, val_loss : 13.82\n",
      "epoch : 170, loss : 12.28, val_loss : 13.79\n",
      "epoch : 171, loss : 12.35, val_loss : 13.80\n",
      "epoch : 172, loss : 12.25, val_loss : 13.78\n",
      "epoch : 173, loss : 12.27, val_loss : 13.77\n",
      "epoch : 174, loss : 12.19, val_loss : 13.75\n",
      "epoch : 175, loss : 12.27, val_loss : 13.73\n",
      "epoch : 176, loss : 12.18, val_loss : 13.72\n",
      "epoch : 177, loss : 12.06, val_loss : 13.70\n",
      "epoch : 178, loss : 12.11, val_loss : 13.67\n",
      "epoch : 179, loss : 12.08, val_loss : 13.67\n",
      "epoch : 180, loss : 12.02, val_loss : 13.70\n",
      "epoch : 181, loss : 12.06, val_loss : 13.64\n",
      "epoch : 182, loss : 11.99, val_loss : 13.64\n",
      "epoch : 183, loss : 11.98, val_loss : 13.61\n",
      "epoch : 184, loss : 11.94, val_loss : 13.60\n",
      "epoch : 185, loss : 11.89, val_loss : 13.65\n",
      "epoch : 186, loss : 11.94, val_loss : 13.58\n",
      "epoch : 187, loss : 11.94, val_loss : 13.65\n",
      "epoch : 188, loss : 11.84, val_loss : 13.57\n",
      "epoch : 189, loss : 11.79, val_loss : 13.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 190, loss : 11.89, val_loss : 13.54\n",
      "epoch : 191, loss : 11.76, val_loss : 13.57\n",
      "epoch : 192, loss : 11.83, val_loss : 13.50\n",
      "epoch : 193, loss : 11.74, val_loss : 13.48\n",
      "epoch : 194, loss : 11.72, val_loss : 13.46\n",
      "epoch : 195, loss : 11.73, val_loss : 13.47\n",
      "epoch : 196, loss : 11.63, val_loss : 13.46\n",
      "epoch : 197, loss : 11.61, val_loss : 13.45\n",
      "epoch : 198, loss : 11.68, val_loss : 13.42\n",
      "epoch : 199, loss : 11.69, val_loss : 13.39\n",
      "epoch : 200, loss : 11.63, val_loss : 13.40\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200 \n",
    "\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    loss = train(model, criterion, optimizer, train_loader)\n",
    "    val_loss = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    print(f\"epoch : {epoch}, loss : {loss:.2f}, val_loss : {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc84f186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted target : 16.5992431640625, real target : 18.399999618530273\n",
      "predicted target : 12.274434089660645, real target : 5.199999809265137\n",
      "predicted target : 13.517139434814453, real target : 11.5\n",
      "predicted target : 3.7794406414031982, real target : 8.899999618530273\n",
      "predicted target : 2.4168059825897217, real target : -0.20000000298023224\n",
      "predicted target : -2.592533588409424, real target : 0.20000000298023224\n",
      "predicted target : 2.5945723056793213, real target : 0.30000001192092896\n",
      "predicted target : -0.6390209197998047, real target : 5.0\n",
      "predicted target : 2.89371657371521, real target : -1.2000000476837158\n",
      "predicted target : 2.018634080886841, real target : 3.5999999046325684\n",
      "predicted target : 2.919801950454712, real target : 2.700000047683716\n",
      "predicted target : 0.40973833203315735, real target : 5.199999809265137\n",
      "predicted target : 3.4526264667510986, real target : 8.199999809265137\n",
      "predicted target : 1.6758506298065186, real target : 0.5\n",
      "predicted target : 7.599041938781738, real target : 3.5999999046325684\n",
      "predicted target : 12.529407501220703, real target : 16.0\n",
      "predicted target : 5.5323615074157715, real target : 7.300000190734863\n",
      "predicted target : 16.52667236328125, real target : 13.199999809265137\n",
      "predicted target : 11.613228797912598, real target : 15.800000190734863\n",
      "predicted target : 15.042898178100586, real target : 11.699999809265137\n",
      "predicted target : 16.130464553833008, real target : 17.700000762939453\n",
      "predicted target : 18.104726791381836, real target : 21.600000381469727\n",
      "predicted target : 19.644262313842773, real target : 19.299999237060547\n",
      "predicted target : 25.550580978393555, real target : 24.100000381469727\n",
      "predicted target : 24.29851531982422, real target : 27.5\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad() :\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "        hypothesis = model(X_batch)\n",
    "        # 배치의 첫 번째 데이터 샘플마다 모델이 예측한 값과 실제 타깃을 출력합니다\n",
    "        print(f\"predicted target : {hypothesis[0].item()}, real target : {y_batch[0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935875d",
   "metadata": {},
   "source": [
    "# STEP 09. Higher 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f272299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext import datasets\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809815f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84.1M/84.1M [00:21<00:00, 3.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터세트의 학습 세트를 불러옵니다\n",
    "train_dataset = datasets.IMDB(split=('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a300f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 객체 생성\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3796e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 누적 사용 빈도를 계산하기 위해 카운터 객체를 생성\n",
    "counter = Counter()\n",
    "\n",
    "# 학습 세트의 문장을 단어 단위로 토큰화하고 단어별 누적사용 빈도를 계산\n",
    "for (label, text) in train_dataset :\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5730fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 이상 사용된 단어를 사용해서 단어장을 만듭니다\n",
    "vocabulary = vocab(counter, min_freq=10)\n",
    "vocabulary.set_default_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "479d85af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1395"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b53a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 정수 인코딩하는 람다 함수를 정의\n",
    "text_transform = lambda x : [vocabulary[token] for token in tokenizer(x)]\n",
    "\n",
    "# 레이블을 정숫값으로 치환하는 람다 함수를 정의\n",
    "label_transform = lambda x : 1 if x =='pos' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "754d5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방금 정의한 두 개의 람다 함수를 이요해 텍스트와 레이블을 전처리하는 함수를 정의\n",
    "def preprocessing(batch) :\n",
    "    label_list, text_list = [], []\n",
    "    \n",
    "    # 람다 함수를 사용해서 배치값을 차례대로 변환\n",
    "    for (_label, _text) in batch :\n",
    "        label_list.append(label_transform(_label))\n",
    "        text_list.append(torch.tensor(text_transform(_text)))\n",
    "        \n",
    "    # 가장 긴 문장을 기준으로 정수 인코딩된 문장의 길이를 통일\n",
    "    data = pad_sequence(text_list)\n",
    "    target = torch.tensor(label_list)\n",
    "    \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23e7486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터세트를 학습 세트와 테스트 세트로 나눠서 불러옵니다\n",
    "train_dataset, test_dataset = datasets.IMDB(split=('train', 'test'))\n",
    "\n",
    "# preprocessing 함수를 적용하여 학습 세트 데이터로더와 테스트 세트 데이터로더를 만듭니다\n",
    "train_loader = DataLoader(list(train_dataset), batch_size=512, shuffle=True, collate_fn=preprocessing)\n",
    "test_loader = DataLoader(list(test_dataset), batch_size=512, shuffle=False, collate_fn=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ca1a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module) :\n",
    "    def __init__(self, vacab_size) :\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 16)\n",
    "        self.cell = nn.LSTM(16,16)\n",
    "        self.fc = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    # 순전파를 정의\n",
    "    def forward(self, X) :\n",
    "        out = self.embed(X)\n",
    "        out, (hidden_state, cell_state) = self.cell(out)\n",
    "        out = self.fc(hidden_state.view(-1, 16))\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48ee9c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습에 사용하는 머신 : cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"\\n학습에 사용하는 머신 : {device}\\n\")\n",
    "\n",
    "# LSTM 모델 객체를 생성\n",
    "vocab_size = len(vocabulary)\n",
    "model = LSTM(vocab_size).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce6de15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for X_batch, y_batch in loader :\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X_batch)\n",
    "        loss = criterion(hypothesis, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = ((hypothesis >= 0.5) == y_batch).float().mean()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbd83cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, loader) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader :\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).float().view(-1,1)\n",
    "            hypothesis = model(X_batch)\n",
    "            loss = criterion(hypothesis, y_batch)\n",
    "            \n",
    "            acc = ((hypothesis >= 0.5) == y_batch).float().mean()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09cf2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.6853, acc : 0.5069, val_loss : 0.6984, val_acc : 0.5015\n",
      "epoch : 2, loss : 0.6859, acc : 0.5029, val_loss : 0.6969, val_acc : 0.5017\n",
      "epoch : 3, loss : 0.6858, acc : 0.5071, val_loss : 0.7023, val_acc : 0.5011\n",
      "epoch : 4, loss : 0.6857, acc : 0.5082, val_loss : 0.6987, val_acc : 0.5023\n",
      "epoch : 5, loss : 0.6848, acc : 0.5032, val_loss : 0.6972, val_acc : 0.5016\n",
      "epoch : 6, loss : 0.6851, acc : 0.5117, val_loss : 0.6986, val_acc : 0.5014\n",
      "epoch : 7, loss : 0.6848, acc : 0.5070, val_loss : 0.6973, val_acc : 0.5026\n",
      "epoch : 8, loss : 0.6846, acc : 0.5085, val_loss : 0.6989, val_acc : 0.5017\n",
      "epoch : 9, loss : 0.6838, acc : 0.5069, val_loss : 0.6994, val_acc : 0.5027\n",
      "epoch : 10, loss : 0.6847, acc : 0.5032, val_loss : 0.6983, val_acc : 0.5025\n",
      "epoch : 11, loss : 0.6841, acc : 0.5063, val_loss : 0.6997, val_acc : 0.5028\n",
      "epoch : 12, loss : 0.6849, acc : 0.5066, val_loss : 0.6984, val_acc : 0.5028\n",
      "epoch : 13, loss : 0.6851, acc : 0.5105, val_loss : 0.6980, val_acc : 0.5029\n",
      "epoch : 14, loss : 0.6843, acc : 0.4998, val_loss : 0.6980, val_acc : 0.5017\n",
      "epoch : 15, loss : 0.6840, acc : 0.5101, val_loss : 0.6991, val_acc : 0.5017\n",
      "epoch : 16, loss : 0.6846, acc : 0.5079, val_loss : 0.6974, val_acc : 0.5041\n",
      "epoch : 17, loss : 0.6841, acc : 0.5081, val_loss : 0.6974, val_acc : 0.5030\n",
      "epoch : 18, loss : 0.6396, acc : 0.6337, val_loss : 0.6212, val_acc : 0.6740\n",
      "epoch : 19, loss : 0.5593, acc : 0.7318, val_loss : 0.5734, val_acc : 0.7199\n",
      "epoch : 20, loss : 0.5082, acc : 0.7742, val_loss : 0.5514, val_acc : 0.7383\n",
      "epoch : 21, loss : 0.4596, acc : 0.8091, val_loss : 0.5156, val_acc : 0.7714\n",
      "epoch : 22, loss : 0.4265, acc : 0.8224, val_loss : 0.5035, val_acc : 0.7857\n",
      "epoch : 23, loss : 0.4386, acc : 0.8127, val_loss : 0.6256, val_acc : 0.6386\n",
      "epoch : 24, loss : 0.4726, acc : 0.8027, val_loss : 0.4824, val_acc : 0.7908\n",
      "epoch : 25, loss : 0.3810, acc : 0.8536, val_loss : 0.4822, val_acc : 0.7938\n",
      "epoch : 26, loss : 0.4215, acc : 0.8223, val_loss : 0.4993, val_acc : 0.7830\n",
      "epoch : 27, loss : 0.3483, acc : 0.8685, val_loss : 0.4695, val_acc : 0.8052\n",
      "epoch : 28, loss : 0.3169, acc : 0.8839, val_loss : 0.4675, val_acc : 0.8123\n",
      "epoch : 29, loss : 0.3062, acc : 0.8890, val_loss : 0.5026, val_acc : 0.7868\n",
      "Early Stopping Process\n",
      "총 소요시간 810.10, epoch당 평균 소요시간 27.93\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "s_time = time()\n",
    "\n",
    "n_epochs = 100\n",
    "patience = 5\n",
    "before_loss = 100\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "    loss, acc = train(model, criterion, optimizer, train_loader)\n",
    "    val_loss, val_acc = evaluate(model, criterion, test_loader)\n",
    "    \n",
    "    print(f\"epoch : {epoch}, loss : {loss:.4f}, acc : {acc:.4f}, val_loss : {val_loss:.4f}, val_acc : {val_acc:.4f}\")\n",
    "    \n",
    "    if epoch > 10 :\n",
    "        if val_loss < before_loss :\n",
    "            before_loss = val_loss\n",
    "        else :\n",
    "            patience -= 1\n",
    "            \n",
    "    if patience == 0 :\n",
    "        print(\"Early Stopping Process\")\n",
    "        break\n",
    "\n",
    "e_time = time()\n",
    "\n",
    "print(f\"총 소요시간 {e_time-s_time:.2f}, epoch당 평균 소요시간 {(e_time-s_time)/epoch:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1be9e27c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
